{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e4e0ad4",
   "metadata": {},
   "source": [
    "# Bias Evaluation : AIF360\n",
    "***\n",
    "\n",
    "Quantification of model bias in terms of fairness against protected groups before and after implementation of mitigation methods\n",
    "\n",
    "## Terminology\n",
    "***\n",
    "\n",
    "***Favorable label:*** A label whose value corresponds to an outcome that provides an advantage to the recipient (such as receiving a loan, being hired for a job, not being arrested)\n",
    "\n",
    "***Protected attribute:*** An attribute that partitions a population into groups whose outcomes should have parity (such as race, gender, caste, and religion)\n",
    "\n",
    "***Privileged value (of a protected attribute):*** A protected attribute value indicating a group that has historically been at a systemic advantage\n",
    "\n",
    "***Fairness metric:*** A quantification of unwanted bias in training data or models\n",
    "\n",
    "***Discrimination/unwanted bias:*** Although bias can refer to any form of preference, fair or unfair, our focus is on undesirable bias or discrimination, which is when specific privileged groups are placed at a systematic advantage and specific unprivileged groups are placed at a systematic disadvantage. This relates to attributes such as race, gender, age, and sexual orientation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4400ba5e",
   "metadata": {},
   "source": [
    "\n",
    "## Structure of Evaluation & Intervention\n",
    "***\n",
    "<img src=\"images/aif360_pipeline.png\" width=\"700\" height=\"500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42162b2",
   "metadata": {},
   "source": [
    "### Three Perspectives of Fairness in ML algorithms\n",
    "***\n",
    "\n",
    "[linkedin article](https://www.linkedin.com/pulse/whats-new-deep-learning-research-reducing-bias-models-jesus-rodriguez/)\n",
    "\n",
    "***1. Data vs Mode***\n",
    "\n",
    "Fairness may be quantified in the training dataset or in the learned model\n",
    "\n",
    "***2. Group vs Individual***\n",
    "\n",
    "Group fairness partitions a population into groups defined by protected attributes and seeks for some statistical measure to be equal across all groups. Individual fairness seeks for similar individuals to be treated similarly.\n",
    "\n",
    "\n",
    "***3. WAE vs WYSIWYG (We are all equal vs What you see is what you get)***\n",
    "\n",
    "WAE says that fairness is an equal distirbution of skills and opportunities among the participants in an ML task, attributing differences in outcome distributions to structural bias and not a difference in distribution to ability. WYSIWYG says that observations reflect ability with respect to a task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef8aefc",
   "metadata": {},
   "source": [
    "> If the application follows the WAE worldview, then the demographic parity metrics should be used: disparate_impact and statistical_parity_difference.  If the application follows the WYSIWYG worldview, then the equality of odds metrics should be used: average_odds_difference and average_abs_odds_difference.  Other group fairness metrics (some are often labeled equality of opportunity) lie in-between the two worldviews and may be used appropriately: false_negative_rate_ratio, false_negative_rate_difference, false_positive_rate_ratio, false_positive_rate_difference, false_discovery_rate_ratio, false_discovery_rate_difference, false_omission_rate_ratio, false_omission_rate_difference, error_rate_ratio, and error_rate_difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7774b603",
   "metadata": {},
   "source": [
    "### 2. Evaluation of Bias in Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9e334f",
   "metadata": {},
   "source": [
    "<center><b>Average Odds Difference:</b> $ \\tfrac{1}{2}\\left[(FPR_{D = \\text{unprivileged}} - FPR_{D = \\text{privileged}}) + (TPR_{D = \\text{privileged}} - TPR_{D = \\text{unprivileged}}))\\right] $ </center>\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<center><b>Statistical Parity Difference:    </b>$ Pr(\\hat{Y} = 1 | D = \\text{unprivileged}) - Pr(\\hat{Y} = 1 | D = \\text{privileged}) $</center>\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<center><b>Equal Opportunity Difference:    </b>$ TPR_{D = \\text{unprivileged}} - TPR_{D = \\text{privileged}} $</center>\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<center><b>Theil Index:    </b>$ \\frac{1}{n}\\sum_{i=1}^n\\frac{b_{i}}{\\mu}\\ln\\frac{b_{i}}{\\mu}, \\text{with} b_i = \\hat{y}_i - y_i + 1 $</center>\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<center><b>Disparate Impact:    </b> $ \\frac{Pr(Y = 1 | D = \\text{unprivileged})} {Pr(Y = 1 | D = \\text{privileged})}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f5c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(context='talk', style='whitegrid')\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers  import Adam, Adagrad, SGD, RMSprop\n",
    "\n",
    "# from aif360.sklearn.metrics import mdss_bias_scan, mdss_bias_score\n",
    "import aif360\n",
    "import utilities\n",
    "import global_variables as gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e95abc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset, BinaryLabelDataset\n",
    "from aif360.sklearn import metrics as mt\n",
    "from aif360.explainers import MetricTextExplainer, MetricJSONExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23849cea",
   "metadata": {},
   "source": [
    "### load data\n",
    "\n",
    "#### configure datasets according to aif360 library\n",
    "<ol>\n",
    "    <li> Binarize the sensitive attribute: 1 set to privileged group, 0 to unprivileged group</li>\n",
    "    <li> Binarize the label columns: 1 is the positive outcome and 0 else</li>\n",
    "    <li> Set the sensitive attribute as index</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73176f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/binary_full.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df['sex-binary']=df['sex'].map(gv.binary_sex)\n",
    "\n",
    "input_cols = df.iloc[:,:61].columns.to_list()\n",
    "X1 = df.loc[:,input_cols+['CVD']+['sex-binary']].set_index('sex-binary')\n",
    "X2 = df.loc[:,input_cols+['CVD']+['race-binary']].set_index('race-binary')\n",
    "X3 = df.loc[:,input_cols+['CVD']]\n",
    "X3['age-binary'] = np.where((df['age']>=50)&(df['age']<70),1,0)\n",
    "X3 = X3.set_index('age-binary')\n",
    "X4 = df.loc[:,input_cols+['CVD']+['age']].set_index('age')\n",
    "\n",
    "# X1.drop(columns=gv.protected_attributes[0], axis=1, inplace=True)\n",
    "# X2.drop(columns=gv.protected_attributes[1], axis=1, inplace=True)\n",
    "# X3.drop(columns=gv.protected_attributes[2], axis=1, inplace=True)\n",
    "# X4.drop(columns=gv.protected_attributes[2], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3670afae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['31-0.0', '21000-0.0', '21003-0.0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv.protected_attributes # sex, race, age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a7e94be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1319-0.0</th>\n",
       "      <th>1408-0.0</th>\n",
       "      <th>1329-0.0</th>\n",
       "      <th>1448-0.0</th>\n",
       "      <th>1538-0.0</th>\n",
       "      <th>6142-0.0</th>\n",
       "      <th>2050-0.0</th>\n",
       "      <th>1508-0.0</th>\n",
       "      <th>1339-0.0</th>\n",
       "      <th>30710-0.0</th>\n",
       "      <th>1349-0.0</th>\n",
       "      <th>30750-0.0</th>\n",
       "      <th>1468-0.0</th>\n",
       "      <th>20117-0.0</th>\n",
       "      <th>30740-0.0</th>\n",
       "      <th>1160-0.0</th>\n",
       "      <th>2090-0.0</th>\n",
       "      <th>31-0.0</th>\n",
       "      <th>1488-0.0</th>\n",
       "      <th>30850-0.0</th>\n",
       "      <th>4080-0.0</th>\n",
       "      <th>1369-0.0</th>\n",
       "      <th>21000-0.0</th>\n",
       "      <th>1200-0.0</th>\n",
       "      <th>1289-0.0</th>\n",
       "      <th>30790-0.0</th>\n",
       "      <th>845-0.0</th>\n",
       "      <th>48-0.0</th>\n",
       "      <th>30630-0.0</th>\n",
       "      <th>1299-0.0</th>\n",
       "      <th>1220-0.0</th>\n",
       "      <th>1548-0.0</th>\n",
       "      <th>1528-0.0</th>\n",
       "      <th>23099-0.0</th>\n",
       "      <th>49-0.0</th>\n",
       "      <th>30690-0.0</th>\n",
       "      <th>1389-0.0</th>\n",
       "      <th>2654-0.0</th>\n",
       "      <th>1249-0.0</th>\n",
       "      <th>1309-0.0</th>\n",
       "      <th>1379-0.0</th>\n",
       "      <th>1239-0.0</th>\n",
       "      <th>21003-0.0</th>\n",
       "      <th>30780-0.0</th>\n",
       "      <th>1438-0.0</th>\n",
       "      <th>30870-0.0</th>\n",
       "      <th>1359-0.0</th>\n",
       "      <th>30770-0.0</th>\n",
       "      <th>21001-0.0</th>\n",
       "      <th>1458-0.0</th>\n",
       "      <th>23100-0.0</th>\n",
       "      <th>6138-0.0</th>\n",
       "      <th>1418-0.0</th>\n",
       "      <th>1478-0.0</th>\n",
       "      <th>4079-0.0</th>\n",
       "      <th>30760-0.0</th>\n",
       "      <th>23101-0.0</th>\n",
       "      <th>2100-0.0</th>\n",
       "      <th>1428-0.0</th>\n",
       "      <th>30640-0.0</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>CVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age-binary</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.937</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.622</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.508</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.4035</td>\n",
       "      <td>20.90</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.593</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>35.6</td>\n",
       "      <td>102.0</td>\n",
       "      <td>6.477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.888</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.977</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.339</td>\n",
       "      <td>24.5790</td>\n",
       "      <td>3.86</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.706</td>\n",
       "      <td>45.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.211</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.900</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.052</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>13.088</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.4000</td>\n",
       "      <td>16.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.390</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.47</td>\n",
       "      <td>36.5</td>\n",
       "      <td>113.0</td>\n",
       "      <td>5.512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.520</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.358</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.701</td>\n",
       "      <td>35.0861</td>\n",
       "      <td>7.00</td>\n",
       "      <td>42.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.173</td>\n",
       "      <td>74.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.310</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.515</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.1000</td>\n",
       "      <td>16.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>7.079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.227</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.655</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.693</td>\n",
       "      <td>19.3835</td>\n",
       "      <td>7.00</td>\n",
       "      <td>15.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.490</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.300</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.449</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.675</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43.5620</td>\n",
       "      <td>18.00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.474</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>28.5</td>\n",
       "      <td>117.0</td>\n",
       "      <td>5.028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>3.041</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.108</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.317</td>\n",
       "      <td>35.1281</td>\n",
       "      <td>7.00</td>\n",
       "      <td>31.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.169</td>\n",
       "      <td>79.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.616</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>20.162</td>\n",
       "      <td>178.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.1100</td>\n",
       "      <td>22.38</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>24.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.983</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.523</td>\n",
       "      <td>25.8866</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.053</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1319-0.0  1408-0.0  1329-0.0  1448-0.0  1538-0.0  6142-0.0  \\\n",
       "age-binary                                                               \n",
       "1                0.0       1.0       2.0       3.0       2.0       1.0   \n",
       "1                0.0       3.0       2.0       1.0       0.0       1.0   \n",
       "1                0.0       3.0       3.0       2.0       1.0       2.0   \n",
       "1                3.0       3.0       3.0       3.0       0.0       2.0   \n",
       "0                0.0       3.0       2.0       1.0       0.0       5.0   \n",
       "\n",
       "            2050-0.0  1508-0.0  1339-0.0  30710-0.0  1349-0.0  30750-0.0  \\\n",
       "age-binary                                                                 \n",
       "1                2.0       3.0       2.0       0.34       1.0     34.937   \n",
       "1                1.0       2.0       2.0       3.94       4.0     40.900   \n",
       "1                1.0       2.0       2.0       0.55       1.0     40.000   \n",
       "1                1.0       2.0       2.0       0.45       2.0     37.300   \n",
       "0                2.0       2.0       2.0       0.75       2.0     32.200   \n",
       "\n",
       "            1468-0.0  20117-0.0  30740-0.0  1160-0.0  2090-0.0  31-0.0  \\\n",
       "age-binary                                                               \n",
       "1                3.0        2.0      5.622       7.0       1.0     0.0   \n",
       "1                5.0        2.0      5.052       9.0       0.0     1.0   \n",
       "1                1.0        0.0      5.310       5.0       0.0     0.0   \n",
       "1                4.0        2.0      4.449       7.0       0.0     1.0   \n",
       "0                1.0        2.0      4.616       6.0       0.0     1.0   \n",
       "\n",
       "            1488-0.0  30850-0.0  4080-0.0  1369-0.0  21000-0.0  1200-0.0  \\\n",
       "age-binary                                                                 \n",
       "1               6.00      0.508     110.0       1.0     1001.0       3.0   \n",
       "1               2.00     13.088     166.0       2.0     1001.0       2.0   \n",
       "1               0.00      0.515     132.0       1.0     1001.0       3.0   \n",
       "1               5.00      4.675     178.0       2.0     1001.0       1.0   \n",
       "0               3.04     20.162     178.0       1.0     1001.0       3.0   \n",
       "\n",
       "            1289-0.0  30790-0.0  845-0.0  48-0.0  30630-0.0  1299-0.0  \\\n",
       "age-binary                                                              \n",
       "1                6.0    54.4035    20.90    74.0      1.593      10.0   \n",
       "1                2.0    15.4000    16.00   120.0      1.390       2.0   \n",
       "1                2.0    32.1000    16.00    66.0      2.005       4.0   \n",
       "1                3.0    43.5620    18.00   110.0      1.474       2.0   \n",
       "0                1.0    71.1100    22.38    94.0      2.149       1.0   \n",
       "\n",
       "            1220-0.0  1548-0.0  1528-0.0  23099-0.0  49-0.0  30690-0.0  \\\n",
       "age-binary                                                               \n",
       "1                0.0       2.0      2.00       35.6   102.0      6.477   \n",
       "1                0.0       2.0      2.47       36.5   113.0      5.512   \n",
       "1                0.0       1.0      1.00       29.5    88.0      7.079   \n",
       "1                0.0       1.0      2.00       28.5   117.0      5.028   \n",
       "0                0.0       2.0      2.00       24.8   100.0      7.958   \n",
       "\n",
       "            1389-0.0  2654-0.0  1249-0.0  1309-0.0  1379-0.0  1239-0.0  \\\n",
       "age-binary                                                               \n",
       "1                1.0       6.0       1.0       2.0       1.0       0.0   \n",
       "1                1.0       7.0       1.0       1.0       2.0       0.0   \n",
       "1                1.0       7.0       3.0       4.0       2.0       0.0   \n",
       "1                0.0       7.0       1.0       1.0       2.0       1.0   \n",
       "0                1.0       7.0       2.0       1.0       1.0       0.0   \n",
       "\n",
       "            21003-0.0  30780-0.0  1438-0.0  30870-0.0  1359-0.0  30770-0.0  \\\n",
       "age-binary                                                                   \n",
       "1                54.0      3.888      10.0      0.977       2.0     26.339   \n",
       "1                65.0      3.520      12.0      2.358       3.0     10.701   \n",
       "1                69.0      4.227       8.0      0.655       2.0     10.693   \n",
       "1                66.0      3.041      10.0      3.108       2.0     25.317   \n",
       "0                48.0      4.983       8.0      1.173       1.0     26.523   \n",
       "\n",
       "            21001-0.0  1458-0.0  23100-0.0  6138-0.0  1418-0.0  1478-0.0  \\\n",
       "age-binary                                                                 \n",
       "1             24.5790      3.86       25.0       1.0       3.0       1.0   \n",
       "1             35.0861      7.00       42.9       3.0       2.0       1.0   \n",
       "1             19.3835      7.00       15.2       3.0       2.0       1.0   \n",
       "1             35.1281      7.00       31.7       3.0       2.0       1.0   \n",
       "0             25.8866      1.00       20.1       1.0       2.0       1.0   \n",
       "\n",
       "            4079-0.0  30760-0.0  23101-0.0  2100-0.0  1428-0.0  30640-0.0  \\\n",
       "age-binary                                                                  \n",
       "1               77.0      1.706       45.2       1.0       0.0      1.211   \n",
       "1               91.0      1.173       74.6       0.0       1.0      1.019   \n",
       "1               67.0      2.490       36.3       0.0       1.0      1.097   \n",
       "1               84.0      1.169       79.6       0.0       3.0      0.923   \n",
       "0               88.0      2.053       61.0       0.0       3.0      1.443   \n",
       "\n",
       "            hypertension  CVD  \n",
       "age-binary                     \n",
       "1                      0    1  \n",
       "1                      1    0  \n",
       "1                      0    0  \n",
       "1                      0    0  \n",
       "0                      0    0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd9cf07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = X1.iloc[:,:-1]\n",
    "y1_train = X1.iloc[:,-1]\n",
    "\n",
    "(X_train, X_test,\n",
    " y_train, y_test) = train_test_split(X1_train, y1_train, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d37b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351736, 61) (150745, 61) (351736,) (150745,)\n",
      "0    319546\n",
      "1     32190\n",
      "Name: CVD, dtype: int64 \n",
      " 0    136805\n",
      "1     13940\n",
      "Name: CVD, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(y_train.value_counts(), '\\n', y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69745439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    191331\n",
      "1    160405\n",
      "Name: sex-binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.index.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88763869",
   "metadata": {},
   "source": [
    "### Evaluate bias in original dataset: Disparate impact ratio\n",
    "\n",
    "#### Interpretation:\n",
    "\n",
    "<ul>\n",
    "    <li> output range=[0,1]</li>\n",
    "    <li> a higher value == more fair related to the given protected attribute</li>\n",
    "    <li> x>0.8 is considered acceptable bias</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f1fa32d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5661578163243346"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.disparate_impact_ratio(X1['CVD'], prot_attr='sex-binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c3db46e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5438220418530659"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.disparate_impact_ratio(X2['CVD'], prot_attr='race-binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "370b7064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31036008621940697"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.disparate_impact_ratio(X3['CVD'], prot_attr='age-binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574f1dbf",
   "metadata": {},
   "source": [
    "> disparate impact ratios indicate that all three investigated protected attributes possess significant bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646fdbc",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8647ec74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `lr` argument is deprecated, use `learning_rate` instead.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('saved_models/mlp_binary_1.h5')\n",
    "model.compile(loss='categorical_hinge',\n",
    "              optimizer=SGD(lr=0.0005),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54831ae6",
   "metadata": {},
   "source": [
    "### functions for evaluating bias of selected protected attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7bcf4cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_protected_attribute(df, label_col):\n",
    "    df = df.copy()\n",
    "    y = df.set_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "332762a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness_report(y_test, y_pred, prot_attr, return_df=True):\n",
    "    fairness_report_dict = {\n",
    "        prot_attr: {\"disparate_impact_ratio\": \n",
    "                        mt.disparate_impact_ratio(y_test, y_pred, prot_attr=prot_attr),\n",
    "                    \"statistical_parity_difference\": \n",
    "                        mt.statistical_parity_difference(y_test, y_pred, prot_attr=prot_attr),\n",
    "                    \"equal_opportunity_difference\": \n",
    "                        mt.equal_opportunity_difference(y_test, y_pred, prot_attr=prot_attr),\n",
    "                    \"average_odds_difference\": \n",
    "                        mt.average_odds_difference(y_test, y_pred, prot_attr=prot_attr),\n",
    "                    \"average odds error\":\n",
    "                        mt.average_odds_error(y_test, y_pred, prot_attr=prot_attr),\n",
    "\n",
    "                   }\n",
    "    }\n",
    "    if return_df:\n",
    "        return pd.DataFrame(fairness_report_dict)\n",
    "    else:\n",
    "        return fairness_report_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6acd89",
   "metadata": {},
   "source": [
    "### Protected Attribute: Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5018009",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_inputs = X1.loc[:,input_cols]\n",
    "privileged_groups = [{'sex-binary': 1}]\n",
    "unprivileged_groups = [{'sex-binary': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "84c9eed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_9\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 105], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_44_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_44\", \"trainable\": true, \"batch_input_shape\": [null, 105], \"dtype\": \"float32\", \"units\": 1000, \"activation\": \"tanh\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_45\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 500, \"activation\": \"tanh\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_46\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 500, \"activation\": \"tanh\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_47\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 200, \"activation\": \"tanh\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_48\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}}'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File('saved_models/mlp_binary_1.h5', 'r')\n",
    "f.attrs.get('model_config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "37ea77dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\anali\\appdata\\roaming\\python\\python38\\site-packages (3.6.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anali\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anali\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anali\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anali\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\anali\\appdata\\roaming\\python\\python38\\site-packages (from h5py) (1.21.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install --user h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc381c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness(df, protected_attribute):\n",
    "\n",
    "    _, _, X_test, _, _, y_test = utilities.process_features(df, 'CVD', RobustScaler(), one_hot=True)\n",
    "    \n",
    "    y_prob = model.predict(X_test)\n",
    "    y_pred = np.where(y_prob > 0.8, 1,0)\n",
    "    \n",
    "    baseline_fairness = fairness_report(y_test, y_pred, prot_attr=protected_attribute)\n",
    "    return baseline_fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6726e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/3141 [==========>...................] - ETA: 9s"
     ]
    }
   ],
   "source": [
    "result = get_fairness(X1, 'sex-binary')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112948b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_fairness(X2, 'race-binary')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_fairness(X3, 'age-binary')\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
