{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c015b538",
   "metadata": {},
   "source": [
    "## Baseline XGBoost Model\n",
    "\n",
    "Tree-based models, specifically gradient boosted decision trees, are generally considered the gold-standard for working with tabular data. While the primary aim of the project is bias mitigation applied to deep-learning it would be dissmisive to not consider model performance against such models for a baseline comparison.\n",
    "\n",
    "Gradient boosting methods inherit values of input features and then execute countless tree models to halt the loss function. It does this by assimilating weak models, then incrementally and iteratively models weighing data, diligently accompanied by an election of a weak model with the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff98064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import utilities\n",
    "import global_variables as gv\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import QuantileTransformer, RobustScaler, StandardScaler,MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e854ba49",
   "metadata": {},
   "source": [
    "### load in data and save DMatrix into a XGBoost binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f77394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first retrieve into pandas dataframe\n",
    "# alternatively:\n",
    "# df = pd.read_csv('CVD_data.csv')\n",
    "df = pd.read_csv(gv.data_link)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb6bcad",
   "metadata": {},
   "source": [
    "### preprocess input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f584511",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = utilities.process_features(df, gv.outcomes[-1], StandardScaler(), one_hot=True, val=False)\n",
    "X_train, y_train= utilities.resample_data(X_train, y_train, 'under')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff1b4c8",
   "metadata": {},
   "source": [
    "### build & save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04606286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=800, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.62      0.71     12898\n",
      "           1       0.37      0.62      0.46      4493\n",
      "\n",
      "    accuracy                           0.62     17391\n",
      "   macro avg       0.60      0.62      0.59     17391\n",
      "weighted avg       0.71      0.62      0.65     17391\n",
      "\n",
      "[[8059 4839]\n",
      " [1690 2803]]\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=800, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.56      0.71     16745\n",
      "           1       0.05      0.55      0.08       646\n",
      "\n",
      "    accuracy                           0.56     17391\n",
      "   macro avg       0.51      0.55      0.40     17391\n",
      "weighted avg       0.94      0.56      0.69     17391\n",
      "\n",
      "[[9374 7371]\n",
      " [ 292  354]]\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=800, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.65      0.60      6940\n",
      "           1       0.74      0.65      0.69     10451\n",
      "\n",
      "    accuracy                           0.65     17391\n",
      "   macro avg       0.64      0.65      0.64     17391\n",
      "weighted avg       0.66      0.65      0.65     17391\n",
      "\n",
      "[[4515 2425]\n",
      " [3664 6787]]\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=800, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.62      0.73     14369\n",
      "           1       0.25      0.59      0.35      3022\n",
      "\n",
      "    accuracy                           0.61     17391\n",
      "   macro avg       0.56      0.61      0.54     17391\n",
      "weighted avg       0.77      0.61      0.66     17391\n",
      "\n",
      "[[8879 5490]\n",
      " [1230 1792]]\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=800, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.64      0.76     15833\n",
      "           1       0.14      0.61      0.23      1558\n",
      "\n",
      "    accuracy                           0.64     17391\n",
      "   macro avg       0.54      0.63      0.50     17391\n",
      "weighted avg       0.87      0.64      0.71     17391\n",
      "\n",
      "[[10108  5725]\n",
      " [  600   958]]\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=800, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.56      0.71     16791\n",
      "           1       0.04      0.55      0.08       600\n",
      "\n",
      "    accuracy                           0.56     17391\n",
      "   macro avg       0.51      0.56      0.40     17391\n",
      "weighted avg       0.94      0.56      0.69     17391\n",
      "\n",
      "[[9471 7320]\n",
      " [ 271  329]]\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=800, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.59      0.72     15748\n",
      "           1       0.13      0.58      0.21      1643\n",
      "\n",
      "    accuracy                           0.59     17391\n",
      "   macro avg       0.53      0.59      0.47     17391\n",
      "weighted avg       0.86      0.59      0.67     17391\n",
      "\n",
      "[[9303 6445]\n",
      " [ 682  961]]\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=800, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...)\n"
     ]
    }
   ],
   "source": [
    "for outcome in gv.outcomes:\n",
    "\n",
    "    X_train, X_test, y_train, y_test = utilities.process_features(df, outcome, StandardScaler(), one_hot=True, val=False)\n",
    "    X_train, y_train= utilities.resample_data(X_train, y_train, 'under')\n",
    "\n",
    "    clf=xgb.XGBClassifier(max_depth=10, learning_rate=0.1, n_estimators=800, objective='binary:logistic', booster='gbtree')\n",
    "\n",
    "    #Printing all the parameters of XGBoost\n",
    "    print(clf)\n",
    "\n",
    "    #Creating the model on Training Data\n",
    "    XGB=clf.fit(X_train,y_train)\n",
    "    prediction=XGB.predict(X_test)\n",
    "\n",
    "    #Measuring accuracy on Testing Data\n",
    "    print(metrics.classification_report(y_test, prediction))\n",
    "    print(metrics.confusion_matrix(y_test, prediction))\n",
    "\n",
    "    #Plotting the feature importance for Top 10 most important columns\n",
    "    %matplotlib inline\n",
    "    feature_importances = pd.Series(XGB.feature_importances_, index=X_train.columns.to_list())\n",
    "    feature_importances.nlargest(10).plot(kind='barh')\n",
    "    plt.title(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b300b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another version\n",
    "\n",
    "xgbc = XGBClassifier(verbose=False).fit(xTrain,yTrain)\n",
    "predict = xgbc.predict(xTest)\n",
    "print(\"==============Results from XGB Classifier before tuning==============\")\n",
    "print(\"Accuracy Score: \", accuracy_score(yTest,predict))\n",
    "R2CV = cross_val_score(xgbc,xTest,yTest,cv=10).mean()\n",
    "print(\"Cross Validation Score: \", R2CV)\n",
    "# 0.84\n",
    "error = mean_squared_error(yTest,predict)\n",
    "print(\"Root Mean Squared Error: \", np.sqrt(error))\n",
    "\n",
    "\n",
    "xgbctuned = XGBClassifier(learning_rate=0.01, max_depth=6, min_samples_split=2,\n",
    "                              n_estimators=100, subsample=0.8).fit(xTrain, yTrain)\n",
    "print(\"==============Results from XGB Classifier after tuning==============\")\n",
    "predicttuned = xgbctuned.predict(xTest)\n",
    "print(\"Accuracy Score: \", accuracy_score(yTest,predicttuned))\n",
    "R2CVtuned = cross_val_score(xgbctuned,xTest,yTest,cv=10).mean()\n",
    "print(\"Cross Validation Score: \", R2CVtuned)\n",
    "# 0.82\n",
    "errortuned = mean_squared_error(yTest,predicttuned)\n",
    "print(\"Root Mean Squared Error: \", np.sqrt(errortuned))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
