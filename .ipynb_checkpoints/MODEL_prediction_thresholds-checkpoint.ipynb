{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18006e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "# Model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.initializers import RandomNormal, Constant\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, QuantileTransformer, RobustScaler, StandardScaler,MinMaxScaler\n",
    "from tensorflow.keras.optimizers  import Adam, Adagrad, SGD, RMSprop\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import fairness_helpers as fh\n",
    "import utilities\n",
    "import global_variables as gv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171bf6e4",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb7e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/binary_full.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61351a49",
   "metadata": {},
   "source": [
    "#### retreive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa423d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('saved_models/mlp_binary_1.h5')\n",
    "model.compile(loss='categorical_hinge', #categorical_hinge\n",
    "              optimizer=SGD(learning_rate=0.0005),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b7a3c3",
   "metadata": {},
   "source": [
    "#### split data and predict probabilities on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f4151bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4711/4711 [==============================] - 44s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.50978285],\n",
       "       [0.5965653 ],\n",
       "       [0.6105521 ],\n",
       "       ...,\n",
       "       [0.5338432 ],\n",
       "       [0.26935902],\n",
       "       [0.5914589 ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,  X_test, _, y_test = utilities.process_features(df, 'CVD', RobustScaler(), one_hot=True, val=False, test_size=0.3 )\n",
    "\n",
    "y_prob = model.predict(X_test) # outputs probablity assigned to Class 1\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69e5e67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5731583]\n",
      "[0.42829001]\n"
     ]
    }
   ],
   "source": [
    "one_count=0\n",
    "zero_count=0\n",
    "one_total=0\n",
    "zero_total=0\n",
    "for i, val in zip(y_test, y_prob):\n",
    "    if i == 1:\n",
    "        one_count+=1\n",
    "        one_total+=val\n",
    "    elif i==0:\n",
    "        zero_count+=1\n",
    "        zero_total+=val\n",
    "\n",
    "print(one_total/one_count)\n",
    "print(zero_total/zero_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9ba1649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5338432], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "386afc37",
   "metadata": {},
   "source": [
    "#### some functions to evaluate model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c2f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_eval(model, X_test, y_test, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Takes in model, testing data, and decision threshold and outputs prediction performance (confusion matrix,\n",
    "    sensitivity, specificity, and accuracy)\n",
    "    \"\"\"\n",
    "    y_predicted = (model.predict(X_test) >= threshold)\n",
    "\n",
    "    conf_mat = confusion_matrix(y_test, y_predicted)\n",
    "    print(conf_mat)\n",
    "    total = sum(sum(conf_mat))\n",
    "    sensitivity = conf_mat[0, 0]/(conf_mat[0, 0] + conf_mat[1, 0])\n",
    "    specificity = conf_mat[1, 1]/(conf_mat[1, 1] + conf_mat[0, 1])\n",
    "    accuracy = (conf_mat[0, 0] + conf_mat[1, 1])/total\n",
    "\n",
    "    print('specificity : ', specificity)\n",
    "    print('sensitivity : ', sensitivity)\n",
    "    print('accuracy : ', accuracy)\n",
    "    return conf_mat, sensitivity, specificity, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42d498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8261cedf",
   "metadata": {},
   "source": [
    "### let's figure out the best threshold to minimize false negatives!\n",
    "\n",
    "> Since this problem is a case of medical diagnostics, we care way more about correctly diagnosing the people who actually have CVDs so that they can get treatment, therefore we are willing to allow a few more false positive cases to ensure the best ultimate health outcomes for everyone. (focus on maximizing Sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde8818e",
   "metadata": {},
   "source": [
    "#### optimal threshold for ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate scores\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39be4af",
   "metadata": {},
   "source": [
    "#### PR Curve: focus on minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b288e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat, spec, sens, acc = confusion_eval(model, X_test, y_test, threshold=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0be663",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_thresholds=np.arange(0,1,0.05)\n",
    "df_results = pd.DataFrame(columns = ['threshold', 'specificity', 'sensitivity', 'accuracy'])\n",
    "for threshold in test_thresholds:\n",
    "    mat, spec, sens, acc = confusion_eval(model, X_test, y_test, threshold=threshold)\n",
    "    \n",
    "    df_new = pd.DataFrame({'threshold':threshold, 'specificity':spec, 'sensitivity':sens, 'accuracy':acc}, index=[0])\n",
    "    df_results = pd.concat([df_results,df_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b853e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a6ca7",
   "metadata": {},
   "source": [
    "#### plot threshold results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d0badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot lines\n",
    "plt.plot(df_results['threshold'], df_results['accuracy'], label = \"accuracy\")\n",
    "plt.plot(df_results['threshold'], df_results['specificity'], label = \"specificity\")\n",
    "plt.plot(df_results['threshold'], df_results['sensitivity'], label = \"sensitivity\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Decision Threshold Optimization')\n",
    "plt.xlabel('Threshold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6371a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
