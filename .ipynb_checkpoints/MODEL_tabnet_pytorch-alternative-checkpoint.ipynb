{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385002dd",
   "metadata": {},
   "source": [
    "## TabNet Implentation for Tabular Data\n",
    "\n",
    "TabNet is proposed in [this article] (https://arxiv.org/abs/1908.07442) as a neural network architecture capable of learning a canonical representation of tabular data. This architecture has shown to perform well against the current gold-standard gradient boosting models for learning on tabular data.\n",
    "\n",
    "TabNet uses a sequential attention mechanism to choose a subset of semantically meaningful\n",
    "features to process at each decision step. Instance-wise feature selection enables efficient learning as the model capacity is fully used for the most salient features, and also yields\n",
    "more interpretable decision making via visualization of selection masks. \n",
    "\n",
    "\n",
    "This implementation closely follows [the TabNet implementation in PyTorch linked here](https://github.com/dreamquark-ai/tabnet/tree/b6e1ebaf694f37ad40a6ba525aa016fd3cec15da). \n",
    "\n",
    "<img src=\"images/tabnet_schematic2.jpg\" width=\"1000\" height=\"800\" align=\"center\"/>\n",
    "\n",
    "\n",
    "#### GLU Block\n",
    "\n",
    "Gated Linear Units act as an attention mechanism where the gates formed involve taking two dense layer outputs, applying a sigmoid to one of them, and then multiplying them together\n",
    "\n",
    "Following GLU blcok contains two dense layers, two ghost batch normalization layers, identity and sigmoid activation functions and multiplication operation.\n",
    "\n",
    "\n",
    "### Feature Transformer Block\n",
    "\n",
    "Builds two GLU blocks with a skip connection from the output of the first\n",
    "\n",
    "<img src=\"images/tabnet_feature_transformer.jpg\" width=\"700\" height=\"500\" align=\"center\"/>\n",
    "\n",
    "#### Attentive Transformer Block\n",
    "\n",
    "Use TabNet prior as an input to layer and reserve to handle prior updates in TabNet step layer\n",
    "\n",
    "> *prior is used to encourage orthogonal feature selection across decision steps, tell us what we know about features and how we have used them in the previous step\n",
    "\n",
    "<img src=\"images/tabnet_attentive_transformer.jpg\" width=\"200\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y-XevvaSe6_T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-XevvaSe6_T",
    "outputId": "8544313a-d02d-485e-cf73-736002fac06b"
   },
   "outputs": [],
   "source": [
    "# ! pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "_hHbyvL7Ub7X",
   "metadata": {
    "id": "_hHbyvL7Ub7X"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import global_variables as gv\n",
    "import utilities\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0f3b0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "5e0f3b0b",
    "outputId": "ee150c2f-7353-4144-8f21-99e54d86cac1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1319-0.0</th>\n",
       "      <th>1408-0.0</th>\n",
       "      <th>1329-0.0</th>\n",
       "      <th>1448-0.0</th>\n",
       "      <th>1538-0.0</th>\n",
       "      <th>6142-0.0</th>\n",
       "      <th>2050-0.0</th>\n",
       "      <th>1508-0.0</th>\n",
       "      <th>1339-0.0</th>\n",
       "      <th>30710-0.0</th>\n",
       "      <th>1349-0.0</th>\n",
       "      <th>30750-0.0</th>\n",
       "      <th>1468-0.0</th>\n",
       "      <th>20117-0.0</th>\n",
       "      <th>30740-0.0</th>\n",
       "      <th>1160-0.0</th>\n",
       "      <th>2090-0.0</th>\n",
       "      <th>31-0.0</th>\n",
       "      <th>1488-0.0</th>\n",
       "      <th>30850-0.0</th>\n",
       "      <th>4080-0.0</th>\n",
       "      <th>1369-0.0</th>\n",
       "      <th>21000-0.0</th>\n",
       "      <th>1200-0.0</th>\n",
       "      <th>1289-0.0</th>\n",
       "      <th>30790-0.0</th>\n",
       "      <th>845-0.0</th>\n",
       "      <th>48-0.0</th>\n",
       "      <th>30630-0.0</th>\n",
       "      <th>1299-0.0</th>\n",
       "      <th>1220-0.0</th>\n",
       "      <th>1548-0.0</th>\n",
       "      <th>1528-0.0</th>\n",
       "      <th>23099-0.0</th>\n",
       "      <th>49-0.0</th>\n",
       "      <th>30690-0.0</th>\n",
       "      <th>1389-0.0</th>\n",
       "      <th>2654-0.0</th>\n",
       "      <th>1249-0.0</th>\n",
       "      <th>1309-0.0</th>\n",
       "      <th>1379-0.0</th>\n",
       "      <th>1239-0.0</th>\n",
       "      <th>21003-0.0</th>\n",
       "      <th>30780-0.0</th>\n",
       "      <th>1438-0.0</th>\n",
       "      <th>30870-0.0</th>\n",
       "      <th>1359-0.0</th>\n",
       "      <th>30770-0.0</th>\n",
       "      <th>21001-0.0</th>\n",
       "      <th>1458-0.0</th>\n",
       "      <th>23100-0.0</th>\n",
       "      <th>6138-0.0</th>\n",
       "      <th>1418-0.0</th>\n",
       "      <th>1478-0.0</th>\n",
       "      <th>4079-0.0</th>\n",
       "      <th>30760-0.0</th>\n",
       "      <th>23101-0.0</th>\n",
       "      <th>2100-0.0</th>\n",
       "      <th>1428-0.0</th>\n",
       "      <th>30640-0.0</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>outcome_cardiomyopathies</th>\n",
       "      <th>outcome_ischemic_heart_disease</th>\n",
       "      <th>outcome_heart_failure</th>\n",
       "      <th>outcome_peripheral_vascular_disease</th>\n",
       "      <th>outcome_cardiac_arrest</th>\n",
       "      <th>outcome_cerebral_infarction</th>\n",
       "      <th>outcome_arrhythmia</th>\n",
       "      <th>outcome_myocardial_infarction</th>\n",
       "      <th>CVD</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>age-binned</th>\n",
       "      <th>race-binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.937</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.622</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.508</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.4035</td>\n",
       "      <td>20.90</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.593</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>35.6</td>\n",
       "      <td>102.0</td>\n",
       "      <td>6.477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.888</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.977</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.339</td>\n",
       "      <td>24.5790</td>\n",
       "      <td>3.86</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.706</td>\n",
       "      <td>45.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>British</td>\n",
       "      <td>50-59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.900</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.052</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>13.088</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.4000</td>\n",
       "      <td>16.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.390</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.47</td>\n",
       "      <td>36.5</td>\n",
       "      <td>113.0</td>\n",
       "      <td>5.512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.520</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.358</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.701</td>\n",
       "      <td>35.0861</td>\n",
       "      <td>7.00</td>\n",
       "      <td>42.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.173</td>\n",
       "      <td>74.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>British</td>\n",
       "      <td>60-69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.310</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.515</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.1000</td>\n",
       "      <td>16.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>7.079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.227</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.655</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.693</td>\n",
       "      <td>19.3835</td>\n",
       "      <td>7.00</td>\n",
       "      <td>15.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.490</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>British</td>\n",
       "      <td>60-69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.300</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.449</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.675</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43.5620</td>\n",
       "      <td>18.00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.474</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>28.5</td>\n",
       "      <td>117.0</td>\n",
       "      <td>5.028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>3.041</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.108</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.317</td>\n",
       "      <td>35.1281</td>\n",
       "      <td>7.00</td>\n",
       "      <td>31.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.169</td>\n",
       "      <td>79.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>British</td>\n",
       "      <td>60-69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.616</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>20.162</td>\n",
       "      <td>178.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.1100</td>\n",
       "      <td>22.38</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>24.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.983</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.523</td>\n",
       "      <td>25.8866</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.053</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>British</td>\n",
       "      <td>40-49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1319-0.0  1408-0.0  1329-0.0  1448-0.0  1538-0.0  6142-0.0  2050-0.0  \\\n",
       "0       0.0       1.0       2.0       3.0       2.0       1.0       2.0   \n",
       "1       0.0       3.0       2.0       1.0       0.0       1.0       1.0   \n",
       "2       0.0       3.0       3.0       2.0       1.0       2.0       1.0   \n",
       "3       3.0       3.0       3.0       3.0       0.0       2.0       1.0   \n",
       "4       0.0       3.0       2.0       1.0       0.0       5.0       2.0   \n",
       "\n",
       "   1508-0.0  1339-0.0  30710-0.0  1349-0.0  30750-0.0  1468-0.0  20117-0.0  \\\n",
       "0       3.0       2.0       0.34       1.0     34.937       3.0        2.0   \n",
       "1       2.0       2.0       3.94       4.0     40.900       5.0        2.0   \n",
       "2       2.0       2.0       0.55       1.0     40.000       1.0        0.0   \n",
       "3       2.0       2.0       0.45       2.0     37.300       4.0        2.0   \n",
       "4       2.0       2.0       0.75       2.0     32.200       1.0        2.0   \n",
       "\n",
       "   30740-0.0  1160-0.0  2090-0.0  31-0.0  1488-0.0  30850-0.0  4080-0.0  \\\n",
       "0      5.622       7.0       1.0     0.0      6.00      0.508     110.0   \n",
       "1      5.052       9.0       0.0     1.0      2.00     13.088     166.0   \n",
       "2      5.310       5.0       0.0     0.0      0.00      0.515     132.0   \n",
       "3      4.449       7.0       0.0     1.0      5.00      4.675     178.0   \n",
       "4      4.616       6.0       0.0     1.0      3.04     20.162     178.0   \n",
       "\n",
       "   1369-0.0  21000-0.0  1200-0.0  1289-0.0  30790-0.0  845-0.0  48-0.0  \\\n",
       "0       1.0     1001.0       3.0       6.0    54.4035    20.90    74.0   \n",
       "1       2.0     1001.0       2.0       2.0    15.4000    16.00   120.0   \n",
       "2       1.0     1001.0       3.0       2.0    32.1000    16.00    66.0   \n",
       "3       2.0     1001.0       1.0       3.0    43.5620    18.00   110.0   \n",
       "4       1.0     1001.0       3.0       1.0    71.1100    22.38    94.0   \n",
       "\n",
       "   30630-0.0  1299-0.0  1220-0.0  1548-0.0  1528-0.0  23099-0.0  49-0.0  \\\n",
       "0      1.593      10.0       0.0       2.0      2.00       35.6   102.0   \n",
       "1      1.390       2.0       0.0       2.0      2.47       36.5   113.0   \n",
       "2      2.005       4.0       0.0       1.0      1.00       29.5    88.0   \n",
       "3      1.474       2.0       0.0       1.0      2.00       28.5   117.0   \n",
       "4      2.149       1.0       0.0       2.0      2.00       24.8   100.0   \n",
       "\n",
       "   30690-0.0  1389-0.0  2654-0.0  1249-0.0  1309-0.0  1379-0.0  1239-0.0  \\\n",
       "0      6.477       1.0       6.0       1.0       2.0       1.0       0.0   \n",
       "1      5.512       1.0       7.0       1.0       1.0       2.0       0.0   \n",
       "2      7.079       1.0       7.0       3.0       4.0       2.0       0.0   \n",
       "3      5.028       0.0       7.0       1.0       1.0       2.0       1.0   \n",
       "4      7.958       1.0       7.0       2.0       1.0       1.0       0.0   \n",
       "\n",
       "   21003-0.0  30780-0.0  1438-0.0  30870-0.0  1359-0.0  30770-0.0  21001-0.0  \\\n",
       "0       54.0      3.888      10.0      0.977       2.0     26.339    24.5790   \n",
       "1       65.0      3.520      12.0      2.358       3.0     10.701    35.0861   \n",
       "2       69.0      4.227       8.0      0.655       2.0     10.693    19.3835   \n",
       "3       66.0      3.041      10.0      3.108       2.0     25.317    35.1281   \n",
       "4       48.0      4.983       8.0      1.173       1.0     26.523    25.8866   \n",
       "\n",
       "   1458-0.0  23100-0.0  6138-0.0  1418-0.0  1478-0.0  4079-0.0  30760-0.0  \\\n",
       "0      3.86       25.0       1.0       3.0       1.0      77.0      1.706   \n",
       "1      7.00       42.9       3.0       2.0       1.0      91.0      1.173   \n",
       "2      7.00       15.2       3.0       2.0       1.0      67.0      2.490   \n",
       "3      7.00       31.7       3.0       2.0       1.0      84.0      1.169   \n",
       "4      1.00       20.1       1.0       2.0       1.0      88.0      2.053   \n",
       "\n",
       "   23101-0.0  2100-0.0  1428-0.0  30640-0.0  hypertension  \\\n",
       "0       45.2       1.0       0.0      1.211             0   \n",
       "1       74.6       0.0       1.0      1.019             1   \n",
       "2       36.3       0.0       1.0      1.097             0   \n",
       "3       79.6       0.0       3.0      0.923             0   \n",
       "4       61.0       0.0       3.0      1.443             0   \n",
       "\n",
       "   outcome_cardiomyopathies  outcome_ischemic_heart_disease  \\\n",
       "0                         0                               0   \n",
       "1                         0                               1   \n",
       "2                         0                               0   \n",
       "3                         0                               0   \n",
       "4                         0                               0   \n",
       "\n",
       "   outcome_heart_failure  outcome_peripheral_vascular_disease  \\\n",
       "0                      0                                    0   \n",
       "1                      0                                    0   \n",
       "2                      0                                    0   \n",
       "3                      0                                    0   \n",
       "4                      0                                    0   \n",
       "\n",
       "   outcome_cardiac_arrest  outcome_cerebral_infarction  outcome_arrhythmia  \\\n",
       "0                       0                            0                   1   \n",
       "1                       0                            0                   0   \n",
       "2                       0                            0                   0   \n",
       "3                       0                            0                   0   \n",
       "4                       0                            0                   0   \n",
       "\n",
       "   outcome_myocardial_infarction  CVD   age     sex     race age-binned  \\\n",
       "0                              0    1  54.0  Female  British      50-59   \n",
       "1                              1    0  65.0    Male  British      60-69   \n",
       "2                              0    0  69.0  Female  British      60-69   \n",
       "3                              0    0  66.0    Male  British      60-69   \n",
       "4                              0    0  48.0    Male  British      40-49   \n",
       "\n",
       "   race-binary  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/binary_full.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iiRxbosArp5N",
   "metadata": {
    "id": "iiRxbosArp5N"
   },
   "source": [
    "### Test TabNet Binary Classifier out-of-the-box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2d28ea4",
   "metadata": {
    "id": "c2d28ea4"
   },
   "outputs": [],
   "source": [
    "X_train1, X_val1, X_test1, y_train1, y_val1, y_test1 = utilities.process_features(df, 'CVD', QuantileTransformer(output_distribution='uniform'), one_hot=False)\n",
    "X_train1, y_train1= utilities.resample_data(X_train1, y_train1, 'under')\n",
    "\n",
    "X_train= X_train1.to_numpy()\n",
    "X_val= X_val1.to_numpy()\n",
    "X_test= X_test1.to_numpy()\n",
    "\n",
    "y_train= y_train1.to_numpy().astype(int)\n",
    "y_val= y_val1.to_numpy().astype(int)\n",
    "y_test= y_test1.to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d02a8f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84f128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.metrics import Metric\n",
    "from keras import backend as K\n",
    "class my_recall(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"recall\"\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        return recall_score(y_true, y_score[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9469f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b9469f1",
    "outputId": "68a9b50c-5aa6-4aaa-dd91-8bd3cc426dda",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "epoch 0  | loss: 0.66278 | val_0_auc: 0.64648 |  0:00:06s\n",
      "epoch 1  | loss: 0.6183  | val_0_auc: 0.73342 |  0:00:12s\n",
      "epoch 2  | loss: 0.60876 | val_0_auc: 0.74582 |  0:00:20s\n",
      "epoch 3  | loss: 0.60321 | val_0_auc: 0.74949 |  0:00:32s\n",
      "epoch 4  | loss: 0.60173 | val_0_auc: 0.75144 |  0:00:44s\n",
      "epoch 5  | loss: 0.6005  | val_0_auc: 0.7524  |  0:00:56s\n",
      "epoch 6  | loss: 0.60022 | val_0_auc: 0.75121 |  0:01:07s\n",
      "epoch 7  | loss: 0.5978  | val_0_auc: 0.75484 |  0:01:15s\n",
      "epoch 8  | loss: 0.59646 | val_0_auc: 0.75618 |  0:01:27s\n",
      "epoch 9  | loss: 0.59456 | val_0_auc: 0.75749 |  0:01:46s\n",
      "epoch 10 | loss: 0.59514 | val_0_auc: 0.75817 |  0:02:01s\n",
      "epoch 11 | loss: 0.59413 | val_0_auc: 0.75811 |  0:02:19s\n",
      "epoch 12 | loss: 0.59247 | val_0_auc: 0.75906 |  0:02:40s\n",
      "epoch 13 | loss: 0.59245 | val_0_auc: 0.75998 |  0:02:55s\n",
      "epoch 14 | loss: 0.59081 | val_0_auc: 0.76018 |  0:03:11s\n",
      "epoch 15 | loss: 0.58964 | val_0_auc: 0.7603  |  0:03:24s\n",
      "epoch 16 | loss: 0.5893  | val_0_auc: 0.75995 |  0:03:42s\n",
      "epoch 17 | loss: 0.58914 | val_0_auc: 0.76061 |  0:03:57s\n",
      "epoch 18 | loss: 0.5888  | val_0_auc: 0.76078 |  0:04:10s\n",
      "epoch 19 | loss: 0.58886 | val_0_auc: 0.76119 |  0:04:23s\n",
      "epoch 20 | loss: 0.5897  | val_0_auc: 0.76152 |  0:04:33s\n",
      "epoch 21 | loss: 0.59271 | val_0_auc: 0.75521 |  0:04:49s\n",
      "epoch 22 | loss: 0.5949  | val_0_auc: 0.7595  |  0:05:07s\n",
      "epoch 23 | loss: 0.59241 | val_0_auc: 0.76227 |  0:05:22s\n",
      "epoch 24 | loss: 0.59221 | val_0_auc: 0.76044 |  0:05:34s\n",
      "epoch 25 | loss: 0.59025 | val_0_auc: 0.76281 |  0:05:45s\n",
      "epoch 26 | loss: 0.59027 | val_0_auc: 0.76281 |  0:05:55s\n",
      "epoch 27 | loss: 0.58998 | val_0_auc: 0.76361 |  0:06:04s\n",
      "epoch 28 | loss: 0.59022 | val_0_auc: 0.76201 |  0:06:15s\n",
      "epoch 29 | loss: 0.58969 | val_0_auc: 0.76301 |  0:06:28s\n",
      "epoch 30 | loss: 0.5893  | val_0_auc: 0.76235 |  0:06:42s\n",
      "epoch 31 | loss: 0.58916 | val_0_auc: 0.76321 |  0:06:53s\n",
      "epoch 32 | loss: 0.58872 | val_0_auc: 0.76401 |  0:07:05s\n",
      "epoch 33 | loss: 0.58774 | val_0_auc: 0.76385 |  0:07:18s\n",
      "epoch 34 | loss: 0.58734 | val_0_auc: 0.76348 |  0:07:30s\n",
      "epoch 35 | loss: 0.58788 | val_0_auc: 0.76411 |  0:07:39s\n",
      "epoch 36 | loss: 0.58718 | val_0_auc: 0.76342 |  0:07:48s\n",
      "epoch 37 | loss: 0.58738 | val_0_auc: 0.76337 |  0:07:58s\n",
      "epoch 38 | loss: 0.58646 | val_0_auc: 0.7641  |  0:08:07s\n",
      "epoch 39 | loss: 0.58589 | val_0_auc: 0.76506 |  0:08:16s\n",
      "epoch 40 | loss: 0.58585 | val_0_auc: 0.76432 |  0:08:28s\n",
      "epoch 41 | loss: 0.58526 | val_0_auc: 0.76467 |  0:08:38s\n",
      "epoch 42 | loss: 0.58518 | val_0_auc: 0.76509 |  0:08:47s\n",
      "epoch 43 | loss: 0.58486 | val_0_auc: 0.76483 |  0:08:57s\n",
      "epoch 44 | loss: 0.58483 | val_0_auc: 0.76411 |  0:09:07s\n",
      "epoch 45 | loss: 0.58623 | val_0_auc: 0.76269 |  0:09:16s\n",
      "epoch 46 | loss: 0.58546 | val_0_auc: 0.76477 |  0:09:25s\n",
      "epoch 47 | loss: 0.58493 | val_0_auc: 0.76538 |  0:09:35s\n",
      "epoch 48 | loss: 0.58368 | val_0_auc: 0.76491 |  0:09:46s\n",
      "epoch 49 | loss: 0.58411 | val_0_auc: 0.76566 |  0:09:56s\n",
      "epoch 50 | loss: 0.58387 | val_0_auc: 0.7642  |  0:10:05s\n",
      "epoch 51 | loss: 0.5829  | val_0_auc: 0.76585 |  0:10:17s\n",
      "epoch 52 | loss: 0.58256 | val_0_auc: 0.76552 |  0:10:28s\n",
      "epoch 53 | loss: 0.5819  | val_0_auc: 0.7647  |  0:10:40s\n",
      "epoch 54 | loss: 0.58265 | val_0_auc: 0.76403 |  0:10:50s\n",
      "epoch 55 | loss: 0.58237 | val_0_auc: 0.76533 |  0:11:00s\n",
      "epoch 56 | loss: 0.58165 | val_0_auc: 0.76544 |  0:11:10s\n",
      "epoch 57 | loss: 0.58057 | val_0_auc: 0.76385 |  0:11:22s\n",
      "epoch 58 | loss: 0.58039 | val_0_auc: 0.76527 |  0:11:34s\n",
      "epoch 59 | loss: 0.57954 | val_0_auc: 0.76404 |  0:11:44s\n",
      "epoch 60 | loss: 0.57948 | val_0_auc: 0.76262 |  0:11:56s\n",
      "epoch 61 | loss: 0.57914 | val_0_auc: 0.76448 |  0:12:11s\n",
      "\n",
      "Early stopping occured at epoch 61 with best_epoch = 51 and best_val_0_auc = 0.76585\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "clf = TabNetClassifier()  \n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train,\n",
    "  eval_set=[(X_val, y_val)],\n",
    "  eval_metric=[\"auc\"]\n",
    ")\n",
    "\n",
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a96fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    456351\n",
       "1     46130\n",
       "Name: CVD, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CVD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "IJSsVVNmUEmR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "IJSsVVNmUEmR",
    "outputId": "526bce84-c3c0-4716-dd1e-2406bbcd5903"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "plt.plot(clf.history['loss'])\n",
    "plt.title('Basic TabNet Loss CVD')\n",
    "plt.savefig('charts/models/TabNet/basic_loss.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b6c65",
   "metadata": {},
   "source": [
    "### Global Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ouDy6aHNUHL5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "ouDy6aHNUHL5",
    "outputId": "74754b86-04fe-420b-bdf1-4626a3540228",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_weights = clf.feature_importances_\n",
    "\n",
    "# zip to feature names\n",
    "input_cols = X_train1.columns.to_list()\n",
    "feat_dict = dict(zip(input_cols, feat_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16d6c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_d = dict( sorted(feat_dict.items(), key=operator.itemgetter(1),reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "028551da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Contritbuting Features : \n",
      "['hypertension', 'age', 'whole body fat-free mass', 'employment status', 'Sex', 'ethnic background']\n"
     ]
    }
   ],
   "source": [
    "top = dict()\n",
    "# Iterate over all the items in dictionary and filter items which has even keys\n",
    "for (key, value) in sorted_d.items():\n",
    "   # Check if key is even then add pair to new dictionary\n",
    "   if value >= 0.01:\n",
    "        top[key] = value\n",
    "print('Top Contritbuting Features : ')\n",
    "replaced_list = [x if x not in gv.input_mapping else gv.input_mapping[x] for x in list(top.keys()) ]\n",
    "print(replaced_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9b98971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-contritbuting Features : \n",
      "['dried fruit intake', 'cheese intake', 'oily fish intake', 'major dietary changes in the last 5 years', 'freq depressed mood past 2 weeks', 'coffee type', 'non-oily fish intake', 'processed meat intake', 'HbA1c', 'cereal type', 'doctor anxiety or depression', 'tea intake', 'systolic blood pressure', 'beef intake', 'cooked veg intake', 'LP-a', 'waist circumference', 'raw veg intake', 'variation in diet', 'water intake', 'body fat percentage', 'hip circumference', 'cholesterol', 'non-butter spread', 'past tobacco smoking', 'fresh fruit intake', 'current tobacco smoking', 'bread intake', 'triglyceride', 'poultry intake', 'BMI', 'cereal intake', 'whole body fat mass', 'Qualifications', 'milk type', 'HDL', 'psychologist anxiety or depression', 'spread type', 'APOB']\n"
     ]
    }
   ],
   "source": [
    "no_contribution = dict()\n",
    "# Iterate over all the items in dictionary and filter items which has even keys\n",
    "for (key, value) in sorted_d.items():\n",
    "   # Check if key is even then add pair to new dictionary\n",
    "   if value ==0:\n",
    "        no_contribution[key] = value\n",
    "print('Non-contritbuting Features : ')\n",
    "replaced_list2 = [x if x not in gv.input_mapping else gv.input_mapping[x] for x in list(no_contribution.keys()) ]\n",
    "print(replaced_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ea0bc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replaced_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "beff9d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lists = sorted(feat_dict.items()) # sorted by key, return a list of tuples\n",
    "\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n",
    "frame1 = plt.gca()\n",
    "plt.plot(x, y)\n",
    "plt.title('Global Feature Importances')\n",
    "frame1.axes.xaxis.set_ticklabels([])\n",
    "plt.show()\n",
    "plt.savefig('charts/models/TabNet/basic_global_features.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2062bd0",
   "metadata": {},
   "source": [
    "### Local Explainablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "TIcvwljsVTHq",
   "metadata": {
    "id": "TIcvwljsVTHq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7500657793674272"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict_proba(X_test)\n",
    "test_auc = roc_auc_score(y_score=preds[:,1], y_true=y_test)\n",
    "test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "83892756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "explain_matrix, masks = clf.explain(X_test)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20,20))\n",
    "\n",
    "for i in range(3):\n",
    "    axs[i].imshow(masks[i][:50])\n",
    "    axs[i].set_title(f\"mask {i}\")\n",
    "\n",
    "plt.savefig('charts/models/TabNet/basic_masks.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LumhsZwC5P3j",
   "metadata": {
    "id": "LumhsZwC5P3j"
   },
   "source": [
    "## Customize Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XryRDsqFpr0s",
   "metadata": {
    "id": "XryRDsqFpr0s"
   },
   "source": [
    "#### Fit parameters\n",
    "\n",
    "<ul>\n",
    "  <li> <b>X_train</b> (np.array): Training Features </li>\n",
    "  <li> <b>y_train</b> (np.array): Training Targets </li>\n",
    "  <li> <b>eval_set</b> (list of eval tuple set):  last one used for early stopping </li>\n",
    "  <li> <b>eval_name</b> (list of str): list of eval set names </li>\n",
    "  <li> <b>eval_metric</b> (list of str: list of evaluation metrics; last used for early stopping </li>\n",
    "  <li> <b>max_epochs</b> (int=200): max epochs for training</li>\n",
    "  <li> <b>patience</b> (int=10):#epochs before early stopping, if 0 then no early stopping performed </li>\n",
    "  <li> <b>weights</b> (int or dict=0): only for TabNetClassifier, sampling param 0 => no sampling, param 0 => automated sampling with inverse class occurences </li>\n",
    "  <li> <b>loss_fn</b>(torch.loss): loss fn for training, w classification can set a list of same length as num tasks  </li>\n",
    "  <li> <b>batch_size</b> (int=1024): #  examples/batch </li>\n",
    "  <li> <b>virtual_batch_size</b> (int=128): size of mini batches for ghost batch normalization  </li>\n",
    "  <li> <b>num_workers</b> (int=0): # workers used in torch.utils.data.Dataloader  </li>\n",
    "  <li> <b>drop_last</b> (bool=False): whether to drop last batch if not complete during training  </li>\n",
    "  <li> <b>callbacks</b> (list of callback fn): list of custom callbacks </li>\n",
    "  <li> <b>pretraining_ratio</b> (float): %input features to mask during pretraining  </li>\n",
    "  <li> <b>warm_start</b> (bool=False): allows to fit twice the same model and start from a warm start  </li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [utilities.recall_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QlQWw4np5ufx",
   "metadata": {
    "id": "QlQWw4np5ufx"
   },
   "outputs": [],
   "source": [
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_cols]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "PO6tgvAF5XHN",
   "metadata": {
    "id": "PO6tgvAF5XHN"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cat_idxs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2516/2765615936.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m tabnet_params = {\"cat_idxs\":cat_idxs, # list of categorical feature indices\n\u001b[0m\u001b[0;32m      2\u001b[0m                  \u001b[1;34m\"cat_dims\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcat_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# list of categorical features number of modalities (#unique values for a categorical feature)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                  \u001b[1;34m\"cat_emb_dim\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# list of embeddings size for each categorical features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                  \u001b[1;34m\"optimizer_fn\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# pytorch optimizer function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                  \u001b[1;34m\"optimizer_params\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2e-2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# parameters compatible with optimizer_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cat_idxs' is not defined"
     ]
    }
   ],
   "source": [
    "tabnet_params = {\"cat_idxs\":cat_idxs, # list of categorical feature indices\n",
    "                 \"cat_dims\":cat_dims, # list of categorical features number of modalities (#unique values for a categorical feature)\n",
    "                 \"cat_emb_dim\":1, # list of embeddings size for each categorical features\n",
    "                 \"optimizer_fn\":torch.optim.Adam, # pytorch optimizer function\n",
    "                 \"optimizer_params\":dict(lr=2e-2), # parameters compatible with optimizer_fn\n",
    "                 \"scheduler_params\":{\"step_size\":50, # how to use learning rate scheduler\n",
    "                                 \"gamma\":0.9}, # dictionary of parameters to apply to the scheduler\n",
    "                 \"scheduler_fn\":torch.optim.lr_scheduler.StepLR,\n",
    "                 \"mask_type\":'entmax' # \"sparsemax\" # either sparsemax or entmac, masking fn for selecting features\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1729ffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.metrics import Metric\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# custom metrics\n",
    "class Recall(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"recall\"\n",
    "        self._maximize = True\n",
    "        \n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return recall_score(y_true, y_pred[:,1])\n",
    "    \n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / predicted_positives \n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "428ed33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "clf = TabNetClassifier(\n",
    "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    scheduler_params={\"mode\":'max', # max because default eval metric for binary is AUC\n",
    "                 \"factor\":0.1,\n",
    "                 \"patience\":1}\n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "473852a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No early stopping will be performed, last training weights will be used.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute AddV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2516/3849445721.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m clf.fit(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0meval_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_tabnet\\abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;31m# Apply predict epoch to all eval sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;31m# Call method on_epoch_end for all callbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_tabnet\\abstract_model.py\u001b[0m in \u001b[0;36m_predict_epoch\u001b[1;34m(self, name, loader)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_y_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_y_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m         \u001b[0mmetrics_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metric_container_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_tabnet\\metrics.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m    140\u001b[0m                 )\n\u001b[0;32m    141\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m             \u001b[0mlogs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2516/78531615.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mtrue_positives\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mpossible_positives\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrue_positives\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpossible_positives\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7163\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7164\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    eval_name=['train', 'val'],\n",
    "    eval_metric=[\"auc\", 'accuracy', Recall],\n",
    "    max_epochs=100 , patience=0,\n",
    "    batch_size=400,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a0a48c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7421a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KSF99rpmt5L1",
   "metadata": {
    "id": "KSF99rpmt5L1"
   },
   "outputs": [],
   "source": [
    "# BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AtEemh_pcdHR",
   "metadata": {
    "id": "AtEemh_pcdHR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fmeP4DRTuHnN",
   "metadata": {
    "id": "fmeP4DRTuHnN"
   },
   "source": [
    "### Save & Load TabNet Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CdyC7g9ruJ6P",
   "metadata": {
    "id": "CdyC7g9ruJ6P"
   },
   "outputs": [],
   "source": [
    "# save tabnet model\n",
    "saving_path_name = \"./tabnet_model_test_1\"\n",
    "saved_filepath = clf.save_model(saving_path_name)\n",
    "\n",
    "# define new model with basic parameters and load state dict weights\n",
    "loaded_clf = TabNetClassifier()\n",
    "loaded_clf.load_model(saved_filepath)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "MODEL_tabnet_pytorch.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
