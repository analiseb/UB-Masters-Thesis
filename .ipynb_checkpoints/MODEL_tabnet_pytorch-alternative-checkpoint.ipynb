{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385002dd",
   "metadata": {},
   "source": [
    "## TabNet Implentation for Tabular Data\n",
    "\n",
    "TabNet is proposed in [this article] (https://arxiv.org/abs/1908.07442) as a neural network architecture capable of learning a canonical representation of tabular data. This architecture has shown to perform well against the current gold-standard gradient boosting models for learning on tabular data.\n",
    "\n",
    "TabNet uses a sequential attention mechanism to choose a subset of semantically meaningful\n",
    "features to process at each decision step. Instance-wise feature selection enables efficient learning as the model capacity is fully used for the most salient features, and also yields\n",
    "more interpretable decision making via visualization of selection masks. \n",
    "\n",
    "\n",
    "This implementation closely follows [the TabNet implementation in PyTorch linked here](https://github.com/dreamquark-ai/tabnet/tree/b6e1ebaf694f37ad40a6ba525aa016fd3cec15da). \n",
    "\n",
    "<img src=\"images/tabnet_schematic2.jpg\" width=\"1000\" height=\"800\" align=\"center\"/>\n",
    "\n",
    "\n",
    "#### GLU Block\n",
    "\n",
    "Gated Linear Units act as an attention mechanism where the gates formed involve taking two dense layer outputs, applying a sigmoid to one of them, and then multiplying them together\n",
    "\n",
    "Following GLU blcok contains two dense layers, two ghost batch normalization layers, identity and sigmoid activation functions and multiplication operation.\n",
    "\n",
    "\n",
    "### Feature Transformer Block\n",
    "\n",
    "Builds two GLU blocks with a skip connection from the output of the first\n",
    "\n",
    "<img src=\"images/tabnet_feature_transformer.jpg\" width=\"700\" height=\"500\" align=\"center\"/>\n",
    "\n",
    "#### Attentive Transformer Block\n",
    "\n",
    "Use TabNet prior as an input to layer and reserve to handle prior updates in TabNet step layer\n",
    "\n",
    "> *prior is used to encourage orthogonal feature selection across decision steps, tell us what we know about features and how we have used them in the previous step\n",
    "\n",
    "<img src=\"images/tabnet_attentive_transformer.jpg\" width=\"200\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y-XevvaSe6_T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-XevvaSe6_T",
    "outputId": "8544313a-d02d-485e-cf73-736002fac06b"
   },
   "outputs": [],
   "source": [
    "# ! pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "_hHbyvL7Ub7X",
   "metadata": {
    "id": "_hHbyvL7Ub7X"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import global_variables as gv\n",
    "import utilities\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0f3b0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "5e0f3b0b",
    "outputId": "ee150c2f-7353-4144-8f21-99e54d86cac1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1319-0.0</th>\n",
       "      <th>1408-0.0</th>\n",
       "      <th>1329-0.0</th>\n",
       "      <th>1448-0.0</th>\n",
       "      <th>1538-0.0</th>\n",
       "      <th>6142-0.0</th>\n",
       "      <th>2050-0.0</th>\n",
       "      <th>1508-0.0</th>\n",
       "      <th>1339-0.0</th>\n",
       "      <th>30710-0.0</th>\n",
       "      <th>1349-0.0</th>\n",
       "      <th>30750-0.0</th>\n",
       "      <th>1468-0.0</th>\n",
       "      <th>20117-0.0</th>\n",
       "      <th>30740-0.0</th>\n",
       "      <th>1160-0.0</th>\n",
       "      <th>2090-0.0</th>\n",
       "      <th>31-0.0</th>\n",
       "      <th>1488-0.0</th>\n",
       "      <th>30850-0.0</th>\n",
       "      <th>4080-0.0</th>\n",
       "      <th>1369-0.0</th>\n",
       "      <th>21000-0.0</th>\n",
       "      <th>1200-0.0</th>\n",
       "      <th>1289-0.0</th>\n",
       "      <th>30790-0.0</th>\n",
       "      <th>845-0.0</th>\n",
       "      <th>48-0.0</th>\n",
       "      <th>30630-0.0</th>\n",
       "      <th>1299-0.0</th>\n",
       "      <th>1220-0.0</th>\n",
       "      <th>1548-0.0</th>\n",
       "      <th>1528-0.0</th>\n",
       "      <th>23099-0.0</th>\n",
       "      <th>49-0.0</th>\n",
       "      <th>30690-0.0</th>\n",
       "      <th>1389-0.0</th>\n",
       "      <th>2654-0.0</th>\n",
       "      <th>1249-0.0</th>\n",
       "      <th>1309-0.0</th>\n",
       "      <th>1379-0.0</th>\n",
       "      <th>1239-0.0</th>\n",
       "      <th>21003-0.0</th>\n",
       "      <th>30780-0.0</th>\n",
       "      <th>1438-0.0</th>\n",
       "      <th>30870-0.0</th>\n",
       "      <th>1359-0.0</th>\n",
       "      <th>30770-0.0</th>\n",
       "      <th>21001-0.0</th>\n",
       "      <th>1458-0.0</th>\n",
       "      <th>23100-0.0</th>\n",
       "      <th>6138-0.0</th>\n",
       "      <th>1418-0.0</th>\n",
       "      <th>1478-0.0</th>\n",
       "      <th>4079-0.0</th>\n",
       "      <th>30760-0.0</th>\n",
       "      <th>23101-0.0</th>\n",
       "      <th>2100-0.0</th>\n",
       "      <th>1428-0.0</th>\n",
       "      <th>30640-0.0</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>outcome_cardiomyopathies</th>\n",
       "      <th>outcome_ischemic_heart_disease</th>\n",
       "      <th>outcome_heart_failure</th>\n",
       "      <th>outcome_peripheral_vascular_disease</th>\n",
       "      <th>outcome_cardiac_arrest</th>\n",
       "      <th>outcome_cerebral_infarction</th>\n",
       "      <th>outcome_arrhythmia</th>\n",
       "      <th>outcome_myocardial_infarction</th>\n",
       "      <th>CVD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.937</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.622</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.508</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.4035</td>\n",
       "      <td>20.90</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.593</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>35.6</td>\n",
       "      <td>102.0</td>\n",
       "      <td>6.477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.888</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.977</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.339</td>\n",
       "      <td>24.5790</td>\n",
       "      <td>3.86</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.706</td>\n",
       "      <td>45.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.900</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.052</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>13.088</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.4000</td>\n",
       "      <td>16.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.390</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.47</td>\n",
       "      <td>36.5</td>\n",
       "      <td>113.0</td>\n",
       "      <td>5.512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.520</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.358</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.701</td>\n",
       "      <td>35.0861</td>\n",
       "      <td>7.00</td>\n",
       "      <td>42.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.173</td>\n",
       "      <td>74.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.310</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.515</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.1000</td>\n",
       "      <td>16.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>7.079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.227</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.655</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.693</td>\n",
       "      <td>19.3835</td>\n",
       "      <td>7.00</td>\n",
       "      <td>15.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.490</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.300</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.449</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.675</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43.5620</td>\n",
       "      <td>18.00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.474</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>28.5</td>\n",
       "      <td>117.0</td>\n",
       "      <td>5.028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>3.041</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.108</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.317</td>\n",
       "      <td>35.1281</td>\n",
       "      <td>7.00</td>\n",
       "      <td>31.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.169</td>\n",
       "      <td>79.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.616</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>20.162</td>\n",
       "      <td>178.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.1100</td>\n",
       "      <td>22.38</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>24.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.983</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.523</td>\n",
       "      <td>25.8866</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.053</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1319-0.0  1408-0.0  1329-0.0  1448-0.0  1538-0.0  6142-0.0  2050-0.0  \\\n",
       "0       0.0       1.0       2.0       3.0       2.0       1.0       2.0   \n",
       "1       0.0       3.0       2.0       1.0       0.0       1.0       1.0   \n",
       "2       0.0       3.0       3.0       2.0       1.0       2.0       1.0   \n",
       "3       3.0       3.0       3.0       3.0       0.0       2.0       1.0   \n",
       "4       0.0       3.0       2.0       1.0       0.0       5.0       2.0   \n",
       "\n",
       "   1508-0.0  1339-0.0  30710-0.0  1349-0.0  30750-0.0  1468-0.0  20117-0.0  \\\n",
       "0       3.0       2.0       0.34       1.0     34.937       3.0        2.0   \n",
       "1       2.0       2.0       3.94       4.0     40.900       5.0        2.0   \n",
       "2       2.0       2.0       0.55       1.0     40.000       1.0        0.0   \n",
       "3       2.0       2.0       0.45       2.0     37.300       4.0        2.0   \n",
       "4       2.0       2.0       0.75       2.0     32.200       1.0        2.0   \n",
       "\n",
       "   30740-0.0  1160-0.0  2090-0.0  31-0.0  1488-0.0  30850-0.0  4080-0.0  \\\n",
       "0      5.622       7.0       1.0     0.0      6.00      0.508     110.0   \n",
       "1      5.052       9.0       0.0     1.0      2.00     13.088     166.0   \n",
       "2      5.310       5.0       0.0     0.0      0.00      0.515     132.0   \n",
       "3      4.449       7.0       0.0     1.0      5.00      4.675     178.0   \n",
       "4      4.616       6.0       0.0     1.0      3.04     20.162     178.0   \n",
       "\n",
       "   1369-0.0  21000-0.0  1200-0.0  1289-0.0  30790-0.0  845-0.0  48-0.0  \\\n",
       "0       1.0     1001.0       3.0       6.0    54.4035    20.90    74.0   \n",
       "1       2.0     1001.0       2.0       2.0    15.4000    16.00   120.0   \n",
       "2       1.0     1001.0       3.0       2.0    32.1000    16.00    66.0   \n",
       "3       2.0     1001.0       1.0       3.0    43.5620    18.00   110.0   \n",
       "4       1.0     1001.0       3.0       1.0    71.1100    22.38    94.0   \n",
       "\n",
       "   30630-0.0  1299-0.0  1220-0.0  1548-0.0  1528-0.0  23099-0.0  49-0.0  \\\n",
       "0      1.593      10.0       0.0       2.0      2.00       35.6   102.0   \n",
       "1      1.390       2.0       0.0       2.0      2.47       36.5   113.0   \n",
       "2      2.005       4.0       0.0       1.0      1.00       29.5    88.0   \n",
       "3      1.474       2.0       0.0       1.0      2.00       28.5   117.0   \n",
       "4      2.149       1.0       0.0       2.0      2.00       24.8   100.0   \n",
       "\n",
       "   30690-0.0  1389-0.0  2654-0.0  1249-0.0  1309-0.0  1379-0.0  1239-0.0  \\\n",
       "0      6.477       1.0       6.0       1.0       2.0       1.0       0.0   \n",
       "1      5.512       1.0       7.0       1.0       1.0       2.0       0.0   \n",
       "2      7.079       1.0       7.0       3.0       4.0       2.0       0.0   \n",
       "3      5.028       0.0       7.0       1.0       1.0       2.0       1.0   \n",
       "4      7.958       1.0       7.0       2.0       1.0       1.0       0.0   \n",
       "\n",
       "   21003-0.0  30780-0.0  1438-0.0  30870-0.0  1359-0.0  30770-0.0  21001-0.0  \\\n",
       "0       54.0      3.888      10.0      0.977       2.0     26.339    24.5790   \n",
       "1       65.0      3.520      12.0      2.358       3.0     10.701    35.0861   \n",
       "2       69.0      4.227       8.0      0.655       2.0     10.693    19.3835   \n",
       "3       66.0      3.041      10.0      3.108       2.0     25.317    35.1281   \n",
       "4       48.0      4.983       8.0      1.173       1.0     26.523    25.8866   \n",
       "\n",
       "   1458-0.0  23100-0.0  6138-0.0  1418-0.0  1478-0.0  4079-0.0  30760-0.0  \\\n",
       "0      3.86       25.0       1.0       3.0       1.0      77.0      1.706   \n",
       "1      7.00       42.9       3.0       2.0       1.0      91.0      1.173   \n",
       "2      7.00       15.2       3.0       2.0       1.0      67.0      2.490   \n",
       "3      7.00       31.7       3.0       2.0       1.0      84.0      1.169   \n",
       "4      1.00       20.1       1.0       2.0       1.0      88.0      2.053   \n",
       "\n",
       "   23101-0.0  2100-0.0  1428-0.0  30640-0.0  hypertension  \\\n",
       "0       45.2       1.0       0.0      1.211             0   \n",
       "1       74.6       0.0       1.0      1.019             1   \n",
       "2       36.3       0.0       1.0      1.097             0   \n",
       "3       79.6       0.0       3.0      0.923             0   \n",
       "4       61.0       0.0       3.0      1.443             0   \n",
       "\n",
       "   outcome_cardiomyopathies  outcome_ischemic_heart_disease  \\\n",
       "0                         0                               0   \n",
       "1                         0                               1   \n",
       "2                         0                               0   \n",
       "3                         0                               0   \n",
       "4                         0                               0   \n",
       "\n",
       "   outcome_heart_failure  outcome_peripheral_vascular_disease  \\\n",
       "0                      0                                    0   \n",
       "1                      0                                    0   \n",
       "2                      0                                    0   \n",
       "3                      0                                    0   \n",
       "4                      0                                    0   \n",
       "\n",
       "   outcome_cardiac_arrest  outcome_cerebral_infarction  outcome_arrhythmia  \\\n",
       "0                       0                            0                   1   \n",
       "1                       0                            0                   0   \n",
       "2                       0                            0                   0   \n",
       "3                       0                            0                   0   \n",
       "4                       0                            0                   0   \n",
       "\n",
       "   outcome_myocardial_infarction  CVD  \n",
       "0                              0    1  \n",
       "1                              1    0  \n",
       "2                              0    0  \n",
       "3                              0    0  \n",
       "4                              0    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/entire_imputed.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iiRxbosArp5N",
   "metadata": {
    "id": "iiRxbosArp5N"
   },
   "source": [
    "### Test TabNet Binary Classifier out-of-the-box (predicting Ischemic Heart Disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2d28ea4",
   "metadata": {
    "id": "c2d28ea4"
   },
   "outputs": [],
   "source": [
    "X_train1, X_val1, X_test1, y_train1, y_val1, y_test1 = utilities.process_features(df, 'CVD', StandardScaler(), one_hot=False)\n",
    "X_train1, y_train1= utilities.resample_data(X_train1, y_train1, 'under')\n",
    "\n",
    "X_train= X_train1.to_numpy()\n",
    "X_val= X_val1.to_numpy()\n",
    "X_test= X_test1.to_numpy()\n",
    "\n",
    "y_train= y_train1.to_numpy()\n",
    "y_val= y_val1.to_numpy()\n",
    "y_test= y_test1.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84f128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.metrics import Metric\n",
    "from keras import backend as K\n",
    "class my_recall(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"recall\"\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        return recall_score(y_true, y_score[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b9469f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b9469f1",
    "outputId": "68a9b50c-5aa6-4aaa-dd91-8bd3cc426dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "epoch 0  | loss: 0.65793 | val_0_auc: 0.70643 |  0:00:06s\n",
      "epoch 1  | loss: 0.60939 | val_0_auc: 0.74607 |  0:00:12s\n",
      "epoch 2  | loss: 0.60229 | val_0_auc: 0.74914 |  0:00:18s\n",
      "epoch 3  | loss: 0.59971 | val_0_auc: 0.7559  |  0:00:25s\n",
      "epoch 4  | loss: 0.59702 | val_0_auc: 0.75689 |  0:00:31s\n",
      "epoch 5  | loss: 0.59724 | val_0_auc: 0.75719 |  0:00:38s\n",
      "epoch 6  | loss: 0.59738 | val_0_auc: 0.75714 |  0:00:44s\n",
      "epoch 7  | loss: 0.59574 | val_0_auc: 0.75604 |  0:00:50s\n",
      "epoch 8  | loss: 0.59653 | val_0_auc: 0.75653 |  0:00:56s\n",
      "epoch 9  | loss: 0.59542 | val_0_auc: 0.75806 |  0:01:03s\n",
      "epoch 10 | loss: 0.59546 | val_0_auc: 0.75766 |  0:01:08s\n",
      "epoch 11 | loss: 0.59546 | val_0_auc: 0.75845 |  0:01:14s\n",
      "epoch 12 | loss: 0.59478 | val_0_auc: 0.75922 |  0:01:21s\n",
      "epoch 13 | loss: 0.59488 | val_0_auc: 0.75999 |  0:01:28s\n",
      "epoch 14 | loss: 0.59451 | val_0_auc: 0.76046 |  0:01:35s\n",
      "epoch 15 | loss: 0.59383 | val_0_auc: 0.76063 |  0:01:46s\n",
      "epoch 16 | loss: 0.59582 | val_0_auc: 0.75933 |  0:01:55s\n",
      "epoch 17 | loss: 0.5939  | val_0_auc: 0.75995 |  0:02:04s\n",
      "epoch 18 | loss: 0.59409 | val_0_auc: 0.76035 |  0:02:12s\n",
      "epoch 19 | loss: 0.59395 | val_0_auc: 0.75973 |  0:02:19s\n",
      "epoch 20 | loss: 0.59351 | val_0_auc: 0.76056 |  0:02:26s\n",
      "epoch 21 | loss: 0.59427 | val_0_auc: 0.75998 |  0:02:32s\n",
      "epoch 22 | loss: 0.59331 | val_0_auc: 0.75862 |  0:02:39s\n",
      "epoch 23 | loss: 0.5935  | val_0_auc: 0.75784 |  0:02:46s\n",
      "epoch 24 | loss: 0.59322 | val_0_auc: 0.76076 |  0:02:53s\n",
      "epoch 25 | loss: 0.59231 | val_0_auc: 0.7599  |  0:03:00s\n",
      "epoch 26 | loss: 0.59342 | val_0_auc: 0.76003 |  0:03:06s\n",
      "epoch 27 | loss: 0.5935  | val_0_auc: 0.75981 |  0:03:13s\n",
      "epoch 28 | loss: 0.59322 | val_0_auc: 0.75956 |  0:03:20s\n",
      "epoch 29 | loss: 0.59311 | val_0_auc: 0.7601  |  0:03:27s\n",
      "epoch 30 | loss: 0.59401 | val_0_auc: 0.75928 |  0:03:34s\n",
      "epoch 31 | loss: 0.59358 | val_0_auc: 0.76046 |  0:03:41s\n",
      "epoch 32 | loss: 0.59299 | val_0_auc: 0.7602  |  0:03:49s\n",
      "epoch 33 | loss: 0.59293 | val_0_auc: 0.76063 |  0:03:57s\n",
      "epoch 34 | loss: 0.59379 | val_0_auc: 0.7596  |  0:04:03s\n",
      "\n",
      "Early stopping occured at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.76076\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "clf = TabNetClassifier()  \n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train,\n",
    "  eval_set=[(X_val, y_val)],\n",
    "  eval_metric=[\"auc\"]\n",
    ")\n",
    "\n",
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "IJSsVVNmUEmR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "IJSsVVNmUEmR",
    "outputId": "526bce84-c3c0-4716-dd1e-2406bbcd5903"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "plt.plot(clf.history['loss'])\n",
    "plt.title('Basic TabNet Loss CVD')\n",
    "plt.savefig('charts/models/TabNet/basic_loss.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b6c65",
   "metadata": {},
   "source": [
    "### Global Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ouDy6aHNUHL5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "ouDy6aHNUHL5",
    "outputId": "74754b86-04fe-420b-bdf1-4626a3540228",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_weights = clf.feature_importances_\n",
    "\n",
    "# zip to feature names\n",
    "input_cols = X_train1.columns.to_list()\n",
    "feat_dict = dict(zip(input_cols, feat_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7866812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_d = dict( sorted(feat_dict.items(), key=operator.itemgetter(1),reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31188151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Contritbuting Features : \n",
      "['hypertension', 'age', 'whole body fat-free mass', 'employment status', 'Sex', 'ethnic background']\n"
     ]
    }
   ],
   "source": [
    "top = dict()\n",
    "# Iterate over all the items in dictionary and filter items which has even keys\n",
    "for (key, value) in sorted_d.items():\n",
    "   # Check if key is even then add pair to new dictionary\n",
    "   if value >= 0.01:\n",
    "        top[key] = value\n",
    "print('Top Contritbuting Features : ')\n",
    "replaced_list = [x if x not in gv.input_mapping else gv.input_mapping[x] for x in list(top.keys()) ]\n",
    "print(replaced_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8eaf62e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-contritbuting Features : \n",
      "['dried fruit intake', 'cheese intake', 'oily fish intake', 'major dietary changes in the last 5 years', 'freq depressed mood past 2 weeks', 'coffee type', 'non-oily fish intake', 'processed meat intake', 'HbA1c', 'cereal type', 'doctor anxiety or depression', 'tea intake', 'systolic blood pressure', 'beef intake', 'cooked veg intake', 'LP-a', 'waist circumference', 'raw veg intake', 'variation in diet', 'water intake', 'body fat percentage', 'hip circumference', 'cholesterol', 'non-butter spread', 'past tobacco smoking', 'fresh fruit intake', 'current tobacco smoking', 'bread intake', 'triglyceride', 'poultry intake', 'BMI', 'cereal intake', 'whole body fat mass', 'Qualifications', 'milk type', 'HDL', 'psychologist anxiety or depression', 'spread type', 'APOB']\n"
     ]
    }
   ],
   "source": [
    "no_contribution = dict()\n",
    "# Iterate over all the items in dictionary and filter items which has even keys\n",
    "for (key, value) in sorted_d.items():\n",
    "   # Check if key is even then add pair to new dictionary\n",
    "   if value ==0:\n",
    "        no_contribution[key] = value\n",
    "print('Non-contritbuting Features : ')\n",
    "replaced_list2 = [x if x not in gv.input_mapping else gv.input_mapping[x] for x in list(no_contribution.keys()) ]\n",
    "print(replaced_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4388b5d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'xlabels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27312/255482275.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Global Feature Importances'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'xlabels'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lists = sorted(feat_dict.items()) # sorted by key, return a list of tuples\n",
    "\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title('Global Feature Importances')\n",
    "plt.xlabels(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2062bd0",
   "metadata": {},
   "source": [
    "### Local Explainablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b0274d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "TIcvwljsVTHq",
   "metadata": {
    "id": "TIcvwljsVTHq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7109673743008749"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict_proba(X_test)\n",
    "test_auc = roc_auc_score(y_score=preds[:,1], y_true=y_test)\n",
    "test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LumhsZwC5P3j",
   "metadata": {
    "id": "LumhsZwC5P3j"
   },
   "source": [
    "## Customize Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XryRDsqFpr0s",
   "metadata": {
    "id": "XryRDsqFpr0s"
   },
   "source": [
    "#### Fit parameters\n",
    "\n",
    "<ul>\n",
    "  <li> <b>X_train</b> (np.array): Training Features </li>\n",
    "  <li> <b>y_train</b> (np.array): Training Targets </li>\n",
    "  <li> <b>eval_set</b> (list of eval tuple set):  last one used for early stopping </li>\n",
    "  <li> <b>eval_name</b> (list of str): list of eval set names </li>\n",
    "  <li> <b>eval_metric</b> (list of str: list of evaluation metrics; last used for early stopping </li>\n",
    "  <li> <b>max_epochs</b> (int=200): max epochs for training</li>\n",
    "  <li> <b>patience</b> (int=10):#epochs before early stopping, if 0 then no early stopping performed </li>\n",
    "  <li> <b>weights</b> (int or dict=0): only for TabNetClassifier, sampling param 0 => no sampling, param 0 => automated sampling with inverse class occurences </li>\n",
    "  <li> <b>loss_fn</b>(torch.loss): loss fn for training, w classification can set a list of same length as num tasks  </li>\n",
    "  <li> <b>batch_size</b> (int=1024): #  examples/batch </li>\n",
    "  <li> <b>virtual_batch_size</b> (int=128): size of mini batches for ghost batch normalization  </li>\n",
    "  <li> <b>num_workers</b> (int=0): # workers used in torch.utils.data.Dataloader  </li>\n",
    "  <li> <b>drop_last</b> (bool=False): whether to drop last batch if not complete during training  </li>\n",
    "  <li> <b>callbacks</b> (list of callback fn): list of custom callbacks </li>\n",
    "  <li> <b>pretraining_ratio</b> (float): %input features to mask during pretraining  </li>\n",
    "  <li> <b>warm_start</b> (bool=False): allows to fit twice the same model and start from a warm start  </li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [utilities.recall_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QlQWw4np5ufx",
   "metadata": {
    "id": "QlQWw4np5ufx"
   },
   "outputs": [],
   "source": [
    "unused_feat = ['Set']\n",
    "\n",
    "features = [ col for col in train.columns if col not in unused_feat+[target]] \n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PO6tgvAF5XHN",
   "metadata": {
    "id": "PO6tgvAF5XHN"
   },
   "outputs": [],
   "source": [
    "tabnet_params = {\"cat_idxs\":cat_idxs, # list of categorical feature indices\n",
    "                 \"cat_dims\":cat_dims, # list of categorical features number of modalities (#unique values for a categorical feature)\n",
    "                 \"cat_emb_dim\":1, # list of embeddings size for each categorical features\n",
    "                 \"optimizer_fn\":torch.optim.Adam, # pytorch optimizer function\n",
    "                 \"optimizer_params\":dict(lr=2e-2), # parameters compatible with optimizer_fn\n",
    "                 \"scheduler_params\":{\"step_size\":50, # how to use learning rate scheduler\n",
    "                                 \"gamma\":0.9}, # dictionary of parameters to apply to the scheduler\n",
    "                 \"scheduler_fn\":torch.optim.lr_scheduler.StepLR,\n",
    "                 \"mask_type\":'entmax' # \"sparsemax\" # either sparsemax or entmac, masking fn for selecting features\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KSF99rpmt5L1",
   "metadata": {
    "id": "KSF99rpmt5L1"
   },
   "outputs": [],
   "source": [
    "# BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AtEemh_pcdHR",
   "metadata": {
    "id": "AtEemh_pcdHR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "WxTTTOmlr0__",
   "metadata": {
    "id": "WxTTTOmlr0__"
   },
   "source": [
    "### Implement Semi-supervised Pre-training (tbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jMghm70xsycy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "jMghm70xsycy",
    "outputId": "67ebbf4b-fb17-4e92-e08b-a89e17127ddd"
   },
   "outputs": [],
   "source": [
    "# import preprocessed data before imputation\n",
    "df2 = pd.read_csv(gv.tabnet_data)\n",
    "df2.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec6b00",
   "metadata": {
    "id": "12ec6b00"
   },
   "outputs": [],
   "source": [
    "# TabNetPretrainer\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax' # \"sparsemax\"\n",
    ")\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train=X_train,\n",
    "    eval_set=[X_val],\n",
    "    pretraining_ratio=0.8,\n",
    ")\n",
    "\n",
    "clf = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                      \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['auc'],\n",
    "    from_unsupervised=unsupervised_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fmeP4DRTuHnN",
   "metadata": {
    "id": "fmeP4DRTuHnN"
   },
   "source": [
    "### Save & Load TabNet Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CdyC7g9ruJ6P",
   "metadata": {
    "id": "CdyC7g9ruJ6P"
   },
   "outputs": [],
   "source": [
    "# save tabnet model\n",
    "saving_path_name = \"./tabnet_model_test_1\"\n",
    "saved_filepath = clf.save_model(saving_path_name)\n",
    "\n",
    "# define new model with basic parameters and load state dict weights\n",
    "loaded_clf = TabNetClassifier()\n",
    "loaded_clf.load_model(saved_filepath)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "MODEL_tabnet_pytorch.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
