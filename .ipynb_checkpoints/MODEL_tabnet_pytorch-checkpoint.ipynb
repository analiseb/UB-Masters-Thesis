{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385002dd",
   "metadata": {},
   "source": [
    "## TabNet Implentation for Tabular Data\n",
    "\n",
    "TabNet is proposed in [this article] (https://arxiv.org/abs/1908.07442) as a neural network architecture capable of learning a canonical representation of tabular data. This architecture has shown to perform well against the current gold-standard gradient boosting models for learning on tabular data.\n",
    "\n",
    "TabNet uses a sequential attention mechanism to choose a subset of semantically meaningful\n",
    "features to process at each decision step. Instance-wise feature selection enables efficient learning as the model capacity is fully used for the most salient features, and also yields\n",
    "more interpretable decision making via visualization of selection masks. \n",
    "\n",
    "\n",
    "This implementation closely follows [the TabNet implementation in PyTorch linked here](https://github.com/dreamquark-ai/tabnet/tree/b6e1ebaf694f37ad40a6ba525aa016fd3cec15da). \n",
    "\n",
    "<img src=\"images/tabnet_schematic2.jpg\" width=\"1000\" height=\"800\" align=\"center\"/>\n",
    "\n",
    "\n",
    "#### GLU Block\n",
    "\n",
    "Gated Linear Units act as an attention mechanism where the gates formed involve taking two dense layer outputs, applying a sigmoid to one of them, and then multiplying them together\n",
    "\n",
    "Following GLU blcok contains two dense layers, two ghost batch normalization layers, identity and sigmoid activation functions and multiplication operation.\n",
    "\n",
    "\n",
    "### Feature Transformer Block\n",
    "\n",
    "Builds two GLU blocks with a skip connection from the output of the first\n",
    "\n",
    "<img src=\"images/tabnet_feature_transformer.jpg\" width=\"700\" height=\"500\" align=\"center\"/>\n",
    "\n",
    "#### Attentive Transformer Block\n",
    "\n",
    "Use TabNet prior as an input to layer and reserve to handle prior updates in TabNet step layer\n",
    "\n",
    "> *prior is used to encourage orthogonal feature selection across decision steps, tell us what we know about features and how we have used them in the previous step\n",
    "\n",
    "<img src=\"images/tabnet_attentive_transformer.jpg\" width=\"200\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y-XevvaSe6_T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-XevvaSe6_T",
    "outputId": "8544313a-d02d-485e-cf73-736002fac06b"
   },
   "outputs": [],
   "source": [
    "# ! pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "_hHbyvL7Ub7X",
   "metadata": {
    "id": "_hHbyvL7Ub7X"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import global_variables as gv\n",
    "import utilities\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0f3b0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "5e0f3b0b",
    "outputId": "ee150c2f-7353-4144-8f21-99e54d86cac1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>30850-0.0</th>\n",
       "      <th>30780-0.0</th>\n",
       "      <th>30690-0.0</th>\n",
       "      <th>30790-0.0</th>\n",
       "      <th>23101-0.0</th>\n",
       "      <th>23099-0.0</th>\n",
       "      <th>48-0.0</th>\n",
       "      <th>23100-0.0</th>\n",
       "      <th>30710-0.0</th>\n",
       "      <th>30760-0.0</th>\n",
       "      <th>30640-0.0</th>\n",
       "      <th>30750-0.0</th>\n",
       "      <th>49-0.0</th>\n",
       "      <th>30770-0.0</th>\n",
       "      <th>30740-0.0</th>\n",
       "      <th>30630-0.0</th>\n",
       "      <th>30870-0.0</th>\n",
       "      <th>21001-0.0</th>\n",
       "      <th>1488-0.0</th>\n",
       "      <th>4079-0.0</th>\n",
       "      <th>1299-0.0</th>\n",
       "      <th>21003-0.0</th>\n",
       "      <th>1160-0.0</th>\n",
       "      <th>1438-0.0</th>\n",
       "      <th>4080-0.0</th>\n",
       "      <th>1458-0.0</th>\n",
       "      <th>1528-0.0</th>\n",
       "      <th>1319-0.0</th>\n",
       "      <th>845-0.0</th>\n",
       "      <th>1289-0.0</th>\n",
       "      <th>1309-0.0</th>\n",
       "      <th>1418-0.0</th>\n",
       "      <th>1329-0.0</th>\n",
       "      <th>1220-0.0</th>\n",
       "      <th>1428-0.0</th>\n",
       "      <th>1249-0.0</th>\n",
       "      <th>1349-0.0</th>\n",
       "      <th>1369-0.0</th>\n",
       "      <th>20117-0.0</th>\n",
       "      <th>2100-0.0</th>\n",
       "      <th>2654-0.0</th>\n",
       "      <th>1339-0.0</th>\n",
       "      <th>21000-0.0</th>\n",
       "      <th>2050-0.0</th>\n",
       "      <th>1408-0.0</th>\n",
       "      <th>1200-0.0</th>\n",
       "      <th>1538-0.0</th>\n",
       "      <th>31-0.0</th>\n",
       "      <th>6138-0.0</th>\n",
       "      <th>1359-0.0</th>\n",
       "      <th>1389-0.0</th>\n",
       "      <th>1478-0.0</th>\n",
       "      <th>2090-0.0</th>\n",
       "      <th>1508-0.0</th>\n",
       "      <th>1379-0.0</th>\n",
       "      <th>6142-0.0</th>\n",
       "      <th>1468-0.0</th>\n",
       "      <th>1548-0.0</th>\n",
       "      <th>1239-0.0</th>\n",
       "      <th>1448-0.0</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>outcome_cardiomyopathies</th>\n",
       "      <th>outcome_ischemic_heart_disease</th>\n",
       "      <th>outcome_heart_failure</th>\n",
       "      <th>outcome_myocardial_infarction</th>\n",
       "      <th>outcome_peripheral_vascular_disease</th>\n",
       "      <th>outcome_cardiac_arrest</th>\n",
       "      <th>outcome_cerebral_infarction</th>\n",
       "      <th>outcome_arrhythmia</th>\n",
       "      <th>multi-labels</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50800</td>\n",
       "      <td>3.88800</td>\n",
       "      <td>6.47700</td>\n",
       "      <td>65.1984</td>\n",
       "      <td>45.2</td>\n",
       "      <td>35.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.70600</td>\n",
       "      <td>1.21100</td>\n",
       "      <td>35.065</td>\n",
       "      <td>102.0</td>\n",
       "      <td>26.339</td>\n",
       "      <td>5.62200</td>\n",
       "      <td>1.59300</td>\n",
       "      <td>0.97700</td>\n",
       "      <td>24.5790</td>\n",
       "      <td>6.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3.73</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.52</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>54</td>\n",
       "      <td>Female</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.08800</td>\n",
       "      <td>3.52000</td>\n",
       "      <td>5.51200</td>\n",
       "      <td>15.4000</td>\n",
       "      <td>74.6</td>\n",
       "      <td>36.5</td>\n",
       "      <td>120.0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1.17300</td>\n",
       "      <td>1.01900</td>\n",
       "      <td>40.900</td>\n",
       "      <td>113.0</td>\n",
       "      <td>10.701</td>\n",
       "      <td>5.05200</td>\n",
       "      <td>1.39000</td>\n",
       "      <td>2.35800</td>\n",
       "      <td>35.0861</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>65</td>\n",
       "      <td>Male</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.73364</td>\n",
       "      <td>4.10892</td>\n",
       "      <td>6.47949</td>\n",
       "      <td>50.8588</td>\n",
       "      <td>71.7</td>\n",
       "      <td>29.7</td>\n",
       "      <td>112.0</td>\n",
       "      <td>30.3</td>\n",
       "      <td>3.88</td>\n",
       "      <td>1.58546</td>\n",
       "      <td>1.22432</td>\n",
       "      <td>84.100</td>\n",
       "      <td>107.0</td>\n",
       "      <td>18.763</td>\n",
       "      <td>13.71763</td>\n",
       "      <td>1.74423</td>\n",
       "      <td>2.78764</td>\n",
       "      <td>30.7934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 1, 1]</td>\n",
       "      <td>55</td>\n",
       "      <td>Male</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.78800</td>\n",
       "      <td>2.88700</td>\n",
       "      <td>5.56500</td>\n",
       "      <td>56.5183</td>\n",
       "      <td>40.2</td>\n",
       "      <td>29.8</td>\n",
       "      <td>67.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.11500</td>\n",
       "      <td>0.81000</td>\n",
       "      <td>36.400</td>\n",
       "      <td>91.0</td>\n",
       "      <td>31.672</td>\n",
       "      <td>4.82700</td>\n",
       "      <td>1.89100</td>\n",
       "      <td>1.15700</td>\n",
       "      <td>20.7577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>49</td>\n",
       "      <td>Female</td>\n",
       "      <td>Irish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75600</td>\n",
       "      <td>2.67000</td>\n",
       "      <td>4.68000</td>\n",
       "      <td>4.7700</td>\n",
       "      <td>46.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.49300</td>\n",
       "      <td>0.73300</td>\n",
       "      <td>34.200</td>\n",
       "      <td>105.0</td>\n",
       "      <td>42.209</td>\n",
       "      <td>5.06300</td>\n",
       "      <td>1.86900</td>\n",
       "      <td>1.67700</td>\n",
       "      <td>25.9766</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>61</td>\n",
       "      <td>Female</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   30850-0.0  30780-0.0  30690-0.0  30790-0.0  23101-0.0  23099-0.0  48-0.0  \\\n",
       "0    0.50800    3.88800    6.47700    65.1984       45.2       35.6    74.0   \n",
       "1   13.08800    3.52000    5.51200    15.4000       74.6       36.5   120.0   \n",
       "2    9.73364    4.10892    6.47949    50.8588       71.7       29.7   112.0   \n",
       "3    1.78800    2.88700    5.56500    56.5183       40.2       29.8    67.0   \n",
       "4    0.75600    2.67000    4.68000     4.7700       46.5       30.1    85.0   \n",
       "\n",
       "   23100-0.0  30710-0.0  30760-0.0  30640-0.0  30750-0.0  49-0.0  30770-0.0  \\\n",
       "0       25.0       0.34    1.70600    1.21100     35.065   102.0     26.339   \n",
       "1       42.9       3.94    1.17300    1.01900     40.900   113.0     10.701   \n",
       "2       30.3       3.88    1.58546    1.22432     84.100   107.0     18.763   \n",
       "3       17.0       0.87    2.11500    0.81000     36.400    91.0     31.672   \n",
       "4       20.0       0.18    1.49300    0.73300     34.200   105.0     42.209   \n",
       "\n",
       "   30740-0.0  30630-0.0  30870-0.0  21001-0.0  1488-0.0  4079-0.0  1299-0.0  \\\n",
       "0    5.62200    1.59300    0.97700    24.5790       6.0      77.0      10.0   \n",
       "1    5.05200    1.39000    2.35800    35.0861       2.0      91.0       2.0   \n",
       "2   13.71763    1.74423    2.78764    30.7934       0.0      99.0       2.0   \n",
       "3    4.82700    1.89100    1.15700    20.7577       0.0      71.0       5.0   \n",
       "4    5.06300    1.86900    1.67700    25.9766       7.0      73.0       4.0   \n",
       "\n",
       "   21003-0.0  1160-0.0  1438-0.0  4080-0.0  1458-0.0  1528-0.0  1319-0.0  \\\n",
       "0       54.0       7.0      10.0     110.0      3.73       2.0       0.0   \n",
       "1       65.0       9.0      12.0     166.0      7.00       2.4       0.0   \n",
       "2       55.0       7.0      10.0     135.0      7.00       2.0       0.0   \n",
       "3       49.0       8.0      14.0     116.0      5.00       3.0       1.0   \n",
       "4       61.0       7.0       2.0     113.0      7.00       4.0       2.0   \n",
       "\n",
       "   845-0.0  1289-0.0  1309-0.0  1418-0.0  1329-0.0  1220-0.0  1428-0.0  \\\n",
       "0    23.52       6.0       2.0         3         2         0         0   \n",
       "1    16.00       2.0       1.0         2         2         0         1   \n",
       "2    21.00       3.0       1.0         2         1         0         0   \n",
       "3    18.00       5.0       1.0         2         2         0         0   \n",
       "4    16.00       3.0       3.0         3         2         1         1   \n",
       "\n",
       "   1249-0.0  1349-0.0  1369-0.0  20117-0.0  2100-0.0  2654-0.0  1339-0.0  \\\n",
       "0         1         1         1          2         1         6         2   \n",
       "1         1         4         2          2         0         7         2   \n",
       "2         1         2         1          2         0         7         2   \n",
       "3         4         1         2          2         0         7         2   \n",
       "4         4         1         1          2         0         7         3   \n",
       "\n",
       "   21000-0.0  2050-0.0  1408-0.0  1200-0.0  1538-0.0  31-0.0  6138-0.0  \\\n",
       "0          0         2         1         3         2       0         1   \n",
       "1          0         1         3         2         0       1         3   \n",
       "2          0         1         2         2         1       1         3   \n",
       "3          2         1         2         1         2       0         6   \n",
       "4          0         1         3         1         0       0         3   \n",
       "\n",
       "   1359-0.0  1389-0.0  1478-0.0  2090-0.0  1508-0.0  1379-0.0  6142-0.0  \\\n",
       "0         2         1         1         1         3         1         1   \n",
       "1         3         1         1         0         2         2         1   \n",
       "2         3         2         1         0         2         2         1   \n",
       "3         2         2         1         0         2         2         1   \n",
       "4         3         1         2         0         1         1         1   \n",
       "\n",
       "   1468-0.0  1548-0.0  1239-0.0  1448-0.0  hypertension  \\\n",
       "0         3         2         0         3             0   \n",
       "1         5         2         0         1             1   \n",
       "2         4         2         0         3             1   \n",
       "3         3         2         0         3             0   \n",
       "4         4         2         0         3             1   \n",
       "\n",
       "   outcome_cardiomyopathies  outcome_ischemic_heart_disease  \\\n",
       "0                         0                               0   \n",
       "1                         0                               1   \n",
       "2                         0                               1   \n",
       "3                         0                               0   \n",
       "4                         0                               0   \n",
       "\n",
       "   outcome_heart_failure  outcome_myocardial_infarction  \\\n",
       "0                      0                              0   \n",
       "1                      0                              1   \n",
       "2                      0                              0   \n",
       "3                      0                              0   \n",
       "4                      0                              1   \n",
       "\n",
       "   outcome_peripheral_vascular_disease  outcome_cardiac_arrest  \\\n",
       "0                                    0                       0   \n",
       "1                                    0                       0   \n",
       "2                                    0                       1   \n",
       "3                                    0                       0   \n",
       "4                                    0                       0   \n",
       "\n",
       "   outcome_cerebral_infarction  outcome_arrhythmia              multi-labels  \\\n",
       "0                            0                   1  [0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "1                            0                   0  [1, 0, 1, 0, 0, 0, 0, 0]   \n",
       "2                            1                   1  [0, 0, 1, 0, 0, 1, 1, 1]   \n",
       "3                            0                   1  [0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "4                            0                   0  [1, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "   age  gender     race  \n",
       "0   54  Female  British  \n",
       "1   65    Male  British  \n",
       "2   55    Male  British  \n",
       "3   49  Female    Irish  \n",
       "4   61  Female  British  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(gv.data_link)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iiRxbosArp5N",
   "metadata": {
    "id": "iiRxbosArp5N"
   },
   "source": [
    "### Test TabNet Binary Classifier out-of-the-box (predicting Ischemic Heart Disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2d28ea4",
   "metadata": {
    "id": "c2d28ea4"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = utilities.process_features(df, gv.outcomes[2], StandardScaler(), one_hot=True)\n",
    "X_train, y_train= utilities.resample_data(X_train, y_train, 'under')\n",
    "\n",
    "X_train= X_train.to_numpy()\n",
    "X_val= X_val.to_numpy()\n",
    "X_test= X_test.to_numpy()\n",
    "\n",
    "y_train= y_train.to_numpy()\n",
    "y_val= y_val.to_numpy()\n",
    "y_test= y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c177e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.metrics import Metric\n",
    "from keras import backend as K\n",
    "class my_recall(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"recall\"\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        return recall_score(y_true, y_score[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b9469f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b9469f1",
    "outputId": "68a9b50c-5aa6-4aaa-dd91-8bd3cc426dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25952/1928109319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m clf.fit(X_train, y_train,\n\u001b[0m\u001b[0;32m      5\u001b[0m   \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"auc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_recall\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_tabnet\\abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;31m# Apply predict epoch to all eval sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;31m# Call method on_epoch_end for all callbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_tabnet\\abstract_model.py\u001b[0m in \u001b[0;36m_predict_epoch\u001b[1;34m(self, name, loader)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_y_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_y_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m         \u001b[0mmetrics_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metric_container_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_tabnet\\metrics.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m    140\u001b[0m                 )\n\u001b[0;32m    141\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m             \u001b[0mlogs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25952/1314534112.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y_true, y_score)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1899\u001b[0m     \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1900\u001b[0m     \"\"\"\n\u001b[1;32m-> 1901\u001b[1;33m     _, r, _, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[0;32m   1902\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1903\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1544\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"average has to be one of \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "clf = TabNetClassifier()  \n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train,\n",
    "  eval_set=[(X_val, y_val)],\n",
    "  eval_metric=[\"auc\", my_recall]\n",
    ")\n",
    "\n",
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IJSsVVNmUEmR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "IJSsVVNmUEmR",
    "outputId": "526bce84-c3c0-4716-dd1e-2406bbcd5903"
   },
   "outputs": [],
   "source": [
    "# plot losses\n",
    "plt.plot(clf.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ouDy6aHNUHL5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "ouDy6aHNUHL5",
    "outputId": "74754b86-04fe-420b-bdf1-4626a3540228"
   },
   "outputs": [],
   "source": [
    "# plot auc\n",
    "plt.plot(clf.history['train_auc'])\n",
    "plt.plot(clf.history['valid_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TIcvwljsVTHq",
   "metadata": {
    "id": "TIcvwljsVTHq"
   },
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_test)\n",
    "test_auc = roc_auc_score(y_score=preds[:,1], y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3yxUZLzZVmm-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3yxUZLzZVmm-",
    "outputId": "dd0a89c2-0772-45f6-fca6-a7b4051f324b"
   },
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LumhsZwC5P3j",
   "metadata": {
    "id": "LumhsZwC5P3j"
   },
   "source": [
    "## Customize Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XryRDsqFpr0s",
   "metadata": {
    "id": "XryRDsqFpr0s"
   },
   "source": [
    "#### Fit parameters\n",
    "\n",
    "<ul>\n",
    "  <li> <b>X_train</b> (np.array): Training Features </li>\n",
    "  <li> <b>y_train</b> (np.array): Training Targets </li>\n",
    "  <li> <b>eval_set</b> (list of eval tuple set):  last one used for early stopping </li>\n",
    "  <li> <b>eval_name</b> (list of str): list of eval set names </li>\n",
    "  <li> <b>eval_metric</b> (list of str: list of evaluation metrics; last used for early stopping </li>\n",
    "  <li> <b>max_epochs</b> (int=200): max epochs for training</li>\n",
    "  <li> <b>patience</b> (int=10):#epochs before early stopping, if 0 then no early stopping performed </li>\n",
    "  <li> <b>weights</b> (int or dict=0): only for TabNetClassifier, sampling param 0 => no sampling, param 0 => automated sampling with inverse class occurences </li>\n",
    "  <li> <b>loss_fn</b>(torch.loss): loss fn for training, w classification can set a list of same length as num tasks  </li>\n",
    "  <li> <b>batch_size</b> (int=1024): #  examples/batch </li>\n",
    "  <li> <b>virtual_batch_size</b> (int=128): size of mini batches for ghost batch normalization  </li>\n",
    "  <li> <b>num_workers</b> (int=0): # workers used in torch.utils.data.Dataloader  </li>\n",
    "  <li> <b>drop_last</b> (bool=False): whether to drop last batch if not complete during training  </li>\n",
    "  <li> <b>callbacks</b> (list of callback fn): list of custom callbacks </li>\n",
    "  <li> <b>pretraining_ratio</b> (float): %input features to mask during pretraining  </li>\n",
    "  <li> <b>warm_start</b> (bool=False): allows to fit twice the same model and start from a warm start  </li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [utilities.recall_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QlQWw4np5ufx",
   "metadata": {
    "id": "QlQWw4np5ufx"
   },
   "outputs": [],
   "source": [
    "unused_feat = ['Set']\n",
    "\n",
    "features = [ col for col in train.columns if col not in unused_feat+[target]] \n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PO6tgvAF5XHN",
   "metadata": {
    "id": "PO6tgvAF5XHN"
   },
   "outputs": [],
   "source": [
    "tabnet_params = {\"cat_idxs\":cat_idxs, # list of categorical feature indices\n",
    "                 \"cat_dims\":cat_dims, # list of categorical features number of modalities (#unique values for a categorical feature)\n",
    "                 \"cat_emb_dim\":1, # list of embeddings size for each categorical features\n",
    "                 \"optimizer_fn\":torch.optim.Adam, # pytorch optimizer function\n",
    "                 \"optimizer_params\":dict(lr=2e-2), # parameters compatible with optimizer_fn\n",
    "                 \"scheduler_params\":{\"step_size\":50, # how to use learning rate scheduler\n",
    "                                 \"gamma\":0.9}, # dictionary of parameters to apply to the scheduler\n",
    "                 \"scheduler_fn\":torch.optim.lr_scheduler.StepLR,\n",
    "                 \"mask_type\":'entmax' # \"sparsemax\" # either sparsemax or entmac, masking fn for selecting features\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KSF99rpmt5L1",
   "metadata": {
    "id": "KSF99rpmt5L1"
   },
   "outputs": [],
   "source": [
    "# BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AtEemh_pcdHR",
   "metadata": {
    "id": "AtEemh_pcdHR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "WxTTTOmlr0__",
   "metadata": {
    "id": "WxTTTOmlr0__"
   },
   "source": [
    "### Implement Semi-supervised Pre-training (tbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jMghm70xsycy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "jMghm70xsycy",
    "outputId": "67ebbf4b-fb17-4e92-e08b-a89e17127ddd"
   },
   "outputs": [],
   "source": [
    "# import preprocessed data before imputation\n",
    "df2 = pd.read_csv(gv.tabnet_data)\n",
    "df2.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec6b00",
   "metadata": {
    "id": "12ec6b00"
   },
   "outputs": [],
   "source": [
    "# TabNetPretrainer\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax' # \"sparsemax\"\n",
    ")\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train=X_train,\n",
    "    eval_set=[X_val],\n",
    "    pretraining_ratio=0.8,\n",
    ")\n",
    "\n",
    "clf = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                      \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['auc'],\n",
    "    from_unsupervised=unsupervised_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fmeP4DRTuHnN",
   "metadata": {
    "id": "fmeP4DRTuHnN"
   },
   "source": [
    "### Save & Load TabNet Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CdyC7g9ruJ6P",
   "metadata": {
    "id": "CdyC7g9ruJ6P"
   },
   "outputs": [],
   "source": [
    "# save tabnet model\n",
    "saving_path_name = \"./tabnet_model_test_1\"\n",
    "saved_filepath = clf.save_model(saving_path_name)\n",
    "\n",
    "# define new model with basic parameters and load state dict weights\n",
    "loaded_clf = TabNetClassifier()\n",
    "loaded_clf.load_model(saved_filepath)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "MODEL_tabnet_pytorch.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
