{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "9d0f0353",
      "metadata": {
        "id": "9d0f0353"
      },
      "outputs": [],
      "source": [
        "# Importing core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "import pprint\n",
        "import joblib\n",
        "\n",
        "# Model selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "# Data transformation pipelines\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import QuantileTransformer, RobustScaler, StandardScaler,MinMaxScaler\n",
        "\n",
        "# Graphics\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "d88b1262",
      "metadata": {
        "id": "d88b1262"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, PReLU\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Concatenate\n",
        "from tensorflow.keras.optimizers  import Adam, Adagrad, SGD\n",
        "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "440b3c88",
      "metadata": {
        "id": "440b3c88"
      },
      "outputs": [],
      "source": [
        "# Importing from Scikit-Learn\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA, FactorAnalysis\n",
        "\n",
        "from keras.layers import Input, Embedding, Reshape, GlobalAveragePooling1D\n",
        "from keras.layers import Flatten, concatenate, Concatenate, Lambda, Dropout, SpatialDropout1D\n",
        "from keras.layers import Activation, LeakyReLU\n",
        "from keras.models import Model, load_model\n",
        "from keras.losses import binary_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed55b3cd",
      "metadata": {
        "id": "ed55b3cd",
        "outputId": "ff1a7971-259a-4ca7-ddb8-2863b3343ef7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>.container { width:80% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "ce03cbb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "ce03cbb9",
        "outputId": "766532c6-8cf6-4819-f9d6-eb47587b48cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   30850-0.0  30780-0.0  30690-0.0  30790-0.0  23101-0.0  23099-0.0  48-0.0  \\\n",
              "0    0.50800    3.88800    6.47700    65.1984       45.2       35.6    74.0   \n",
              "1   13.08800    3.52000    5.51200    15.4000       74.6       36.5   120.0   \n",
              "2    9.73364    4.10892    6.47949    50.8588       71.7       29.7   112.0   \n",
              "3    1.78800    2.88700    5.56500    56.5183       40.2       29.8    67.0   \n",
              "4    0.75600    2.67000    4.68000     4.7700       46.5       30.1    85.0   \n",
              "\n",
              "   23100-0.0  30710-0.0  30760-0.0  30640-0.0  30750-0.0  49-0.0  30770-0.0  \\\n",
              "0       25.0       0.34    1.70600    1.21100     35.065   102.0     26.339   \n",
              "1       42.9       3.94    1.17300    1.01900     40.900   113.0     10.701   \n",
              "2       30.3       3.88    1.58546    1.22432     84.100   107.0     18.763   \n",
              "3       17.0       0.87    2.11500    0.81000     36.400    91.0     31.672   \n",
              "4       20.0       0.18    1.49300    0.73300     34.200   105.0     42.209   \n",
              "\n",
              "   30740-0.0  30630-0.0  30870-0.0  21001-0.0  1488-0.0  4079-0.0  1299-0.0  \\\n",
              "0    5.62200    1.59300    0.97700    24.5790       6.0      77.0      10.0   \n",
              "1    5.05200    1.39000    2.35800    35.0861       2.0      91.0       2.0   \n",
              "2   13.71763    1.74423    2.78764    30.7934       0.0      99.0       2.0   \n",
              "3    4.82700    1.89100    1.15700    20.7577       0.0      71.0       5.0   \n",
              "4    5.06300    1.86900    1.67700    25.9766       7.0      73.0       4.0   \n",
              "\n",
              "   21003-0.0  1160-0.0  1438-0.0  4080-0.0  1458-0.0  1528-0.0  1319-0.0  \\\n",
              "0       54.0       7.0      10.0     110.0      3.73       2.0       0.0   \n",
              "1       65.0       9.0      12.0     166.0      7.00       2.4       0.0   \n",
              "2       55.0       7.0      10.0     135.0      7.00       2.0       0.0   \n",
              "3       49.0       8.0      14.0     116.0      5.00       3.0       1.0   \n",
              "4       61.0       7.0       2.0     113.0      7.00       4.0       2.0   \n",
              "\n",
              "   845-0.0  1289-0.0  1309-0.0  1418-0.0  1329-0.0  1220-0.0  1428-0.0  \\\n",
              "0    23.52       6.0       2.0         3         2         0         0   \n",
              "1    16.00       2.0       1.0         2         2         0         1   \n",
              "2    21.00       3.0       1.0         2         1         0         0   \n",
              "3    18.00       5.0       1.0         2         2         0         0   \n",
              "4    16.00       3.0       3.0         3         2         1         1   \n",
              "\n",
              "   1249-0.0  1349-0.0  1369-0.0  20117-0.0  2100-0.0  2654-0.0  1339-0.0  \\\n",
              "0         1         1         1          2         1         6         2   \n",
              "1         1         4         2          2         0         7         2   \n",
              "2         1         2         1          2         0         7         2   \n",
              "3         4         1         2          2         0         7         2   \n",
              "4         4         1         1          2         0         7         3   \n",
              "\n",
              "   21000-0.0  2050-0.0  1408-0.0  1200-0.0  1538-0.0  31-0.0  6138-0.0  \\\n",
              "0          0         2         1         3         2       0         1   \n",
              "1          0         1         3         2         0       1         3   \n",
              "2          0         1         2         2         1       1         3   \n",
              "3          2         1         2         1         2       0         6   \n",
              "4          0         1         3         1         0       0         3   \n",
              "\n",
              "   1359-0.0  1389-0.0  1478-0.0  2090-0.0  1508-0.0  1379-0.0  6142-0.0  \\\n",
              "0         2         1         1         1         3         1         1   \n",
              "1         3         1         1         0         2         2         1   \n",
              "2         3         2         1         0         2         2         1   \n",
              "3         2         2         1         0         2         2         1   \n",
              "4         3         1         2         0         1         1         1   \n",
              "\n",
              "   1468-0.0  1548-0.0  1239-0.0  1448-0.0  hypertension  \\\n",
              "0         3         2         0         3             0   \n",
              "1         5         2         0         1             1   \n",
              "2         4         2         0         3             1   \n",
              "3         3         2         0         3             0   \n",
              "4         4         2         0         3             1   \n",
              "\n",
              "   outcome_cardiomyopathies  outcome_ischemic_heart_disease  \\\n",
              "0                         0                               0   \n",
              "1                         0                               1   \n",
              "2                         0                               1   \n",
              "3                         0                               0   \n",
              "4                         0                               0   \n",
              "\n",
              "   outcome_heart_failure  outcome_myocardial_infarction  \\\n",
              "0                      0                              0   \n",
              "1                      0                              1   \n",
              "2                      0                              0   \n",
              "3                      0                              0   \n",
              "4                      0                              1   \n",
              "\n",
              "   outcome_peripheral_vascular_disease  outcome_cardiac_arrest  \\\n",
              "0                                    0                       0   \n",
              "1                                    0                       0   \n",
              "2                                    0                       1   \n",
              "3                                    0                       0   \n",
              "4                                    0                       0   \n",
              "\n",
              "   outcome_cerebral_infarction  outcome_arrhythmia              multi-labels  \\\n",
              "0                            0                   1  [0, 0, 0, 0, 0, 0, 0, 1]   \n",
              "1                            0                   0  [1, 0, 1, 0, 0, 0, 0, 0]   \n",
              "2                            1                   1  [0, 0, 1, 0, 0, 1, 1, 1]   \n",
              "3                            0                   1  [0, 0, 0, 0, 0, 0, 0, 1]   \n",
              "4                            0                   0  [1, 0, 0, 0, 0, 0, 0, 0]   \n",
              "\n",
              "   age  gender     race  \n",
              "0   54  Female  British  \n",
              "1   65    Male  British  \n",
              "2   55    Male  British  \n",
              "3   49  Female    Irish  \n",
              "4   61  Female  British  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b7bee5a-5f2a-443b-8263-5ce0db0be578\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>30850-0.0</th>\n",
              "      <th>30780-0.0</th>\n",
              "      <th>30690-0.0</th>\n",
              "      <th>30790-0.0</th>\n",
              "      <th>23101-0.0</th>\n",
              "      <th>23099-0.0</th>\n",
              "      <th>48-0.0</th>\n",
              "      <th>23100-0.0</th>\n",
              "      <th>30710-0.0</th>\n",
              "      <th>30760-0.0</th>\n",
              "      <th>30640-0.0</th>\n",
              "      <th>30750-0.0</th>\n",
              "      <th>49-0.0</th>\n",
              "      <th>30770-0.0</th>\n",
              "      <th>30740-0.0</th>\n",
              "      <th>30630-0.0</th>\n",
              "      <th>30870-0.0</th>\n",
              "      <th>21001-0.0</th>\n",
              "      <th>1488-0.0</th>\n",
              "      <th>4079-0.0</th>\n",
              "      <th>1299-0.0</th>\n",
              "      <th>21003-0.0</th>\n",
              "      <th>1160-0.0</th>\n",
              "      <th>1438-0.0</th>\n",
              "      <th>4080-0.0</th>\n",
              "      <th>1458-0.0</th>\n",
              "      <th>1528-0.0</th>\n",
              "      <th>1319-0.0</th>\n",
              "      <th>845-0.0</th>\n",
              "      <th>1289-0.0</th>\n",
              "      <th>1309-0.0</th>\n",
              "      <th>1418-0.0</th>\n",
              "      <th>1329-0.0</th>\n",
              "      <th>1220-0.0</th>\n",
              "      <th>1428-0.0</th>\n",
              "      <th>1249-0.0</th>\n",
              "      <th>1349-0.0</th>\n",
              "      <th>1369-0.0</th>\n",
              "      <th>20117-0.0</th>\n",
              "      <th>2100-0.0</th>\n",
              "      <th>2654-0.0</th>\n",
              "      <th>1339-0.0</th>\n",
              "      <th>21000-0.0</th>\n",
              "      <th>2050-0.0</th>\n",
              "      <th>1408-0.0</th>\n",
              "      <th>1200-0.0</th>\n",
              "      <th>1538-0.0</th>\n",
              "      <th>31-0.0</th>\n",
              "      <th>6138-0.0</th>\n",
              "      <th>1359-0.0</th>\n",
              "      <th>1389-0.0</th>\n",
              "      <th>1478-0.0</th>\n",
              "      <th>2090-0.0</th>\n",
              "      <th>1508-0.0</th>\n",
              "      <th>1379-0.0</th>\n",
              "      <th>6142-0.0</th>\n",
              "      <th>1468-0.0</th>\n",
              "      <th>1548-0.0</th>\n",
              "      <th>1239-0.0</th>\n",
              "      <th>1448-0.0</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>outcome_cardiomyopathies</th>\n",
              "      <th>outcome_ischemic_heart_disease</th>\n",
              "      <th>outcome_heart_failure</th>\n",
              "      <th>outcome_myocardial_infarction</th>\n",
              "      <th>outcome_peripheral_vascular_disease</th>\n",
              "      <th>outcome_cardiac_arrest</th>\n",
              "      <th>outcome_cerebral_infarction</th>\n",
              "      <th>outcome_arrhythmia</th>\n",
              "      <th>multi-labels</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>race</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.50800</td>\n",
              "      <td>3.88800</td>\n",
              "      <td>6.47700</td>\n",
              "      <td>65.1984</td>\n",
              "      <td>45.2</td>\n",
              "      <td>35.6</td>\n",
              "      <td>74.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.70600</td>\n",
              "      <td>1.21100</td>\n",
              "      <td>35.065</td>\n",
              "      <td>102.0</td>\n",
              "      <td>26.339</td>\n",
              "      <td>5.62200</td>\n",
              "      <td>1.59300</td>\n",
              "      <td>0.97700</td>\n",
              "      <td>24.5790</td>\n",
              "      <td>6.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.52</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>54</td>\n",
              "      <td>Female</td>\n",
              "      <td>British</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.08800</td>\n",
              "      <td>3.52000</td>\n",
              "      <td>5.51200</td>\n",
              "      <td>15.4000</td>\n",
              "      <td>74.6</td>\n",
              "      <td>36.5</td>\n",
              "      <td>120.0</td>\n",
              "      <td>42.9</td>\n",
              "      <td>3.94</td>\n",
              "      <td>1.17300</td>\n",
              "      <td>1.01900</td>\n",
              "      <td>40.900</td>\n",
              "      <td>113.0</td>\n",
              "      <td>10.701</td>\n",
              "      <td>5.05200</td>\n",
              "      <td>1.39000</td>\n",
              "      <td>2.35800</td>\n",
              "      <td>35.0861</td>\n",
              "      <td>2.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>65</td>\n",
              "      <td>Male</td>\n",
              "      <td>British</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.73364</td>\n",
              "      <td>4.10892</td>\n",
              "      <td>6.47949</td>\n",
              "      <td>50.8588</td>\n",
              "      <td>71.7</td>\n",
              "      <td>29.7</td>\n",
              "      <td>112.0</td>\n",
              "      <td>30.3</td>\n",
              "      <td>3.88</td>\n",
              "      <td>1.58546</td>\n",
              "      <td>1.22432</td>\n",
              "      <td>84.100</td>\n",
              "      <td>107.0</td>\n",
              "      <td>18.763</td>\n",
              "      <td>13.71763</td>\n",
              "      <td>1.74423</td>\n",
              "      <td>2.78764</td>\n",
              "      <td>30.7934</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 1, 0, 0, 1, 1, 1]</td>\n",
              "      <td>55</td>\n",
              "      <td>Male</td>\n",
              "      <td>British</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.78800</td>\n",
              "      <td>2.88700</td>\n",
              "      <td>5.56500</td>\n",
              "      <td>56.5183</td>\n",
              "      <td>40.2</td>\n",
              "      <td>29.8</td>\n",
              "      <td>67.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.87</td>\n",
              "      <td>2.11500</td>\n",
              "      <td>0.81000</td>\n",
              "      <td>36.400</td>\n",
              "      <td>91.0</td>\n",
              "      <td>31.672</td>\n",
              "      <td>4.82700</td>\n",
              "      <td>1.89100</td>\n",
              "      <td>1.15700</td>\n",
              "      <td>20.7577</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>49</td>\n",
              "      <td>Female</td>\n",
              "      <td>Irish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.75600</td>\n",
              "      <td>2.67000</td>\n",
              "      <td>4.68000</td>\n",
              "      <td>4.7700</td>\n",
              "      <td>46.5</td>\n",
              "      <td>30.1</td>\n",
              "      <td>85.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.18</td>\n",
              "      <td>1.49300</td>\n",
              "      <td>0.73300</td>\n",
              "      <td>34.200</td>\n",
              "      <td>105.0</td>\n",
              "      <td>42.209</td>\n",
              "      <td>5.06300</td>\n",
              "      <td>1.86900</td>\n",
              "      <td>1.67700</td>\n",
              "      <td>25.9766</td>\n",
              "      <td>7.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>61</td>\n",
              "      <td>Female</td>\n",
              "      <td>British</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b7bee5a-5f2a-443b-8263-5ce0db0be578')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b7bee5a-5f2a-443b-8263-5ce0db0be578 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b7bee5a-5f2a-443b-8263-5ce0db0be578');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "link ='https://github.com/analiseb/UB-Masters-Thesis/blob/main/data/CVD_data.csv?raw=true'\n",
        "df = pd.read_csv(link)\n",
        "pd.set_option('display.max_columns', None)\n",
        "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "23351717",
      "metadata": {
        "id": "23351717"
      },
      "outputs": [],
      "source": [
        "outcomes = ['outcome_myocardial_infarction','outcome_cardiomyopathies','outcome_ischemic_heart_disease','outcome_heart_failure','outcome_peripheral_vascular_disease','outcome_cardiac_arrest','outcome_cerebral_infarction','outcome_arrhythmia']\n",
        "\n",
        "# classifying features by datatype for appropriate use in model\n",
        "continuous_cols = df.iloc[:,:18].columns.to_list()\n",
        "numerical_cols = df.iloc[:,18:18+13].columns.to_list()\n",
        "categorical_cols = df.iloc[:,18+13:18+13+30].columns.to_list() # ordinal encoded\n",
        "nominal_cats = ['1428-0.0','20117-0.0','2100-0.0','2654-0.0','21000-0.0','1538-0.0','31-0.0','6138-0.0','2090-0.0','1508-0.0','6142-0.0','1468-0.0','1239-0.0','1448-0.0','hypertension']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e7b2cff",
      "metadata": {
        "id": "1e7b2cff"
      },
      "source": [
        "### transform features & split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "8eb52956",
      "metadata": {
        "id": "8eb52956"
      },
      "outputs": [],
      "source": [
        "def process_features(data, target, norm_method, one_hot=True):\n",
        "    \n",
        "    # split data into features and target \n",
        "    X = data.iloc[:,:61]\n",
        "    y = data[target]\n",
        "    \n",
        "    # split into training and test set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=False)\n",
        "    \n",
        "    # scale numerical features\n",
        "    scaler = norm_method # QuantileTransformer(output_distribution='uniform'), StandardScaler(), MaxMinScaler()\n",
        "    X_train[continuous_cols+numerical_cols]=scaler.fit_transform(X_train[continuous_cols+numerical_cols])\n",
        "    X_test[continuous_cols+numerical_cols] = scaler.transform(X_test[continuous_cols+numerical_cols])\n",
        "    \n",
        "    # get_dummies on nominal categorical features & drop original cols\n",
        "    if one_hot:\n",
        "        join = pd.concat([X_train,X_test],axis=0)\n",
        "        dummies = pd.get_dummies(join[nominal_cats], columns=nominal_cats, drop_first=True)\n",
        "        X_train[dummies.columns] = dummies.iloc[:len(X_train),:]\n",
        "        X_test[dummies.columns] = dummies.iloc[len(X_train):,:]\n",
        "        X_test = X_test.reindex(columns = X_train.columns, fill_value=0)\n",
        "        del(dummies)\n",
        "\n",
        "        X_train.drop(nominal_cats,axis=1,inplace=True)\n",
        "        X_test.drop(nominal_cats,axis=1,inplace=True)\n",
        "\n",
        "    X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.15, random_state=1)\n",
        "    \n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "879ff13a",
      "metadata": {
        "id": "879ff13a"
      },
      "source": [
        "### Resampling on training data to address class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "d28072b3",
      "metadata": {
        "id": "d28072b3"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import ADASYN, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "def resample_data(X_train, y_train, method):\n",
        "    \n",
        "    if method=='ADASYN':\n",
        "        X_temp,y_train= ADASYN().fit_resample(X_train,y_train)\n",
        "        X_train = pd.DataFrame(X_temp, columns=X_train.columns)\n",
        "        \n",
        "    elif method=='over':\n",
        "        # over sample the majority class in train\n",
        "        oversample = RandomOverSampler(sampling_strategy='minority',random_state=1)\n",
        "        X_temp, y_train = oversample.fit_resample(X_train, y_train)\n",
        "        X_train = pd.DataFrame(X_temp, columns=X_train.columns)\n",
        "\n",
        "    elif method=='under':\n",
        "        # under sample the majority class in train\n",
        "        undersample = RandomUnderSampler(sampling_strategy='majority',random_state=1)\n",
        "        X_temp, y_train = undersample.fit_resample(X_train, y_train)\n",
        "        X_train = pd.DataFrame(X_temp, columns=X_train.columns)\n",
        "        \n",
        "    elif method=='partial_under':\n",
        "        # under sample the majority class in train, ~2:1 neg/pos ratio\n",
        "        undersample_uneven = RandomUnderSampler(sampling_strategy=0.5,random_state=1)\n",
        "        X_temp, y_train = undersample_uneven.fit_resample(X_train, y_train)\n",
        "        X_train = pd.DataFrame(X_temp, columns=X_train2.columns)\n",
        "        \n",
        "    return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79f27ac1",
      "metadata": {
        "id": "79f27ac1"
      },
      "source": [
        "### Build MLP Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4311a358",
      "metadata": {
        "id": "4311a358"
      },
      "source": [
        "#### define model metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "1bd9d66d",
      "metadata": {
        "id": "1bd9d66d"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "]\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "617f83cd",
      "metadata": {
        "id": "617f83cd"
      },
      "source": [
        "#### optimize number of nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5d5bf9b2",
      "metadata": {
        "id": "5d5bf9b2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def evaluate_nodes(n_nodes, X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch):\n",
        "    \n",
        "    # define model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(100, activation=tf.keras.activations.gelu , input_shape=(X_train.shape[1],)))\n",
        "    model.add(Dense(n_nodes, activation=tf.keras.activations.gelu ))\n",
        "    model.add(Dense(n_nodes, activation=tf.keras.activations.gelu ))\n",
        "    model.add(Dense(1, activation=tf.nn.sigmoid))\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=Adam(learning_rate=0.000001),\n",
        "        metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "    # fit model on train set\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=batch,\n",
        "        epochs=epochs,\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        validation_data=(X_val, y_val),\n",
        "    )\n",
        "    score = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return history, score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "bgpit_ZemX1V",
      "metadata": {
        "id": "bgpit_ZemX1V"
      },
      "outputs": [],
      "source": [
        "def evaluate_layers(n_layers, X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch):\n",
        "    \n",
        "    # define model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(100, activation=tf.keras.activations.gelu , input_shape=(X_train.shape[1],)))\n",
        "    for _ in range(1,n_layers):\n",
        "        model.add(Dense(50, activation=tf.keras.activations.gelu ))\n",
        "    model.add(Dense(1, activation=tf.nn.sigmoid))\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=Adam(learning_rate=0.000001),\n",
        "        metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "    # fit model on train set\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=batch,\n",
        "        epochs=epochs,\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        validation_data=(X_val, y_val),\n",
        "    )\n",
        "    score = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return history, score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "6d8fd955",
      "metadata": {
        "id": "6d8fd955"
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "    fig, ((ax1,ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "    ax1.set_title(\"Loss\")\n",
        "    ax1.plot(history.history[\"loss\"])\n",
        "    ax1.plot(history.history[\"val_loss\"])\n",
        "    ax1.legend([\"Test Loss\", \"Validation Loss\"])\n",
        "    ax1.set_xlabel (\"Epoch\")\n",
        "\n",
        "    ax2.set_title(\"Accuracy\")\n",
        "    ax2.plot(history.history[\"acc\"])\n",
        "    ax2.plot(history.history[\"val_acc\"])\n",
        "    ax2.legend([\"Test Accuracy\", \"Validation Accuracy\"])\n",
        "    ax2.set_xlabel (\"Epoch\")\n",
        "\n",
        "    ax3.set_title(\"Recall\")\n",
        "    ax3.plot(history.history[\"recall_m\"])\n",
        "    ax3.plot(history.history[\"val_recall_m\"])\n",
        "    ax3.legend([\"Test Recall\", \"Validation Recall\"])\n",
        "    ax3.set_xlabel (\"Epoch\")\n",
        "\n",
        "    ax4.set_title(\"F1\")\n",
        "    ax4.plot(history.history[\"f1_m\"])\n",
        "    ax4.plot(history.history[\"val_f1_m\"])\n",
        "    ax4.legend([\"Test F1-score\", \"Validation F1-score\"])\n",
        "    ax4.set_xlabel (\"Epoch\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b6cc2f2",
      "metadata": {
        "id": "9b6cc2f2"
      },
      "source": [
        "#### test range of input nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf9dae95",
      "metadata": {
        "id": "cf9dae95"
      },
      "outputs": [],
      "source": [
        "num_nodes = [10, 25, 50, 100, 150, 200]\n",
        "epochs = 400\n",
        "batch = 500\n",
        "\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = process_features(df, 'outcome_arrhythmia', QuantileTransformer(output_distribution='uniform'), one_hot=True)\n",
        "X_train, y_train= resample_data(X_train, y_train, 'under')\n",
        "\n",
        "save_history = pd.DataFrame()\n",
        "for n_nodes in num_nodes:\n",
        "    # evaluate model with a given number of nodes\n",
        "    history, result = evaluate_nodes(n_nodes, X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch)\n",
        "    save_history['loss_'+str(n_nodes)]=history.history[\"loss\"]\n",
        "    save_history['acc_'+str(n_nodes)]=history.history[\"acc\"]\n",
        "    save_history['f1'+str(n_nodes)]=history.history[\"f1_m\"]\n",
        "    save_history['recall'+str(n_nodes)]=history.history[\"recall_m\"]\n",
        "\n",
        "\n",
        "    # summarize final test set accuracy\n",
        "    print('nodes=%d  loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (n_nodes, result[0], result[1], result[2], result[3], result[4]))\n",
        "    \n",
        "    # plot learning curves\n",
        "    plot_history(history)\n",
        "    plt.suptitle('Number of Nodes: '+str(n_nodes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "kJOOk6B5ZxXS",
      "metadata": {
        "id": "kJOOk6B5ZxXS"
      },
      "outputs": [],
      "source": [
        "def plot_compare(data, metric):\n",
        "  labels = []\n",
        "  for i in range(data.shape[1]):\n",
        "    sns.lineplot(x=data.index, y=data.loc[:,data.columns[i-1]], data=data)\n",
        "    plt.title(metric+' for all num_nodes')\n",
        "    labels.append(str(data.columns[i-1]))\n",
        "  plt.legend(title=metric, loc='best', labels=labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3HVZFtPQcE-B",
      "metadata": {
        "id": "3HVZFtPQcE-B"
      },
      "outputs": [],
      "source": [
        "plot_compare(save_history.loc[:,save_history.columns.to_list()[::4]], 'loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dQxjf1IXvO_C",
      "metadata": {
        "id": "dQxjf1IXvO_C"
      },
      "outputs": [],
      "source": [
        "plot_compare(save_history.loc[:,save_history.columns.to_list()[1::4]], 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zz0p182tzyHR",
      "metadata": {
        "id": "zz0p182tzyHR"
      },
      "outputs": [],
      "source": [
        "plot_compare(save_history.loc[:,save_history.columns.to_list()[2::4]], 'F1-Score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XhRlCOvtzyRo",
      "metadata": {
        "id": "XhRlCOvtzyRo"
      },
      "outputs": [],
      "source": [
        "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XB4Rv9251GnD",
      "metadata": {
        "id": "XB4Rv9251GnD"
      },
      "outputs": [],
      "source": [
        "num_layers = [3, 4, 5]\n",
        "epochs = 400\n",
        "batch = 500\n",
        "\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = process_features(df, 'outcome_arrhythmia', QuantileTransformer(output_distribution='uniform'), one_hot=True)\n",
        "X_train, y_train= resample_data(X_train, y_train, 'under')\n",
        "\n",
        "save_history = pd.DataFrame()\n",
        "for n_layers in num_layers:\n",
        "    # evaluate model with a given number of nodes\n",
        "    history, result = evaluate_layers(n_layers, X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch)\n",
        "    save_history['loss_'+str(n_layers)]=history.history[\"loss\"]\n",
        "    save_history['acc_'+str(n_layers)]=history.history[\"acc\"]\n",
        "    save_history['f1'+str(n_layers)]=history.history[\"f1_m\"]\n",
        "    save_history['recall'+str(n_layers)]=history.history[\"recall_m\"]\n",
        "\n",
        "\n",
        "    # summarize final test set accuracy\n",
        "    print('nodes=%d  loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (n_layers, result[0], result[1], result[2], result[3], result[4]))\n",
        "    \n",
        "    # plot learning curves\n",
        "    plot_history(history)\n",
        "    plt.suptitle('Number of Layers: '+str(n_layers))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a0e3458",
      "metadata": {
        "id": "2a0e3458"
      },
      "source": [
        "### Build Model after testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "0009fde5",
      "metadata": {
        "id": "0009fde5"
      },
      "outputs": [],
      "source": [
        "def basic_model( X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation='relu',opt=SGD, lr=0.000001):\n",
        "    \n",
        "    # define model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1000, activation=activation , input_shape=(X_train.shape[1],)))\n",
        "    model.add(Dense(500, activation=activation))\n",
        "    model.add(Dense(500, activation=activation ))\n",
        "    model.add(Dense(200, activation=activation ))\n",
        "    model.add(Dense(1, activation=tf.nn.sigmoid))\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=opt(learning_rate=lr),\n",
        "        metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "    # fit model on train set\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=batch,\n",
        "        epochs=epochs,\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        validation_data=(X_val, y_val),\n",
        "    )\n",
        "    score = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return history, score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "6ad05a1b",
      "metadata": {
        "id": "6ad05a1b"
      },
      "outputs": [],
      "source": [
        "epochs =500\n",
        "batch = 400\n",
        "sample_methods =['ADASYN', 'over', 'under', 'partial_under']\n",
        "activations=['relu', 'tanh', tf.keras.activations.gelu]\n",
        "optimizers = [SGD, Adam, Adagrad]\n",
        "num_transformers = [StandardScaler(), MinMaxScaler(), QuantileTransformer(output_distribution='uniform')]\n",
        "# test one_hot==True/False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e51f06c",
      "metadata": {
        "id": "3e51f06c",
        "outputId": "c55f6aaf-a2ac-4304-c726-b8f3c2a700f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "139/139 [==============================] - 4s 21ms/step - loss: 0.7230 - acc: 0.4847 - f1_m: 0.3388 - precision_m: 0.4727 - recall_m: 0.2649 - val_loss: 0.7283 - val_acc: 0.4751 - val_f1_m: 0.3410 - val_precision_m: 0.4922 - val_recall_m: 0.2618\n",
            "Epoch 2/500\n",
            "139/139 [==============================] - 2s 18ms/step - loss: 0.7228 - acc: 0.4845 - f1_m: 0.3404 - precision_m: 0.4732 - recall_m: 0.2668 - val_loss: 0.7281 - val_acc: 0.4746 - val_f1_m: 0.3413 - val_precision_m: 0.4911 - val_recall_m: 0.2624\n",
            "Epoch 3/500\n",
            "139/139 [==============================] - 2s 17ms/step - loss: 0.7227 - acc: 0.4847 - f1_m: 0.3420 - precision_m: 0.4731 - recall_m: 0.2687 - val_loss: 0.7279 - val_acc: 0.4749 - val_f1_m: 0.3459 - val_precision_m: 0.4959 - val_recall_m: 0.2664\n",
            "Epoch 4/500\n",
            "139/139 [==============================] - 2s 17ms/step - loss: 0.7225 - acc: 0.4847 - f1_m: 0.3437 - precision_m: 0.4730 - recall_m: 0.2707 - val_loss: 0.7277 - val_acc: 0.4750 - val_f1_m: 0.3475 - val_precision_m: 0.4960 - val_recall_m: 0.2683\n",
            "Epoch 5/500\n",
            "139/139 [==============================] - 2s 17ms/step - loss: 0.7224 - acc: 0.4844 - f1_m: 0.3452 - precision_m: 0.4732 - recall_m: 0.2726 - val_loss: 0.7275 - val_acc: 0.4754 - val_f1_m: 0.3521 - val_precision_m: 0.4999 - val_recall_m: 0.2726\n",
            "Epoch 6/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7223 - acc: 0.4846 - f1_m: 0.3468 - precision_m: 0.4734 - recall_m: 0.2745 - val_loss: 0.7273 - val_acc: 0.4757 - val_f1_m: 0.3538 - val_precision_m: 0.5004 - val_recall_m: 0.2745\n",
            "Epoch 7/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7222 - acc: 0.4849 - f1_m: 0.3488 - precision_m: 0.4745 - recall_m: 0.2768 - val_loss: 0.7271 - val_acc: 0.4755 - val_f1_m: 0.3547 - val_precision_m: 0.5000 - val_recall_m: 0.2757\n",
            "Epoch 8/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7220 - acc: 0.4847 - f1_m: 0.3502 - precision_m: 0.4741 - recall_m: 0.2786 - val_loss: 0.7269 - val_acc: 0.4758 - val_f1_m: 0.3559 - val_precision_m: 0.5005 - val_recall_m: 0.2771\n",
            "Epoch 9/500\n",
            "139/139 [==============================] - 2s 15ms/step - loss: 0.7219 - acc: 0.4847 - f1_m: 0.3517 - precision_m: 0.4741 - recall_m: 0.2805 - val_loss: 0.7267 - val_acc: 0.4766 - val_f1_m: 0.3589 - val_precision_m: 0.5017 - val_recall_m: 0.2802\n",
            "Epoch 10/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7218 - acc: 0.4848 - f1_m: 0.3533 - precision_m: 0.4743 - recall_m: 0.2822 - val_loss: 0.7266 - val_acc: 0.4766 - val_f1_m: 0.3603 - val_precision_m: 0.5017 - val_recall_m: 0.2820\n",
            "Epoch 11/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7217 - acc: 0.4848 - f1_m: 0.3546 - precision_m: 0.4742 - recall_m: 0.2840 - val_loss: 0.7264 - val_acc: 0.4771 - val_f1_m: 0.3625 - val_precision_m: 0.5025 - val_recall_m: 0.2844\n",
            "Epoch 12/500\n",
            "139/139 [==============================] - 2s 17ms/step - loss: 0.7215 - acc: 0.4847 - f1_m: 0.3557 - precision_m: 0.4742 - recall_m: 0.2856 - val_loss: 0.7262 - val_acc: 0.4774 - val_f1_m: 0.3671 - val_precision_m: 0.5053 - val_recall_m: 0.2891\n",
            "Epoch 13/500\n",
            "139/139 [==============================] - 2s 17ms/step - loss: 0.7214 - acc: 0.4850 - f1_m: 0.3572 - precision_m: 0.4749 - recall_m: 0.2873 - val_loss: 0.7261 - val_acc: 0.4769 - val_f1_m: 0.3686 - val_precision_m: 0.5044 - val_recall_m: 0.2912\n",
            "Epoch 14/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7213 - acc: 0.4852 - f1_m: 0.3593 - precision_m: 0.4755 - recall_m: 0.2897 - val_loss: 0.7259 - val_acc: 0.4761 - val_f1_m: 0.3691 - val_precision_m: 0.5031 - val_recall_m: 0.2923\n",
            "Epoch 15/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7212 - acc: 0.4854 - f1_m: 0.3610 - precision_m: 0.4760 - recall_m: 0.2917 - val_loss: 0.7257 - val_acc: 0.4758 - val_f1_m: 0.3694 - val_precision_m: 0.5027 - val_recall_m: 0.2928\n",
            "Epoch 16/500\n",
            "139/139 [==============================] - 2s 17ms/step - loss: 0.7211 - acc: 0.4852 - f1_m: 0.3620 - precision_m: 0.4759 - recall_m: 0.2930 - val_loss: 0.7256 - val_acc: 0.4762 - val_f1_m: 0.3718 - val_precision_m: 0.5032 - val_recall_m: 0.2956\n",
            "Epoch 17/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7210 - acc: 0.4854 - f1_m: 0.3636 - precision_m: 0.4769 - recall_m: 0.2947 - val_loss: 0.7254 - val_acc: 0.4767 - val_f1_m: 0.3737 - val_precision_m: 0.5039 - val_recall_m: 0.2979\n",
            "Epoch 18/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7209 - acc: 0.4856 - f1_m: 0.3650 - precision_m: 0.4772 - recall_m: 0.2965 - val_loss: 0.7253 - val_acc: 0.4766 - val_f1_m: 0.3747 - val_precision_m: 0.5036 - val_recall_m: 0.2993\n",
            "Epoch 19/500\n",
            "139/139 [==============================] - 2s 17ms/step - loss: 0.7208 - acc: 0.4857 - f1_m: 0.3662 - precision_m: 0.4771 - recall_m: 0.2982 - val_loss: 0.7251 - val_acc: 0.4759 - val_f1_m: 0.3757 - val_precision_m: 0.5024 - val_recall_m: 0.3011\n",
            "Epoch 20/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7207 - acc: 0.4857 - f1_m: 0.3674 - precision_m: 0.4769 - recall_m: 0.2997 - val_loss: 0.7249 - val_acc: 0.4762 - val_f1_m: 0.3777 - val_precision_m: 0.5029 - val_recall_m: 0.3033\n",
            "Epoch 21/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7206 - acc: 0.4858 - f1_m: 0.3688 - precision_m: 0.4777 - recall_m: 0.3013 - val_loss: 0.7248 - val_acc: 0.4752 - val_f1_m: 0.3781 - val_precision_m: 0.4998 - val_recall_m: 0.3048\n",
            "Epoch 22/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7205 - acc: 0.4858 - f1_m: 0.3702 - precision_m: 0.4778 - recall_m: 0.3031 - val_loss: 0.7247 - val_acc: 0.4755 - val_f1_m: 0.3793 - val_precision_m: 0.5003 - val_recall_m: 0.3062\n",
            "Epoch 23/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7204 - acc: 0.4856 - f1_m: 0.3712 - precision_m: 0.4778 - recall_m: 0.3043 - val_loss: 0.7245 - val_acc: 0.4757 - val_f1_m: 0.3803 - val_precision_m: 0.5006 - val_recall_m: 0.3075\n",
            "Epoch 24/500\n",
            "139/139 [==============================] - 2s 17ms/step - loss: 0.7203 - acc: 0.4857 - f1_m: 0.3723 - precision_m: 0.4769 - recall_m: 0.3062 - val_loss: 0.7244 - val_acc: 0.4753 - val_f1_m: 0.3807 - val_precision_m: 0.5000 - val_recall_m: 0.3082\n",
            "Epoch 25/500\n",
            "139/139 [==============================] - 2s 17ms/step - loss: 0.7202 - acc: 0.4855 - f1_m: 0.3736 - precision_m: 0.4779 - recall_m: 0.3079 - val_loss: 0.7242 - val_acc: 0.4754 - val_f1_m: 0.3819 - val_precision_m: 0.5001 - val_recall_m: 0.3096\n",
            "Epoch 26/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7201 - acc: 0.4854 - f1_m: 0.3746 - precision_m: 0.4773 - recall_m: 0.3093 - val_loss: 0.7241 - val_acc: 0.4754 - val_f1_m: 0.3848 - val_precision_m: 0.5020 - val_recall_m: 0.3127\n",
            "Epoch 27/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7200 - acc: 0.4852 - f1_m: 0.3756 - precision_m: 0.4772 - recall_m: 0.3107 - val_loss: 0.7240 - val_acc: 0.4749 - val_f1_m: 0.3854 - val_precision_m: 0.5012 - val_recall_m: 0.3138\n",
            "Epoch 28/500\n",
            "139/139 [==============================] - 2s 15ms/step - loss: 0.7199 - acc: 0.4852 - f1_m: 0.3767 - precision_m: 0.4768 - recall_m: 0.3123 - val_loss: 0.7238 - val_acc: 0.4748 - val_f1_m: 0.3863 - val_precision_m: 0.5012 - val_recall_m: 0.3150\n",
            "Epoch 29/500\n",
            "139/139 [==============================] - 2s 17ms/step - loss: 0.7198 - acc: 0.4854 - f1_m: 0.3781 - precision_m: 0.4774 - recall_m: 0.3136 - val_loss: 0.7237 - val_acc: 0.4744 - val_f1_m: 0.3869 - val_precision_m: 0.5005 - val_recall_m: 0.3161\n",
            "Epoch 30/500\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.7198 - acc: 0.4856 - f1_m: 0.3796 - precision_m: 0.4782 - recall_m: 0.3155 - val_loss: 0.7236 - val_acc: 0.4743 - val_f1_m: 0.3875 - val_precision_m: 0.5004 - val_recall_m: 0.3170\n",
            "Epoch 31/500\n",
            " 88/139 [=================>............] - ETA: 0s - loss: 0.7203 - acc: 0.4854 - f1_m: 0.3792 - precision_m: 0.4763 - recall_m: 0.3158"
          ]
        }
      ],
      "source": [
        "# Test numerical transformers\n",
        "save_history = pd.DataFrame()\n",
        "for param in num_transformers:\n",
        "    \n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = process_features(df, 'outcome_arrhythmia', param, one_hot=True)\n",
        "    X_train, y_train= resample_data(X_train, y_train, 'under')\n",
        "    \n",
        "    # evaluate model with a given number of nodes\n",
        "    history, result = basic_model( X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation='tanh',opt=SGD, lr=0.000001)\n",
        "    save_history['loss_'+str(n_nodes)]=history.history[\"loss\"]\n",
        "    save_history['acc_'+str(n_nodes)]=history.history[\"acc\"]\n",
        "    save_history['f1'+str(n_nodes)]=history.history[\"f1_m\"]\n",
        "    save_history['recall'+str(n_nodes)]=history.history[\"recall_m\"]\n",
        "\n",
        "\n",
        "    # summarize final test set accuracy\n",
        "    print('loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (result[0], result[1], result[2], result[3], result[4]))\n",
        "    \n",
        "    # plot learning curves\n",
        "    plot_history(history)\n",
        "    plt.suptitle(str(param))\n",
        "\n",
        "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "404a7317",
      "metadata": {
        "id": "404a7317"
      },
      "outputs": [],
      "source": [
        "# Test sample methods\n",
        "save_history = pd.DataFrame()\n",
        "for param in sample_methods:\n",
        "    \n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = process_features(df, 'outcome_arrhythmia', QuantileTransformer(output_distribution='uniform'), one_hot=True)\n",
        "    X_train, y_train= resample_data(X_train, y_train, param)\n",
        "    \n",
        "    # evaluate model with a given number of nodes\n",
        "    history, result = basic_model(X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation='relu',opt=SGD, lr=0.000001)\n",
        "    save_history['loss_'+str(n_nodes)]=history.history[\"loss\"]\n",
        "    save_history['acc_'+str(n_nodes)]=history.history[\"acc\"]\n",
        "    save_history['f1'+str(n_nodes)]=history.history[\"f1_m\"]\n",
        "    save_history['recall'+str(n_nodes)]=history.history[\"recall_m\"]\n",
        "\n",
        "\n",
        "    # summarize final test set accuracy\n",
        "    print('nodes=%d  loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (n_nodes, result[0], result[1], result[2], result[3], result[4]))\n",
        "    \n",
        "    # plot learning curves\n",
        "    plot_history(history)\n",
        "    plt.suptitle(str(param))\n",
        "\n",
        "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f84752a4",
      "metadata": {
        "id": "f84752a4"
      },
      "outputs": [],
      "source": [
        "# Test activations\n",
        "save_history = pd.DataFrame()\n",
        "for param in activations:\n",
        "    \n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = process_features(df, 'outcome_arrhythmia', QuantileTransformer(output_distribution='uniform'), one_hot=True)\n",
        "    X_train, y_train= resample_data(X_train, y_train, 'under')\n",
        "    \n",
        "    # evaluate model with a given number of nodes\n",
        "    history, result = basic_model(X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation=param,opt=SGD, lr=0.000001)\n",
        "    save_history['loss_'+str(n_nodes)]=history.history[\"loss\"]\n",
        "    save_history['acc_'+str(n_nodes)]=history.history[\"acc\"]\n",
        "    save_history['f1'+str(n_nodes)]=history.history[\"f1_m\"]\n",
        "    save_history['recall'+str(n_nodes)]=history.history[\"recall_m\"]\n",
        "\n",
        "\n",
        "    # summarize final test set accuracy\n",
        "    print('nodes=%d  loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (n_nodes, result[0], result[1], result[2], result[3], result[4]))\n",
        "    \n",
        "    # plot learning curves\n",
        "    plot_history(history)\n",
        "    plt.suptitle(str(param))\n",
        "\n",
        "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "580a1880",
      "metadata": {
        "id": "580a1880"
      },
      "outputs": [],
      "source": [
        "# Test optimizers\n",
        "save_history = pd.DataFrame()\n",
        "for param in optimizers:\n",
        "    \n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = process_features(df, 'outcome_arrhythmia', QuantileTransformer(output_distribution='uniform'), one_hot=True)\n",
        "    X_train, y_train= resample_data(X_train, y_train, 'under')\n",
        "    \n",
        "    # evaluate model with a given number of nodes\n",
        "    history, result = basic_model(n_nodes, X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation='relu',opt=param, lr=0.000001)\n",
        "    save_history['loss_'+str(n_nodes)]=history.history[\"loss\"]\n",
        "    save_history['acc_'+str(n_nodes)]=history.history[\"acc\"]\n",
        "    save_history['f1'+str(n_nodes)]=history.history[\"f1_m\"]\n",
        "    save_history['recall'+str(n_nodes)]=history.history[\"recall_m\"]\n",
        "\n",
        "\n",
        "    # summarize final test set accuracy\n",
        "    print('nodes=%d  loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (n_nodes, result[0], result[1], result[2], result[3], result[4]))\n",
        "    \n",
        "    # plot learning curves\n",
        "    plot_history(history)\n",
        "    plt.suptitle(str(param))\n",
        "\n",
        "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test opt opt params\n",
        "\n",
        "learning_rates = [1e-3, 1e-4, 1e-6, some_changing_thing()]\n",
        "beta1, beta2 = [1,2,3,4], [1,2,3,4]\n",
        "save_history = pd.DataFrame()\n",
        "for param in optimizers:\n",
        "    \n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = process_features(df, 'outcome_arrhythmia', QuantileTransformer(output_distribution='uniform'), one_hot=True)\n",
        "    X_train, y_train= resample_data(X_train, y_train, 'under')\n",
        "    \n",
        "    # evaluate model with a given number of nodes\n",
        "    history, result = basic_model(n_nodes, X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation='relu',opt=param, lr=0.000001)\n",
        "    save_history['loss_'+str(n_nodes)]=history.history[\"loss\"]\n",
        "    save_history['acc_'+str(n_nodes)]=history.history[\"acc\"]\n",
        "    save_history['f1'+str(n_nodes)]=history.history[\"f1_m\"]\n",
        "    save_history['recall'+str(n_nodes)]=history.history[\"recall_m\"]\n",
        "\n",
        "\n",
        "    # summarize final test set accuracy\n",
        "    print('nodes=%d  loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (n_nodes, result[0], result[1], result[2], result[3], result[4]))\n",
        "    \n",
        "    # plot learning curves\n",
        "    plot_history(history)\n",
        "    plt.suptitle(str(param))\n",
        "\n",
        "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
      ],
      "metadata": {
        "id": "dAaElnGDpvzg"
      },
      "id": "dAaElnGDpvzg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b7132839",
      "metadata": {
        "id": "b7132839"
      },
      "source": [
        "### Build MLP Model with Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32f78ee8",
      "metadata": {
        "id": "32f78ee8"
      },
      "outputs": [],
      "source": [
        "def build_categorical_inputs(features):\n",
        "\n",
        "    initial_inputs = {}\n",
        "    cat_input_layers={}\n",
        "    \n",
        "    train_test_cat_features = pd.concat([X_train[categorical_cols], X_test[categorical_cols]])\n",
        "    \n",
        "    for feature in features:\n",
        "        no_of_unique_cats  = train_test_cat_features[feature].nunique()\n",
        "        embedding_size = int(min(np.ceil((no_of_unique_cats)/2), 50))\n",
        "        categories  = no_of_unique_cats + 1\n",
        "\n",
        "        initial_inputs[feature] = Input(shape=(1,))\n",
        "        embedding_layer = Embedding(categories, \n",
        "                                    embedding_size,\n",
        "                                    embeddings_regularizer=regularizers.l2(0.01),\n",
        "                                    input_length=1)(initial_inputs[feature])\n",
        "        cat_input_layers[feature] = Reshape(target_shape=(embedding_size,))(embedding_layer)\n",
        "\n",
        "    return initial_inputs, cat_input_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58a231b6",
      "metadata": {
        "id": "58a231b6"
      },
      "outputs": [],
      "source": [
        "def build_model( X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch):\n",
        "    \n",
        "    models = []\n",
        "    for categorical_var in categorical_cols :\n",
        "        model = Sequential()\n",
        "        no_of_unique_cat  = X_train[categorical_var].nunique()\n",
        "        embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
        "        embedding_size = int(embedding_size)\n",
        "        vocab  = no_of_unique_cat+1\n",
        "        model.add( Embedding(vocab ,embedding_size, input_length = 1 ))\n",
        "        model.add(Reshape(target_shape=(embedding_size,)))\n",
        "        models.append( model )\n",
        "        \n",
        "    model_rest = Sequential()\n",
        "    model_rest.add(Dense(16, input_dim= X_train[numerical_cols+continuous_cols].shape[1]))\n",
        "    models.append(model_rest)\n",
        "\n",
        "    full_model = Sequential()\n",
        "    full_model.add(Concatenate(models))\n",
        "    full_model.add(Dense(1000))\n",
        "    full_model.add(Activation('relu'))\n",
        "    full_model.add(Dense(400))\n",
        "    full_model.add(Activation('relu'))\n",
        "    full_model.add(Dense(1))\n",
        "    full_model.add(Activation('sigmoid'))\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=Adam(learning_rate=0.000001),\n",
        "        metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "    # fit model on train set\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=batch,\n",
        "        epochs=epochs,\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        validation_data=(X_val, y_val),\n",
        "    )\n",
        "    score = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return history, score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7df20d86",
      "metadata": {
        "id": "7df20d86"
      },
      "outputs": [],
      "source": [
        "def build_model( X_train, X_val, X_test ,y_train, y_val, y_test, epochs, batch):\n",
        "    \n",
        "    # define model\n",
        "    model = Sequential()\n",
        "    for col in categorical_cols:\n",
        "        no_of_unique_cat  = X_train[col].nunique()\n",
        "        embedding_size = min(np.ceil((no_of_unique_cat)/2), 50)\n",
        "        embedding_size = int(embedding_size)\n",
        "        vocab  = no_of_unique_cat+1\n",
        "        model.add(Embedding(input_dim=no_of_unique_cat, output_dim=embedding_size, input_shape=(X_train.shape[1],)))\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(50, activation=tf.keras.activations.gelu ))\n",
        "    model.add(Dense(1, activation=tf.nn.sigmoid))\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=Adam(learning_rate=0.000001),\n",
        "        metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "    # fit model on train set\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=batch,\n",
        "        epochs=epochs,\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        validation_data=(X_val, y_val),\n",
        "    )\n",
        "    score = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return history, score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7504bd9e",
      "metadata": {
        "id": "7504bd9e",
        "outputId": "461b0328-9c50-49ca-c506-82ac05ebb67c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='embedding_179_input'), name='embedding_179_input', description=\"created by layer 'embedding_179_input'\"), but it was called on an input with incompatible shape (None, 61).\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\reshaping\\reshape.py\", line 111, in _fix_unknown_dimension\n        raise ValueError(msg)\n\n    ValueError: Exception encountered when calling layer \"reshape_149\" (type Reshape).\n    \n    total size of new array must be unchanged, input_shape = [61, 1], output_shape = [1]\n    \n    Call arguments received by layer \"reshape_149\" (type Reshape):\n      • inputs=tf.Tensor(shape=(None, 61, 1), dtype=float32)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33300/3241727813.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'outcome_arrhythmia'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQuantileTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_distribution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mresample_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'under'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33300/2518285737.py\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# fit model on train set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     history = model.fit(\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\reshaping\\reshape.py\", line 111, in _fix_unknown_dimension\n        raise ValueError(msg)\n\n    ValueError: Exception encountered when calling layer \"reshape_149\" (type Reshape).\n    \n    total size of new array must be unchanged, input_shape = [61, 1], output_shape = [1]\n    \n    Call arguments received by layer \"reshape_149\" (type Reshape):\n      • inputs=tf.Tensor(shape=(None, 61, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = process_features(df, 'outcome_arrhythmia', QuantileTransformer(output_distribution='uniform'), one_hot=False)\n",
        "X_train, y_train= resample_data(X_train, y_train, 'under')\n",
        "model=build_model(X_train, X_val, X_test ,y_train, y_val, y_test, 400, 600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fac49e1",
      "metadata": {
        "id": "1fac49e1"
      },
      "outputs": [],
      "source": [
        "initial_inputs, input_layers = build_categorical_inputs(categorical_cols)\n",
        "\n",
        "no_of_num_features = len(X_train.columns) - len(categorical_cols)\n",
        "\n",
        "initial_inputs['numerical_features'] = Input(shape=(no_of_num_features,))\n",
        "input_layers['numerical_features'] = initial_inputs['numerical_features']\n",
        "\n",
        "inputs = Concatenate(axis=-1)([layer for layer in input_layers.values()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40ccdade",
      "metadata": {
        "id": "40ccdade"
      },
      "outputs": [],
      "source": [
        "models = []\n",
        "\n",
        "model_rest = Sequential()\n",
        "model_rest.add(Dense(100, input_dim= len(numerical_cols+continuous_cols) ))\n",
        "models.append(model_rest)\n",
        "\n",
        "for categorical_var in categorical_cols :\n",
        "     \n",
        "    model = Sequential()\n",
        "    no_of_unique_cat  = X_train[categorical_var].nunique()\n",
        "    \n",
        "    # jeremy howard rule\n",
        "    embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
        "    embedding_size = int(embedding_size)\n",
        "    vocab  = no_of_unique_cat+1\n",
        "    model.add( Embedding(vocab ,embedding_size, input_length = 1 ))\n",
        "    model.add(Reshape(target_shape=(embedding_size,)))\n",
        "    models.append( model )\n",
        "\n",
        "\n",
        "full_model = Sequential()\n",
        "full_model.add(Concatenate(models))\n",
        "full_model.add(Dense(1000))\n",
        "full_model.add(Activation('relu'))\n",
        "full_model.add(Dense(400))\n",
        "full_model.add(Activation('relu'))\n",
        "full_model.add(Dense(200))\n",
        "full_model.add(Activation('sigmoid'))\n",
        "full_model.add(Dense(1))\n",
        "full_model.add(Activation('sigmoid'))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.000001)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['acc',f1_m,precision_m, recall_m])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "987f57a0",
      "metadata": {
        "id": "987f57a0",
        "outputId": "d565f829-b10a-4bf0-eae3-9a584de3dd05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='embedding_607_input'), name='embedding_607_input', description=\"created by layer 'embedding_607_input'\"), but it was called on an input with incompatible shape (None, 61).\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\reshaping\\reshape.py\", line 111, in _fix_unknown_dimension\n        raise ValueError(msg)\n\n    ValueError: Exception encountered when calling layer \"reshape_603\" (type Reshape).\n    \n    total size of new array must be unchanged, input_shape = [61, 1], output_shape = [1]\n    \n    Call arguments received by layer \"reshape_603\" (type Reshape):\n      • inputs=tf.Tensor(shape=(None, 61, 1), dtype=float32)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31388/13893326.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# fit model on train set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\anali\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\reshaping\\reshape.py\", line 111, in _fix_unknown_dimension\n        raise ValueError(msg)\n\n    ValueError: Exception encountered when calling layer \"reshape_603\" (type Reshape).\n    \n    total size of new array must be unchanged, input_shape = [61, 1], output_shape = [1]\n    \n    Call arguments received by layer \"reshape_603\" (type Reshape):\n      • inputs=tf.Tensor(shape=(None, 61, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "batch=1000\n",
        "epochs=100\n",
        "# fit model on train set\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=batch,\n",
        "    epochs=epochs,\n",
        "#     shuffle=True,\n",
        "    verbose=1,\n",
        "    validation_data=(X_val, y_val),\n",
        ")\n",
        "score = model.evaluate(X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a0276b8",
      "metadata": {
        "id": "6a0276b8"
      },
      "source": [
        "### K-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "436b62e0",
      "metadata": {
        "id": "436b62e0"
      },
      "outputs": [],
      "source": [
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((input_train, input_test), axis=0)\n",
        "targets = np.concatenate((target_train, target_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "    # Define the model architecture\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=loss_function,\n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    # Generate a print\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "    # Fit data to model\n",
        "    history = model.fit(inputs[train], targets[train],\n",
        "              batch_size=batch_size,\n",
        "              epochs=no_epochs,\n",
        "              verbose=verbosity)\n",
        "\n",
        "    # Generate generalization metrics\n",
        "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "779c9624",
      "metadata": {
        "id": "779c9624"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00dd4df5",
      "metadata": {
        "id": "00dd4df5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "name": "02-basic_model.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}