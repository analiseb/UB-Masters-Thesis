{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b62aa9f5",
      "metadata": {
        "id": "b62aa9f5"
      },
      "source": [
        "## Post-processing Mitigation Methods: AIF360\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install aif360\n",
        "# ! pip install BlackBoxAuditing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq8CBZGU3vCh",
        "outputId": "edf8ddb5-fdea-4e0a-c84e-eec5ae5b2858"
      },
      "id": "bq8CBZGU3vCh",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: aif360 in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.0.2)\n",
            "Requirement already satisfied: scipy<1.6.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.5.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360) (3.2.2)\n",
            "Requirement already satisfied: tempeh in /usr/local/lib/python3.7/dist-packages (from aif360) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->aif360) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->aif360) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->aif360) (4.1.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (3.6.4)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (0.41.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (2.23.0)\n",
            "Requirement already satisfied: memory-profiler in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (0.60.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler->tempeh->aif360) (5.4.8)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.11.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (57.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (22.1.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (8.14.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2.10)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (1.5.0)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (4.64.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (0.56.0)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (0.0.7)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (21.3)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap->tempeh->aif360) (0.39.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba->shap->tempeh->aif360) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->shap->tempeh->aif360) (3.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "fd8d3312",
      "metadata": {
        "id": "fd8d3312"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import fairness_helpers as fh\n",
        "import utilities\n",
        "import global_variables as gv\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.optimizers  import Adam, Adagrad, SGD, RMSprop\n",
        "\n",
        "from aif360.sklearn.postprocessing import CalibratedEqualizedOdds, PostProcessingMeta\n",
        "from aif360.sklearn.metrics import disparate_impact_ratio, average_odds_error, generalized_fpr\n",
        "from aif360.sklearn.metrics import generalized_fnr, difference\n",
        "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
        "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
        "# from common_utils import compute_metrics\n",
        "from aif360.datasets import StandardDataset, BinaryLabelDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
        "from aif360.algorithms.postprocessing.calibrated_eq_odds_postprocessing import CalibratedEqOddsPostprocessing\n",
        "from tqdm import tqdm\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e96f3165",
      "metadata": {
        "id": "e96f3165",
        "outputId": "780c3212-e01b-4461-ae44-8ae48ce04770"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>.container { width:80% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XRDe0qU37MK",
        "outputId": "f2d2fd3f-d5db-4870-e4b3-f58617710bcc"
      },
      "id": "_XRDe0qU37MK",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5646fdbc",
      "metadata": {
        "id": "5646fdbc"
      },
      "source": [
        "### load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8647ec74",
      "metadata": {
        "id": "8647ec74"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('saved_models/mlp_binary_1.h5')\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=SGD(learning_rate=0.0005),\n",
        "              metrics=['acc',tf.keras.metrics.AUC(), tf.keras.metrics.Recall()])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f0fca1e",
      "metadata": {
        "id": "7f0fca1e"
      },
      "source": [
        "### get data & convert to AIF360 BinaryLabelDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "93b373d7",
      "metadata": {
        "id": "93b373d7"
      },
      "outputs": [],
      "source": [
        "_, X1 = fh.get_aif360_data(colab=True)\n",
        "\n",
        "dataset1b = BinaryLabelDataset(df=X1, \n",
        "                          label_names=['CVD'], \n",
        "                          protected_attribute_names=['sex-binary'])\n",
        "\n",
        "dataset2b = BinaryLabelDataset(df=X1, \n",
        "                          label_names=['CVD'], \n",
        "                          protected_attribute_names=['race-binary'])\n",
        "\n",
        "dataset3b = BinaryLabelDataset(df=X1, \n",
        "                          label_names=['CVD'], \n",
        "                          protected_attribute_names=['age-binary'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "eb377a77",
      "metadata": {
        "id": "eb377a77"
      },
      "outputs": [],
      "source": [
        "# split into train, validation, and test partitions\n",
        "\n",
        "dataset_orig_train1, dataset_orig_vt1 = dataset1b.split([0.6], shuffle=True)\n",
        "dataset_orig_valid1, dataset_orig_test1 = dataset1b.split([0.5], shuffle=True)\n",
        "\n",
        "dataset_orig_train2, dataset_orig_vt2 = dataset2b.split([0.6], shuffle=True)\n",
        "dataset_orig_valid2, dataset_orig_test2 = dataset2b.split([0.5], shuffle=True)\n",
        "\n",
        "dataset_orig_train3, dataset_orig_vt3 = dataset3b.split([0.6], shuffle=True)\n",
        "dataset_orig_valid3, dataset_orig_test3 = dataset3b.split([0.5], shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "c71af6f0",
      "metadata": {
        "scrolled": true,
        "id": "c71af6f0"
      },
      "outputs": [],
      "source": [
        "# sex\n",
        "X_train1 = dataset_orig_train1.features[:,:-4]\n",
        "y_train1 = dataset_orig_train1.labels\n",
        "\n",
        "X_val1 = dataset_orig_valid1.features[:,:-4]\n",
        "y_val1 = dataset_orig_valid1.labels\n",
        "\n",
        "X_test1 = dataset_orig_test1.features[:,:-4]\n",
        "y_test1 = dataset_orig_test1.labels\n",
        "\n",
        "# race\n",
        "X_train2 = dataset_orig_train2.features[:,:-4]\n",
        "y_train2 = dataset_orig_train2.labels\n",
        "\n",
        "X_val2 = dataset_orig_valid2.features[:,:-4]\n",
        "y_val2 = dataset_orig_valid2.labels\n",
        "\n",
        "X_test2 = dataset_orig_test2.features[:,:-4]\n",
        "y_test2 = dataset_orig_test2.labels\n",
        "\n",
        "# age\n",
        "X_train3 = dataset_orig_train3.features[:,:-4]\n",
        "y_train3 = dataset_orig_train3.labels\n",
        "\n",
        "X_val3 = dataset_orig_valid3.features[:,:-4]\n",
        "y_val3 = dataset_orig_valid3.labels\n",
        "\n",
        "X_test3 = dataset_orig_test3.features[:,:-4]\n",
        "y_test3 = dataset_orig_test3.labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2c5b2e3",
      "metadata": {
        "id": "e2c5b2e3"
      },
      "source": [
        "#### get original predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "7deafb28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7deafb28",
        "outputId": "82580713-22a4-4875-a202-b8245e7f8a5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9422/9422 [==============================] - 58s 6ms/step - loss: 0.2693 - acc: 0.9082 - auc_1: 0.7580 - recall_1: 0.0065\n"
          ]
        }
      ],
      "source": [
        "# sex\n",
        "model.fit(X_train1, y_train1)\n",
        "y_train_pred_prob1 = model.predict(X_train1)\n",
        "y_val_pred_prob1 = model.predict(X_val1)\n",
        "y_test_pred_prob1 = model.predict(X_test1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# race\n",
        "model.fit(X_train2, y_train2)\n",
        "y_train_pred_prob2 = model.predict(X_train2)\n",
        "y_val_pred_prob2 = model.predict(X_val2)\n",
        "y_test_pred_prob2 = model.predict(X_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmEfvIt04yvp",
        "outputId": "a8510d39-9d48-456c-cdee-0c86d989f225"
      },
      "id": "hmEfvIt04yvp",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9422/9422 [==============================] - 56s 6ms/step - loss: 0.2688 - acc: 0.9082 - auc_1: 0.7594 - recall_1: 0.0074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# age\n",
        "model.fit(X_train3, y_train3)\n",
        "y_train_pred_prob3 = model.predict(X_train3)\n",
        "y_val_pred_prob3 = model.predict(X_val3)\n",
        "y_test_pred_prob3 = model.predict(X_test3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWulJJcn9wnK",
        "outputId": "fae4520e-eba4-41aa-f092-85270e981020"
      },
      "id": "JWulJJcn9wnK",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9422/9422 [==============================] - 59s 6ms/step - loss: 0.2696 - acc: 0.9080 - auc_1: 0.7585 - recall_1: 0.0072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_thresh = 0.609388\n",
        "\n",
        "# Placeholder for predicted and transformed datasets (sex)\n",
        "dataset_orig_train_pred1 = dataset_orig_train1.copy(deepcopy=True)\n",
        "dataset_orig_valid_pred1 = dataset_orig_valid1.copy(deepcopy=True)\n",
        "dataset_orig_test_pred1 = dataset_orig_test1.copy(deepcopy=True)\n",
        "\n",
        "# insert prediction scores\n",
        "dataset_orig_train_pred1.scores = y_train_pred_prob1.reshape(-1,1)\n",
        "dataset_orig_valid_pred1.scores = y_val_pred_prob1.reshape(-1,1)\n",
        "dataset_orig_test_pred1.scores = y_test_pred_prob1.reshape(-1,1)\n",
        "\n",
        "# get labels from probabilities\n",
        "y_train_pred1 = np.zeros_like(dataset_orig_train_pred1.labels)\n",
        "y_train_pred1[y_train_pred_prob1 >= class_thresh] = dataset_orig_train_pred1.favorable_label\n",
        "y_train_pred1[~(y_train_pred_prob1 >= class_thresh)] = dataset_orig_train_pred1.unfavorable_label\n",
        "dataset_orig_train_pred1.labels = y_train_pred1\n",
        "\n",
        "y_valid_pred1 = np.zeros_like(dataset_orig_valid_pred1.labels)\n",
        "y_valid_pred1[y_val_pred_prob1 >= class_thresh] = dataset_orig_valid_pred1.favorable_label\n",
        "y_valid_pred1[~(y_val_pred_prob1 >= class_thresh)] = dataset_orig_valid_pred1.unfavorable_label\n",
        "dataset_orig_valid_pred1.labels = y_valid_pred1\n",
        "    \n",
        "y_test_pred1 = np.zeros_like(dataset_orig_test_pred1.labels)\n",
        "y_test_pred1[y_test_pred_prob1 >= class_thresh] = dataset_orig_test_pred1.favorable_label\n",
        "y_test_pred1[~(y_test_pred_prob1 >= class_thresh)] = dataset_orig_test_pred1.unfavorable_label\n",
        "dataset_orig_test_pred1.labels = y_test_pred1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Placeholder for predicted and transformed datasets (race)\n",
        "dataset_orig_train_pred2 = dataset_orig_train2.copy(deepcopy=True)\n",
        "dataset_orig_valid_pred2 = dataset_orig_valid2.copy(deepcopy=True)\n",
        "dataset_orig_test_pred2 = dataset_orig_test2.copy(deepcopy=True)\n",
        "\n",
        "# insert prediction scores\n",
        "dataset_orig_train_pred2.scores = y_train_pred_prob2.reshape(-1,1)\n",
        "dataset_orig_valid_pred2.scores = y_val_pred_prob2.reshape(-1,1)\n",
        "dataset_orig_test_pred2.scores = y_test_pred_prob2.reshape(-1,1)\n",
        "\n",
        "# get labels from probabilities\n",
        "y_train_pred2 = np.zeros_like(dataset_orig_train_pred2.labels)\n",
        "y_train_pred2[y_train_pred_prob2 >= class_thresh] = dataset_orig_train_pred2.favorable_label\n",
        "y_train_pred2[~(y_train_pred_prob2 >= class_thresh)] = dataset_orig_train_pred2.unfavorable_label\n",
        "dataset_orig_train_pred2.labels = y_train_pred2\n",
        "\n",
        "y_valid_pred2 = np.zeros_like(dataset_orig_valid_pred2.labels)\n",
        "y_valid_pred2[y_val_pred_prob2 >= class_thresh] = dataset_orig_valid_pred2.favorable_label\n",
        "y_valid_pred2[~(y_val_pred_prob2 >= class_thresh)] = dataset_orig_valid_pred2.unfavorable_label\n",
        "dataset_orig_valid_pred2.labels = y_valid_pred2\n",
        "    \n",
        "y_test_pred2 = np.zeros_like(dataset_orig_test_pred2.labels)\n",
        "y_test_pred2[y_test_pred_prob2 >= class_thresh] = dataset_orig_test_pred2.favorable_label\n",
        "y_test_pred2[~(y_test_pred_prob2 >= class_thresh)] = dataset_orig_test_pred2.unfavorable_label\n",
        "dataset_orig_test_pred2.labels = y_test_pred2\n",
        "\n",
        "\n",
        "\n",
        "# Placeholder for predicted and transformed datasets (age)\n",
        "dataset_orig_train_pred3 = dataset_orig_train3.copy(deepcopy=True)\n",
        "dataset_orig_valid_pred3 = dataset_orig_valid3.copy(deepcopy=True)\n",
        "dataset_orig_test_pred3 = dataset_orig_test3.copy(deepcopy=True)\n",
        "\n",
        "# insert prediction scores\n",
        "dataset_orig_train_pred3.scores = y_train_pred_prob3.reshape(-1,1)\n",
        "dataset_orig_valid_pred3.scores = y_val_pred_prob3.reshape(-1,1)\n",
        "dataset_orig_test_pred3.scores = y_test_pred_prob3.reshape(-1,1)\n",
        "\n",
        "# get labels from probabilities\n",
        "y_train_pred3 = np.zeros_like(dataset_orig_train_pred3.labels)\n",
        "y_train_pred3[y_train_pred_prob3 >= class_thresh] = dataset_orig_train_pred3.favorable_label\n",
        "y_train_pred3[~(y_train_pred_prob3 >= class_thresh)] = dataset_orig_train_pred3.unfavorable_label\n",
        "dataset_orig_train_pred3.labels = y_train_pred3\n",
        "\n",
        "y_valid_pred3 = np.zeros_like(dataset_orig_valid_pred3.labels)\n",
        "y_valid_pred3[y_val_pred_prob3 >= class_thresh] = dataset_orig_valid_pred3.favorable_label\n",
        "y_valid_pred3[~(y_val_pred_prob3 >= class_thresh)] = dataset_orig_valid_pred3.unfavorable_label\n",
        "dataset_orig_valid_pred3.labels = y_valid_pred3\n",
        "    \n",
        "y_test_pred3 = np.zeros_like(dataset_orig_test_pred3.labels)\n",
        "y_test_pred3[y_test_pred_prob3 >= class_thresh] = dataset_orig_test_pred3.favorable_label\n",
        "y_test_pred3[~(y_test_pred_prob3 >= class_thresh)] = dataset_orig_test_pred3.unfavorable_label\n",
        "dataset_orig_test_pred3.labels = y_test_pred3"
      ],
      "metadata": {
        "id": "H-eVY488BCrx"
      },
      "id": "H-eVY488BCrx",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6bdd6c33",
      "metadata": {
        "id": "6bdd6c33"
      },
      "source": [
        "### Method 1. Calibrated Equalized Odds Post-processing\n",
        "\n",
        "Optimizes over calibrated classifier score outputs to find probabilities with which to change output labels with an equalized odds objective"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eef732ca",
      "metadata": {
        "id": "eef732ca"
      },
      "source": [
        "#### construct calibrated classifier for each protected attribute & constraint (FNR & weighted(fnr/fpr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "be640614",
      "metadata": {
        "id": "be640614"
      },
      "outputs": [],
      "source": [
        "# cost constraint of fnr will optimize generalized false negative rates, that of\n",
        "# fpr will optimize generalized false positive rates, and weighted will optimize\n",
        "# a weighted combination of both\n",
        "cost_constraint_fnr = \"fnr\" # \"fnr\", \"fpr\", \"weighted\"\n",
        "cost_constraint_weighted = \"weighted\"\n",
        "randseed = 156"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "28f7a660",
      "metadata": {
        "id": "28f7a660"
      },
      "outputs": [],
      "source": [
        "p1, u1 = fh.get_att_privilege_groups('sex-binary')\n",
        "p2, u2 = fh.get_att_privilege_groups('race-binary')\n",
        "p3, u3 = fh.get_att_privilege_groups('age-binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "cedf0320",
      "metadata": {
        "id": "cedf0320"
      },
      "outputs": [],
      "source": [
        "# Learn parameters to equalize odds and apply to create a new dataset\n",
        "\n",
        "# fnr constraint\n",
        "cpp_sex_fnr = CalibratedEqOddsPostprocessing(privileged_groups = p1,\n",
        "                                     unprivileged_groups = u1,\n",
        "                                     cost_constraint=cost_constraint_fnr,\n",
        "                                     seed=randseed)\n",
        "\n",
        "cpp_race_fnr = CalibratedEqOddsPostprocessing(privileged_groups = p2,\n",
        "                                     unprivileged_groups = u2,\n",
        "                                     cost_constraint=cost_constraint_fnr,\n",
        "                                     seed=randseed)\n",
        "\n",
        "cpp_age_fnr = CalibratedEqOddsPostprocessing(privileged_groups = p3,\n",
        "                                     unprivileged_groups = u3,\n",
        "                                     cost_constraint=cost_constraint_fnr,\n",
        "                                     seed=randseed)\n",
        "\n",
        "# weighted constraint\n",
        "cpp_sex_weighted = CalibratedEqOddsPostprocessing(privileged_groups = p1,\n",
        "                                     unprivileged_groups = u1,\n",
        "                                     cost_constraint=cost_constraint_weighted,\n",
        "                                     seed=randseed)\n",
        "\n",
        "cpp_race_weighted = CalibratedEqOddsPostprocessing(privileged_groups = p2,\n",
        "                                     unprivileged_groups = u2,\n",
        "                                     cost_constraint=cost_constraint_weighted,\n",
        "                                     seed=randseed)\n",
        "\n",
        "cpp_age_weighted = CalibratedEqOddsPostprocessing(privileged_groups = p3,\n",
        "                                     unprivileged_groups = u3,\n",
        "                                     cost_constraint=cost_constraint_weighted,\n",
        "                                     seed=randseed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f5b96d6",
      "metadata": {
        "id": "2f5b96d6"
      },
      "source": [
        "#### perform odds equalizing post processing on scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "90ae9b27",
      "metadata": {
        "id": "90ae9b27"
      },
      "outputs": [],
      "source": [
        "# sex\n",
        "cpp_sex_fnr = cpp_sex_fnr.fit(dataset_orig_valid1, dataset_orig_valid_pred1)\n",
        "cpp_sex_weighted = cpp_sex_weighted.fit(dataset_orig_valid1, dataset_orig_valid_pred1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "0dbb8f70",
      "metadata": {
        "id": "0dbb8f70"
      },
      "outputs": [],
      "source": [
        "# race\n",
        "cpp_race_fnr = cpp_race_fnr.fit(dataset_orig_valid2, dataset_orig_valid_pred2)\n",
        "cpp_race_weighted = cpp_race_weighted.fit(dataset_orig_valid2, dataset_orig_valid_pred2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "e26cadd8",
      "metadata": {
        "id": "e26cadd8"
      },
      "outputs": [],
      "source": [
        "# age \n",
        "cpp_age_fnr = cpp_age_fnr.fit(dataset_orig_valid3, dataset_orig_valid_pred3)\n",
        "cpp_age_weighted = cpp_age_weighted.fit(dataset_orig_valid3, dataset_orig_valid_pred3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "026e93ee",
      "metadata": {
        "id": "026e93ee"
      },
      "source": [
        "### transform validation and test data using the post processing algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "b7871a18",
      "metadata": {
        "id": "b7871a18"
      },
      "outputs": [],
      "source": [
        "# sex fnr transform\n",
        "dataset_transf_valid_pred11 = cpp_sex_fnr.predict(dataset_orig_valid_pred1)\n",
        "dataset_transf_test_pred11 = cpp_sex_fnr.predict(dataset_orig_test_pred1)\n",
        "\n",
        "# sex weighted transform\n",
        "dataset_transf_valid_pred12 = cpp_sex_weighted.predict(dataset_orig_valid_pred1)\n",
        "dataset_transf_test_pred12 = cpp_sex_weighted.predict(dataset_orig_test_pred1)\n",
        "\n",
        "# race fnr transform\n",
        "dataset_transf_valid_pred21 = cpp_race_fnr.predict(dataset_orig_valid_pred2)\n",
        "dataset_transf_test_pred21 = cpp_race_fnr.predict(dataset_orig_test_pred2)\n",
        "\n",
        "# race weighted transform\n",
        "dataset_transf_valid_pred22 = cpp_race_weighted.predict(dataset_orig_valid_pred2)\n",
        "dataset_transf_test_pred22 = cpp_race_weighted.predict(dataset_orig_test_pred2)\n",
        "\n",
        "# age fnr transform\n",
        "dataset_transf_valid_pred31 = cpp_age_fnr.predict(dataset_orig_valid_pred3)\n",
        "dataset_transf_test_pred31 = cpp_age_fnr.predict(dataset_orig_test_pred3)\n",
        "\n",
        "# age weighted transform\n",
        "dataset_transf_valid_pred32 = cpp_age_weighted.predict(dataset_orig_valid_pred3)\n",
        "dataset_transf_test_pred32 = cpp_age_weighted.predict(dataset_orig_test_pred3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Calibrated Equalized Odds Results"
      ],
      "metadata": {
        "id": "0R1UhKEdQF10"
      },
      "id": "0R1UhKEdQF10"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "989bbd86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "989bbd86",
        "outputId": "2cd4b09f-63f8-4e1a-a342-234515654fc8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Classification thresholds used for validation and parameter selection"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 16/25 [01:34<01:05,  7.24s/it]"
          ]
        }
      ],
      "source": [
        "# Thresholds\n",
        "all_thresh = np.linspace(0.01, 0.99, 25)\n",
        "display(Markdown(\"#### Classification thresholds used for validation and parameter selection\"))\n",
        "\n",
        "bef_avg_odds_diff_test = []\n",
        "bef_avg_odds_diff_valid = []\n",
        "aft_avg_odds_diff_test = []\n",
        "aft_avg_odds_diff_valid = []\n",
        "bef_bal_acc_valid = []\n",
        "bef_bal_acc_test = []\n",
        "aft_bal_acc_valid = []\n",
        "aft_bal_acc_test = []\n",
        "for thresh in tqdm(all_thresh):\n",
        "    \n",
        "    dataset_orig_valid_pred_thresh1 = dataset_orig_valid_pred1.copy(deepcopy=True)\n",
        "    dataset_orig_test_pred_thresh1 = dataset_orig_test_pred1.copy(deepcopy=True)\n",
        "    dataset_transf_valid_pred_thresh1 = dataset_transf_valid_pred11.copy(deepcopy=True)\n",
        "    dataset_transf_test_pred_thresh1 = dataset_transf_test_pred11.copy(deepcopy=True)\n",
        "    \n",
        "    # Labels for the datasets from scores\n",
        "    y_temp = np.zeros_like(dataset_orig_valid_pred_thresh1.labels)\n",
        "    y_temp[dataset_orig_valid_pred_thresh1.scores >= thresh] = dataset_orig_valid_pred_thresh1.favorable_label\n",
        "    y_temp[~(dataset_orig_valid_pred_thresh1.scores >= thresh)] = dataset_orig_valid_pred_thresh1.unfavorable_label\n",
        "    dataset_orig_valid_pred_thresh1.labels = y_temp\n",
        "\n",
        "    y_temp = np.zeros_like(dataset_orig_test_pred_thresh1.labels)\n",
        "    y_temp[dataset_orig_test_pred_thresh1.scores >= thresh] = dataset_orig_test_pred_thresh1.favorable_label\n",
        "    y_temp[~(dataset_orig_test_pred_thresh1.scores >= thresh)] = dataset_orig_test_pred_thresh1.unfavorable_label\n",
        "    dataset_orig_test_pred_thresh1.labels = y_temp\n",
        "    \n",
        "    y_temp = np.zeros_like(dataset_transf_valid_pred_thresh1.labels)\n",
        "    y_temp[dataset_transf_valid_pred_thresh1.scores >= thresh] = dataset_transf_valid_pred_thresh1.favorable_label\n",
        "    y_temp[~(dataset_transf_valid_pred_thresh1.scores >= thresh)] = dataset_transf_valid_pred_thresh1.unfavorable_label\n",
        "    dataset_transf_valid_pred_thresh1.labels = y_temp\n",
        "    \n",
        "    y_temp = np.zeros_like(dataset_transf_test_pred_thresh1.labels)\n",
        "    y_temp[dataset_transf_test_pred_thresh1.scores >= thresh] = dataset_transf_test_pred_thresh1.favorable_label\n",
        "    y_temp[~(dataset_transf_test_pred_thresh1.scores >= thresh)] = dataset_transf_test_pred_thresh1.unfavorable_label\n",
        "    dataset_transf_test_pred_thresh1.labels = y_temp\n",
        "    \n",
        "    # Metrics for original validation data\n",
        "    classified_metric_orig_valid = ClassificationMetric(dataset_orig_valid1,\n",
        "                                                 dataset_orig_valid_pred_thresh1,\n",
        "                                                 unprivileged_groups=u1,\n",
        "                                                 privileged_groups=p1)\n",
        "    bef_avg_odds_diff_valid.append(classified_metric_orig_valid.equal_opportunity_difference())\n",
        "\n",
        "    bef_bal_acc_valid.append(0.5*(classified_metric_orig_valid.true_positive_rate()+\n",
        "                              classified_metric_orig_valid.true_negative_rate()))\n",
        "\n",
        "    classified_metric_orig_test = ClassificationMetric(dataset_orig_test1,\n",
        "                                                 dataset_orig_test_pred_thresh1,\n",
        "                                                 unprivileged_groups=u1,\n",
        "                                                 privileged_groups=p1)\n",
        "    bef_avg_odds_diff_test.append(classified_metric_orig_test.equal_opportunity_difference())\n",
        "    bef_bal_acc_test.append(0.5*(classified_metric_orig_test.true_positive_rate()+\n",
        "                              classified_metric_orig_test.true_negative_rate()))\n",
        "\n",
        "    # Metrics for transf validing data\n",
        "    classified_metric_transf_valid = ClassificationMetric(\n",
        "                                     dataset_orig_valid1, \n",
        "                                     dataset_transf_valid_pred_thresh1,\n",
        "                                     unprivileged_groups=u1,\n",
        "                                     privileged_groups=p1)\n",
        "    aft_avg_odds_diff_valid.append(classified_metric_transf_valid.equal_opportunity_difference())\n",
        "    aft_bal_acc_valid.append(0.5*(classified_metric_transf_valid.true_positive_rate()+\n",
        "                              classified_metric_transf_valid.true_negative_rate()))\n",
        "\n",
        "    # Metrics for transf validation data\n",
        "    classified_metric_transf_test = ClassificationMetric(dataset_orig_test1,\n",
        "                                                 dataset_transf_test_pred_thresh1,\n",
        "                                                 unprivileged_groups=u1,\n",
        "                                                 privileged_groups=p1)\n",
        "    aft_avg_odds_diff_test.append(classified_metric_transf_test.equal_opportunity_difference())\n",
        "    aft_bal_acc_test.append(0.5*(classified_metric_transf_test.true_positive_rate()+\n",
        "                                  classified_metric_transf_test.true_negative_rate()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b2f09be",
      "metadata": {
        "id": "2b2f09be"
      },
      "outputs": [],
      "source": [
        "bef_bal_acc_valid = np.array(bef_bal_acc_valid)\n",
        "bef_avg_odds_diff_valid = np.array(bef_avg_odds_diff_valid)\n",
        "\n",
        "aft_bal_acc_valid = np.array(aft_bal_acc_valid)\n",
        "aft_avg_odds_diff_valid = np.array(aft_avg_odds_diff_valid)\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(13,7))\n",
        "ax1.plot(all_thresh, bef_bal_acc_valid, color='b')\n",
        "ax1.plot(all_thresh, aft_bal_acc_valid, color='b', linestyle='dashed')\n",
        "ax1.set_title('Original and Postprocessed validation data', fontsize=16, fontweight='bold')\n",
        "ax1.set_xlabel('Classification Thresholds', fontsize=16, fontweight='bold')\n",
        "ax1.set_ylabel('Balanced Accuracy', color='b', fontsize=16, fontweight='bold')\n",
        "ax1.xaxis.set_tick_params(labelsize=14)\n",
        "ax1.yaxis.set_tick_params(labelsize=14)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(all_thresh, np.abs(bef_avg_odds_diff_valid), color='r')\n",
        "ax2.plot(all_thresh, np.abs(aft_avg_odds_diff_valid), color='r', linestyle='dashed')\n",
        "ax2.set_ylabel('abs(Equal opportunity diff)', color='r', fontsize=16, fontweight='bold')\n",
        "ax2.yaxis.set_tick_params(labelsize=14)\n",
        "ax2.grid(True)\n",
        "fig.legend([\"Balanced Acc. - Orig.\", \"Balanced Acc. - Postproc.\",\n",
        "             \"Equal opp. diff. - Orig.\",\"Equal opp. diff. - Postproc.\",], \n",
        "           fontsize=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10e264d2",
      "metadata": {
        "id": "10e264d2"
      },
      "outputs": [],
      "source": [
        "bef_bal_acc_test = np.array(bef_bal_acc_test)\n",
        "bef_avg_odds_diff_test = np.array(bef_avg_odds_diff_test)\n",
        "\n",
        "aft_bal_acc_test = np.array(aft_bal_acc_test)\n",
        "aft_avg_odds_diff_test = np.array(aft_avg_odds_diff_test)\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(13,7))\n",
        "ax1.plot(all_thresh, bef_bal_acc_test, color='b')\n",
        "ax1.plot(all_thresh, aft_bal_acc_test, color='b', linestyle='dashed')\n",
        "ax1.set_title('Original and Postprocessed testing data', fontsize=16, fontweight='bold')\n",
        "ax1.set_xlabel('Classification Thresholds', fontsize=16, fontweight='bold')\n",
        "ax1.set_ylabel('Balanced Accuracy', color='b', fontsize=16, fontweight='bold')\n",
        "ax1.xaxis.set_tick_params(labelsize=14)\n",
        "ax1.yaxis.set_tick_params(labelsize=14)\n",
        "\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(all_thresh, np.abs(bef_avg_odds_diff_test), color='r')\n",
        "ax2.plot(all_thresh, np.abs(aft_avg_odds_diff_test), color='r', linestyle='dashed')\n",
        "ax2.set_ylabel('abs(Equal opportunity diff)', color='r', fontsize=16, fontweight='bold')\n",
        "ax2.yaxis.set_tick_params(labelsize=14)\n",
        "ax2.grid(True)\n",
        "fig.legend([\"Balanced Acc. - Orig.\", \"Balanced Acc. - Postproc.\",\n",
        "            \"Equal opp. diff. - Orig.\", \"Equal opp. diff. - Postproc.\"], \n",
        "           fontsize=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6cda2b8",
      "metadata": {
        "id": "d6cda2b8"
      },
      "source": [
        "#### alternative method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fabfa2b0",
      "metadata": {
        "id": "fabfa2b0"
      },
      "outputs": [],
      "source": [
        "cal_eq_odds = CalibratedEqualizedOdds('sex', cost_constraint='fnr', random_state=1234567)\n",
        "log_reg = LogisticRegression(solver='lbfgs')\n",
        "postproc = PostProcessingMeta(estimator=log_reg, postprocessor=cal_eq_odds, random_state=1234567)\n",
        "\n",
        "postproc.fit(X_train, y_train)\n",
        "accuracy_score(y_test, postproc.predict(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a9f3f32",
      "metadata": {
        "id": "5a9f3f32"
      },
      "outputs": [],
      "source": [
        "y_pred = postproc.predict_proba(X_test)[:, 1]\n",
        "y_lr = postproc.estimator_.predict_proba(X_test)[:, 1]\n",
        "br = postproc.postprocessor_.base_rates_\n",
        "i = X_test.index.get_level_values('sex-binary') == 1\n",
        "\n",
        "plt.plot([0, br[0]], [0, 1-br[0]], '-b', label='All calibrated classifiers (Females)')\n",
        "plt.plot([0, br[1]], [0, 1-br[1]], '-r', label='All calibrated classifiers (Males)')\n",
        "\n",
        "plt.scatter(generalized_fpr(y_test[~i], y_lr[~i]),\n",
        "            generalized_fnr(y_test[~i], y_lr[~i]),\n",
        "            300, c='b', marker='.', label='Original classifier (Females)')\n",
        "plt.scatter(generalized_fpr(y_test[i], y_lr[i]),\n",
        "            generalized_fnr(y_test[i], y_lr[i]),\n",
        "            300, c='r', marker='.', label='Original classifier (Males)')\n",
        "                                                                        \n",
        "plt.scatter(generalized_fpr(y_test[~i], y_pred[~i]),\n",
        "            generalized_fnr(y_test[~i], y_pred[~i]),\n",
        "            100, c='b', marker='d', label='Post-processed classifier (Females)')\n",
        "plt.scatter(generalized_fpr(y_test[i], y_pred[i]),\n",
        "            generalized_fnr(y_test[i], y_pred[i]),\n",
        "            100, c='r', marker='d', label='Post-processed classifier (Males)')\n",
        "\n",
        "plt.plot([0, 1], [generalized_fnr(y_test, y_pred)]*2, '--', c='0.5')\n",
        "\n",
        "plt.axis('square')\n",
        "plt.xlim([0.0, 0.4])\n",
        "plt.ylim([0.3, 0.7])\n",
        "plt.xlabel('generalized fpr');\n",
        "plt.ylabel('generalized fnr');\n",
        "plt.legend(bbox_to_anchor=(1.04,1), loc='upper left');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9651132",
      "metadata": {
        "id": "b9651132"
      },
      "outputs": [],
      "source": [
        "difference(generalized_fnr, y_test, y_pred, prot_attr='sex')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0df4fe3e",
      "metadata": {
        "id": "0df4fe3e"
      },
      "source": [
        "### Method 2.  Equalized Odds Post-Processing\n",
        "\n",
        "Solves a linear program to find probabilities with which to change output labels to optimize equalized odds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "609e0d90",
      "metadata": {
        "id": "609e0d90"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "01b09ab1",
      "metadata": {
        "id": "01b09ab1"
      },
      "source": [
        "### Method 3. Reject Option Classification\n",
        "\n",
        "Gives favorable outcomes ot unprivileged groups and unfavorable outcomes to priviliged groups in a confidence band around the decision boundary with the highest uncertainty\n",
        "\n",
        "> The debiasing function used is implemented in the RejectOptionClassification class.\n",
        "- Divide the dataset into training, validation, and testing partitions.\n",
        "- Train classifier on original training data.\n",
        "- Estimate the optimal classification threshold, that maximizes balanced accuracy without fairness constraints.\n",
        "- Estimate the optimal classification threshold, and the critical region boundary (ROC margin) using a validation set for the desired constraint on fairness. The best parameters are those that maximize the classification threshold while satisfying the fairness constraints.\n",
        "- The constraints can be used on the following fairness measures:\n",
        "          - Statistical parity difference on the predictions of the classifier\n",
        "          - Average odds difference for the classifier\n",
        "          - Equal opportunity difference for the classifier\n",
        "- Determine the prediction scores for testing data. Using the estimated optimal classification threshold, compute accuracy and fairness metrics.\n",
        "- Using the determined optimal classification threshold and the ROC margin, adjust the predictions. Report accuracy and fairness metric on the new predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "275c0914",
      "metadata": {
        "id": "275c0914"
      },
      "source": [
        "#### estimate optimal parameters for the ROC method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc614000",
      "metadata": {
        "id": "fc614000"
      },
      "outputs": [],
      "source": [
        "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
        "                                 privileged_groups=privileged_groups, \n",
        "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
        "                                  num_class_thresh=100, num_ROC_margin=50,\n",
        "                                  metric_name=metric_name,\n",
        "                                  metric_ub=metric_ub, metric_lb=metric_lb)\n",
        "ROC = ROC.fit(dataset_orig_valid, dataset_orig_valid_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8964651f",
      "metadata": {
        "id": "8964651f"
      },
      "outputs": [],
      "source": [
        "print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
        "print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}