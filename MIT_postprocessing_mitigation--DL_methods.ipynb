{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62aa9f5",
   "metadata": {},
   "source": [
    "## Post-processing Mitigation Methods: AIF360\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8d3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.optimizers  import Adam, Adagrad, SGD, RMSprop\n",
    "\n",
    "from aif360.sklearn.postprocessing import CalibratedEqualizedOdds, PostProcessingMeta\n",
    "from aif360.sklearn.metrics import disparate_impact_ratio, average_odds_error, generalized_fpr\n",
    "from aif360.sklearn.metrics import generalized_fnr, difference\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
    "# from common_utils import compute_metrics\n",
    "\n",
    "from aif360.algorithms.postprocessing.calibrated_eq_odds_postprocessing import CalibratedEqOddsPostprocessing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e616ef43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646fdbc",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8647ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('saved_models/mlp_binary_1.h5')\n",
    "model.compile(loss='categorical_hinge',\n",
    "              optimizer=SGD(learning_rate=0.0005),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd6c33",
   "metadata": {},
   "source": [
    "### Method 1. Calibrated Equalized Odds Post-processing\n",
    "\n",
    "Optimizes over calibrated classifier score outputs to find probabilities with which to change output labels with an equalized odds objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef732ca",
   "metadata": {},
   "source": [
    "### perform odds equalizing post processing on scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf0320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters to equalize odds and apply to create a new dataset\n",
    "\n",
    "# cost_constraint: statistical parity difference\n",
    "cpp_spd = CalibratedEqOddsPostprocessing(privileged_groups = p1,\n",
    "                                     unprivileged_groups = u1,\n",
    "                                     cost_constraint=cost_constraint,\n",
    "                                     seed=randseed)\n",
    "\n",
    "cpp_spd = CalibratedEqOddsPostprocessing(privileged_groups = p1,\n",
    "                                     unprivileged_groups = u1,\n",
    "                                     cost_constraint=cost_constraint,\n",
    "                                     seed=randseed)\n",
    "\n",
    "cpp_spd = CalibratedEqOddsPostprocessing(privileged_groups = p1,\n",
    "                                     unprivileged_groups = u1,\n",
    "                                     cost_constraint=cost_constraint,\n",
    "                                     seed=randseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp = cpp.fit(dataset_orig_valid, dataset_orig_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026e93ee",
   "metadata": {},
   "source": [
    "### transform validation and test data using the post processing algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7871a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transf_valid_pred = cpp.predict(dataset_orig_valid_pred)\n",
    "dataset_transf_test_pred = cpp.predict(dataset_orig_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b97e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing: Check if the rates for validation data has gone down\n",
    "assert np.abs(cm_transf_valid.difference(cm_transf_valid.generalized_false_negative_rate)) < np.abs(cm_pred_valid.difference(cm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989bbd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds\n",
    "all_thresh = np.linspace(0.01, 0.99, 25)\n",
    "display(Markdown(\"#### Classification thresholds used for validation and parameter selection\"))\n",
    "\n",
    "bef_avg_odds_diff_test = []\n",
    "bef_avg_odds_diff_valid = []\n",
    "aft_avg_odds_diff_test = []\n",
    "aft_avg_odds_diff_valid = []\n",
    "bef_bal_acc_valid = []\n",
    "bef_bal_acc_test = []\n",
    "aft_bal_acc_valid = []\n",
    "aft_bal_acc_test = []\n",
    "for thresh in tqdm(all_thresh):\n",
    "    \n",
    "    dataset_orig_valid_pred_thresh = dataset_orig_valid_pred.copy(deepcopy=True)\n",
    "    dataset_orig_test_pred_thresh = dataset_orig_test_pred.copy(deepcopy=True)\n",
    "    dataset_transf_valid_pred_thresh = dataset_transf_valid_pred.copy(deepcopy=True)\n",
    "    dataset_transf_test_pred_thresh = dataset_transf_test_pred.copy(deepcopy=True)\n",
    "    \n",
    "    # Labels for the datasets from scores\n",
    "    y_temp = np.zeros_like(dataset_orig_valid_pred_thresh.labels)\n",
    "    y_temp[dataset_orig_valid_pred_thresh.scores >= thresh] = dataset_orig_valid_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_orig_valid_pred_thresh.scores >= thresh)] = dataset_orig_valid_pred_thresh.unfavorable_label\n",
    "    dataset_orig_valid_pred_thresh.labels = y_temp\n",
    "\n",
    "    y_temp = np.zeros_like(dataset_orig_test_pred_thresh.labels)\n",
    "    y_temp[dataset_orig_test_pred_thresh.scores >= thresh] = dataset_orig_test_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_orig_test_pred_thresh.scores >= thresh)] = dataset_orig_test_pred_thresh.unfavorable_label\n",
    "    dataset_orig_test_pred_thresh.labels = y_temp\n",
    "    \n",
    "    y_temp = np.zeros_like(dataset_transf_valid_pred_thresh.labels)\n",
    "    y_temp[dataset_transf_valid_pred_thresh.scores >= thresh] = dataset_transf_valid_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_transf_valid_pred_thresh.scores >= thresh)] = dataset_transf_valid_pred_thresh.unfavorable_label\n",
    "    dataset_transf_valid_pred_thresh.labels = y_temp\n",
    "    \n",
    "    y_temp = np.zeros_like(dataset_transf_test_pred_thresh.labels)\n",
    "    y_temp[dataset_transf_test_pred_thresh.scores >= thresh] = dataset_transf_test_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_transf_test_pred_thresh.scores >= thresh)] = dataset_transf_test_pred_thresh.unfavorable_label\n",
    "    dataset_transf_test_pred_thresh.labels = y_temp\n",
    "    \n",
    "    # Metrics for original validation data\n",
    "    classified_metric_orig_valid = ClassificationMetric(dataset_orig_valid,\n",
    "                                                 dataset_orig_valid_pred_thresh,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    bef_avg_odds_diff_valid.append(classified_metric_orig_valid.equal_opportunity_difference())\n",
    "\n",
    "    bef_bal_acc_valid.append(0.5*(classified_metric_orig_valid.true_positive_rate()+\n",
    "                              classified_metric_orig_valid.true_negative_rate()))\n",
    "\n",
    "    classified_metric_orig_test = ClassificationMetric(dataset_orig_test,\n",
    "                                                 dataset_orig_test_pred_thresh,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    bef_avg_odds_diff_test.append(classified_metric_orig_test.equal_opportunity_difference())\n",
    "    bef_bal_acc_test.append(0.5*(classified_metric_orig_test.true_positive_rate()+\n",
    "                              classified_metric_orig_test.true_negative_rate()))\n",
    "\n",
    "    # Metrics for transf validing data\n",
    "    classified_metric_transf_valid = ClassificationMetric(\n",
    "                                     dataset_orig_valid, \n",
    "                                     dataset_transf_valid_pred_thresh,\n",
    "                                     unprivileged_groups=unprivileged_groups,\n",
    "                                     privileged_groups=privileged_groups)\n",
    "    aft_avg_odds_diff_valid.append(classified_metric_transf_valid.equal_opportunity_difference())\n",
    "    aft_bal_acc_valid.append(0.5*(classified_metric_transf_valid.true_positive_rate()+\n",
    "                              classified_metric_transf_valid.true_negative_rate()))\n",
    "\n",
    "    # Metrics for transf validation data\n",
    "    classified_metric_transf_test = ClassificationMetric(dataset_orig_test,\n",
    "                                                 dataset_transf_test_pred_thresh,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    aft_avg_odds_diff_test.append(classified_metric_transf_test.equal_opportunity_difference())\n",
    "    aft_bal_acc_test.append(0.5*(classified_metric_transf_test.true_positive_rate()+\n",
    "                                  classified_metric_transf_test.true_negative_rate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "bef_bal_acc_valid = np.array(bef_bal_acc_valid)\n",
    "bef_avg_odds_diff_valid = np.array(bef_avg_odds_diff_valid)\n",
    "\n",
    "aft_bal_acc_valid = np.array(aft_bal_acc_valid)\n",
    "aft_avg_odds_diff_valid = np.array(aft_avg_odds_diff_valid)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(13,7))\n",
    "ax1.plot(all_thresh, bef_bal_acc_valid, color='b')\n",
    "ax1.plot(all_thresh, aft_bal_acc_valid, color='b', linestyle='dashed')\n",
    "ax1.set_title('Original and Postprocessed validation data', fontsize=16, fontweight='bold')\n",
    "ax1.set_xlabel('Classification Thresholds', fontsize=16, fontweight='bold')\n",
    "ax1.set_ylabel('Balanced Accuracy', color='b', fontsize=16, fontweight='bold')\n",
    "ax1.xaxis.set_tick_params(labelsize=14)\n",
    "ax1.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(all_thresh, np.abs(bef_avg_odds_diff_valid), color='r')\n",
    "ax2.plot(all_thresh, np.abs(aft_avg_odds_diff_valid), color='r', linestyle='dashed')\n",
    "ax2.set_ylabel('abs(Equal opportunity diff)', color='r', fontsize=16, fontweight='bold')\n",
    "ax2.yaxis.set_tick_params(labelsize=14)\n",
    "ax2.grid(True)\n",
    "fig.legend([\"Balanced Acc. - Orig.\", \"Balanced Acc. - Postproc.\",\n",
    "             \"Equal opp. diff. - Orig.\",\"Equal opp. diff. - Postproc.\",], \n",
    "           fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e264d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bef_bal_acc_test = np.array(bef_bal_acc_test)\n",
    "bef_avg_odds_diff_test = np.array(bef_avg_odds_diff_test)\n",
    "\n",
    "aft_bal_acc_test = np.array(aft_bal_acc_test)\n",
    "aft_avg_odds_diff_test = np.array(aft_avg_odds_diff_test)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(13,7))\n",
    "ax1.plot(all_thresh, bef_bal_acc_test, color='b')\n",
    "ax1.plot(all_thresh, aft_bal_acc_test, color='b', linestyle='dashed')\n",
    "ax1.set_title('Original and Postprocessed testing data', fontsize=16, fontweight='bold')\n",
    "ax1.set_xlabel('Classification Thresholds', fontsize=16, fontweight='bold')\n",
    "ax1.set_ylabel('Balanced Accuracy', color='b', fontsize=16, fontweight='bold')\n",
    "ax1.xaxis.set_tick_params(labelsize=14)\n",
    "ax1.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(all_thresh, np.abs(bef_avg_odds_diff_test), color='r')\n",
    "ax2.plot(all_thresh, np.abs(aft_avg_odds_diff_test), color='r', linestyle='dashed')\n",
    "ax2.set_ylabel('abs(Equal opportunity diff)', color='r', fontsize=16, fontweight='bold')\n",
    "ax2.yaxis.set_tick_params(labelsize=14)\n",
    "ax2.grid(True)\n",
    "fig.legend([\"Balanced Acc. - Orig.\", \"Balanced Acc. - Postproc.\",\n",
    "            \"Equal opp. diff. - Orig.\", \"Equal opp. diff. - Postproc.\"], \n",
    "           fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cda2b8",
   "metadata": {},
   "source": [
    "#### alternative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabfa2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_eq_odds = CalibratedEqualizedOdds('sex', cost_constraint='fnr', random_state=1234567)\n",
    "log_reg = LogisticRegression(solver='lbfgs')\n",
    "postproc = PostProcessingMeta(estimator=log_reg, postprocessor=cal_eq_odds, random_state=1234567)\n",
    "\n",
    "postproc.fit(X_train, y_train)\n",
    "accuracy_score(y_test, postproc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = postproc.predict_proba(X_test)[:, 1]\n",
    "y_lr = postproc.estimator_.predict_proba(X_test)[:, 1]\n",
    "br = postproc.postprocessor_.base_rates_\n",
    "i = X_test.index.get_level_values('sex-binary') == 1\n",
    "\n",
    "plt.plot([0, br[0]], [0, 1-br[0]], '-b', label='All calibrated classifiers (Females)')\n",
    "plt.plot([0, br[1]], [0, 1-br[1]], '-r', label='All calibrated classifiers (Males)')\n",
    "\n",
    "plt.scatter(generalized_fpr(y_test[~i], y_lr[~i]),\n",
    "            generalized_fnr(y_test[~i], y_lr[~i]),\n",
    "            300, c='b', marker='.', label='Original classifier (Females)')\n",
    "plt.scatter(generalized_fpr(y_test[i], y_lr[i]),\n",
    "            generalized_fnr(y_test[i], y_lr[i]),\n",
    "            300, c='r', marker='.', label='Original classifier (Males)')\n",
    "                                                                        \n",
    "plt.scatter(generalized_fpr(y_test[~i], y_pred[~i]),\n",
    "            generalized_fnr(y_test[~i], y_pred[~i]),\n",
    "            100, c='b', marker='d', label='Post-processed classifier (Females)')\n",
    "plt.scatter(generalized_fpr(y_test[i], y_pred[i]),\n",
    "            generalized_fnr(y_test[i], y_pred[i]),\n",
    "            100, c='r', marker='d', label='Post-processed classifier (Males)')\n",
    "\n",
    "plt.plot([0, 1], [generalized_fnr(y_test, y_pred)]*2, '--', c='0.5')\n",
    "\n",
    "plt.axis('square')\n",
    "plt.xlim([0.0, 0.4])\n",
    "plt.ylim([0.3, 0.7])\n",
    "plt.xlabel('generalized fpr');\n",
    "plt.ylabel('generalized fnr');\n",
    "plt.legend(bbox_to_anchor=(1.04,1), loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9651132",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference(generalized_fnr, y_test, y_pred, prot_attr='sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df4fe3e",
   "metadata": {},
   "source": [
    "### Method 2.  Equalized Odds Post-Processing\n",
    "\n",
    "Solves a linear program to find probabilities with which to change output labels to optimize equalized odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609e0d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01b09ab1",
   "metadata": {},
   "source": [
    "### Method 3. Reject Option Classification\n",
    "\n",
    "Gives favorable outcomes ot unprivileged groups and unfavorable outcomes to priviliged groups in a confidence band around the decision boundary with the highest uncertainty\n",
    "\n",
    "> The debiasing function used is implemented in the RejectOptionClassification class.\n",
    "- Divide the dataset into training, validation, and testing partitions.\n",
    "- Train classifier on original training data.\n",
    "- Estimate the optimal classification threshold, that maximizes balanced accuracy without fairness constraints.\n",
    "- Estimate the optimal classification threshold, and the critical region boundary (ROC margin) using a validation set for the desired constraint on fairness. The best parameters are those that maximize the classification threshold while satisfying the fairness constraints.\n",
    "- The constraints can be used on the following fairness measures:\n",
    "          - Statistical parity difference on the predictions of the classifier\n",
    "          - Average odds difference for the classifier\n",
    "          - Equal opportunity difference for the classifier\n",
    "- Determine the prediction scores for testing data. Using the estimated optimal classification threshold, compute accuracy and fairness metrics.\n",
    "- Using the determined optimal classification threshold and the ROC margin, adjust the predictions. Report accuracy and fairness metric on the new predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275c0914",
   "metadata": {},
   "source": [
    "#### estimate optimal parameters for the ROC method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc614000",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                  num_class_thresh=100, num_ROC_margin=50,\n",
    "                                  metric_name=metric_name,\n",
    "                                  metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "ROC = ROC.fit(dataset_orig_valid, dataset_orig_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8964651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
