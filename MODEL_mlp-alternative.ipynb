{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9d0f0353",
      "metadata": {
        "id": "9d0f0353"
      },
      "outputs": [],
      "source": [
        "# Importing core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "import pprint\n",
        "import joblib\n",
        "import global_variables as gv\n",
        "import utilities\n",
        "\n",
        "# Model selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "# Data transformation pipelines\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import QuantileTransformer, RobustScaler, StandardScaler,MinMaxScaler\n",
        "\n",
        "# Graphics\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d88b1262",
      "metadata": {
        "id": "d88b1262"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, PReLU\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Concatenate\n",
        "from tensorflow.keras.optimizers  import Adam, Adagrad, SGD\n",
        "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "440b3c88",
      "metadata": {
        "id": "440b3c88"
      },
      "outputs": [],
      "source": [
        "# Importing from Scikit-Learn\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA, FactorAnalysis\n",
        "\n",
        "from keras.layers import Input, Embedding, Reshape\n",
        "from keras.layers import Flatten, concatenate, Concatenate, Lambda, Dropout\n",
        "from keras.layers import Activation, LeakyReLU\n",
        "from keras.models import Model, load_model\n",
        "from keras.losses import binary_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed55b3cd",
      "metadata": {
        "id": "ed55b3cd",
        "outputId": "ff1a7971-259a-4ca7-ddb8-2863b3343ef7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>.container { width:80% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ce03cbb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "ce03cbb9",
        "outputId": "30967952-cd87-47f4-9577-6966f38533b5",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   1319-0.0  1408-0.0  1329-0.0  1448-0.0  1538-0.0  6142-0.0  2050-0.0  \\\n",
              "0       0.0       1.0       2.0       3.0       2.0       1.0       2.0   \n",
              "1       0.0       3.0       2.0       1.0       0.0       1.0       1.0   \n",
              "2       0.0       3.0       3.0       2.0       1.0       2.0       1.0   \n",
              "3       3.0       3.0       3.0       3.0       0.0       2.0       1.0   \n",
              "4       0.0       3.0       2.0       1.0       0.0       5.0       2.0   \n",
              "\n",
              "   1508-0.0  1339-0.0  30710-0.0  1349-0.0  30750-0.0  1468-0.0  20117-0.0  \\\n",
              "0       3.0       2.0       0.34       1.0     34.937       3.0        2.0   \n",
              "1       2.0       2.0       3.94       4.0     40.900       5.0        2.0   \n",
              "2       2.0       2.0       0.55       1.0     40.000       1.0        0.0   \n",
              "3       2.0       2.0       0.45       2.0     37.300       4.0        2.0   \n",
              "4       2.0       2.0       0.75       2.0     32.200       1.0        2.0   \n",
              "\n",
              "   30740-0.0  1160-0.0  2090-0.0  31-0.0  1488-0.0  30850-0.0  4080-0.0  \\\n",
              "0      5.622       7.0       1.0     0.0      6.00      0.508     110.0   \n",
              "1      5.052       9.0       0.0     1.0      2.00     13.088     166.0   \n",
              "2      5.310       5.0       0.0     0.0      0.00      0.515     132.0   \n",
              "3      4.449       7.0       0.0     1.0      5.00      4.675     178.0   \n",
              "4      4.616       6.0       0.0     1.0      3.04     20.162     178.0   \n",
              "\n",
              "   1369-0.0  21000-0.0  1200-0.0  1289-0.0  30790-0.0  845-0.0  48-0.0  \\\n",
              "0       1.0     1001.0       3.0       6.0    54.4035    20.90    74.0   \n",
              "1       2.0     1001.0       2.0       2.0    15.4000    16.00   120.0   \n",
              "2       1.0     1001.0       3.0       2.0    32.1000    16.00    66.0   \n",
              "3       2.0     1001.0       1.0       3.0    43.5620    18.00   110.0   \n",
              "4       1.0     1001.0       3.0       1.0    71.1100    22.38    94.0   \n",
              "\n",
              "   30630-0.0  1299-0.0  1220-0.0  1548-0.0  1528-0.0  23099-0.0  49-0.0  \\\n",
              "0      1.593      10.0       0.0       2.0      2.00       35.6   102.0   \n",
              "1      1.390       2.0       0.0       2.0      2.47       36.5   113.0   \n",
              "2      2.005       4.0       0.0       1.0      1.00       29.5    88.0   \n",
              "3      1.474       2.0       0.0       1.0      2.00       28.5   117.0   \n",
              "4      2.149       1.0       0.0       2.0      2.00       24.8   100.0   \n",
              "\n",
              "   30690-0.0  1389-0.0  2654-0.0  1249-0.0  1309-0.0  1379-0.0  1239-0.0  \\\n",
              "0      6.477       1.0       6.0       1.0       2.0       1.0       0.0   \n",
              "1      5.512       1.0       7.0       1.0       1.0       2.0       0.0   \n",
              "2      7.079       1.0       7.0       3.0       4.0       2.0       0.0   \n",
              "3      5.028       0.0       7.0       1.0       1.0       2.0       1.0   \n",
              "4      7.958       1.0       7.0       2.0       1.0       1.0       0.0   \n",
              "\n",
              "   21003-0.0  30780-0.0  1438-0.0  30870-0.0  1359-0.0  30770-0.0  21001-0.0  \\\n",
              "0       54.0      3.888      10.0      0.977       2.0     26.339    24.5790   \n",
              "1       65.0      3.520      12.0      2.358       3.0     10.701    35.0861   \n",
              "2       69.0      4.227       8.0      0.655       2.0     10.693    19.3835   \n",
              "3       66.0      3.041      10.0      3.108       2.0     25.317    35.1281   \n",
              "4       48.0      4.983       8.0      1.173       1.0     26.523    25.8866   \n",
              "\n",
              "   1458-0.0  23100-0.0  6138-0.0  1418-0.0  1478-0.0  4079-0.0  30760-0.0  \\\n",
              "0      3.86       25.0       1.0       3.0       1.0      77.0      1.706   \n",
              "1      7.00       42.9       3.0       2.0       1.0      91.0      1.173   \n",
              "2      7.00       15.2       3.0       2.0       1.0      67.0      2.490   \n",
              "3      7.00       31.7       3.0       2.0       1.0      84.0      1.169   \n",
              "4      1.00       20.1       1.0       2.0       1.0      88.0      2.053   \n",
              "\n",
              "   23101-0.0  2100-0.0  1428-0.0  30640-0.0  hypertension  \\\n",
              "0       45.2       1.0       0.0      1.211           0.0   \n",
              "1       74.6       0.0       1.0      1.019           1.0   \n",
              "2       36.3       0.0       1.0      1.097           0.0   \n",
              "3       79.6       0.0       3.0      0.923           0.0   \n",
              "4       61.0       0.0       3.0      1.443           0.0   \n",
              "\n",
              "   outcome_cardiomyopathies  outcome_ischemic_heart_disease  \\\n",
              "0                       0.0                             0.0   \n",
              "1                       0.0                             1.0   \n",
              "2                       0.0                             0.0   \n",
              "3                       0.0                             0.0   \n",
              "4                       0.0                             0.0   \n",
              "\n",
              "   outcome_heart_failure  outcome_peripheral_vascular_disease  \\\n",
              "0                    0.0                                  0.0   \n",
              "1                    0.0                                  0.0   \n",
              "2                    0.0                                  0.0   \n",
              "3                    0.0                                  0.0   \n",
              "4                    0.0                                  0.0   \n",
              "\n",
              "   outcome_cardiac_arrest  outcome_cerebral_infarction  outcome_arrhythmia  \\\n",
              "0                     0.0                          0.0                 1.0   \n",
              "1                     0.0                          0.0                 0.0   \n",
              "2                     0.0                          0.0                 0.0   \n",
              "3                     0.0                          0.0                 0.0   \n",
              "4                     0.0                          0.0                 0.0   \n",
              "\n",
              "   outcome_myocardial_infarction  CVD   age     sex     race age-binned  \\\n",
              "0                            0.0  1.0  54.0  Female  British      50-59   \n",
              "1                            1.0  0.0  65.0    Male  British      60-69   \n",
              "2                            0.0  0.0  69.0  Female  British      60-69   \n",
              "3                            0.0  0.0  66.0    Male  British      60-69   \n",
              "4                            0.0  0.0  48.0    Male  British      40-49   \n",
              "\n",
              "   race-binary  \n",
              "0          1.0  \n",
              "1          1.0  \n",
              "2          1.0  \n",
              "3          1.0  \n",
              "4          1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89e75112-813e-4108-ad10-1dcb8e16c69d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1319-0.0</th>\n",
              "      <th>1408-0.0</th>\n",
              "      <th>1329-0.0</th>\n",
              "      <th>1448-0.0</th>\n",
              "      <th>1538-0.0</th>\n",
              "      <th>6142-0.0</th>\n",
              "      <th>2050-0.0</th>\n",
              "      <th>1508-0.0</th>\n",
              "      <th>1339-0.0</th>\n",
              "      <th>30710-0.0</th>\n",
              "      <th>1349-0.0</th>\n",
              "      <th>30750-0.0</th>\n",
              "      <th>1468-0.0</th>\n",
              "      <th>20117-0.0</th>\n",
              "      <th>30740-0.0</th>\n",
              "      <th>1160-0.0</th>\n",
              "      <th>2090-0.0</th>\n",
              "      <th>31-0.0</th>\n",
              "      <th>1488-0.0</th>\n",
              "      <th>30850-0.0</th>\n",
              "      <th>4080-0.0</th>\n",
              "      <th>1369-0.0</th>\n",
              "      <th>21000-0.0</th>\n",
              "      <th>1200-0.0</th>\n",
              "      <th>1289-0.0</th>\n",
              "      <th>30790-0.0</th>\n",
              "      <th>845-0.0</th>\n",
              "      <th>48-0.0</th>\n",
              "      <th>30630-0.0</th>\n",
              "      <th>1299-0.0</th>\n",
              "      <th>1220-0.0</th>\n",
              "      <th>1548-0.0</th>\n",
              "      <th>1528-0.0</th>\n",
              "      <th>23099-0.0</th>\n",
              "      <th>49-0.0</th>\n",
              "      <th>30690-0.0</th>\n",
              "      <th>1389-0.0</th>\n",
              "      <th>2654-0.0</th>\n",
              "      <th>1249-0.0</th>\n",
              "      <th>1309-0.0</th>\n",
              "      <th>1379-0.0</th>\n",
              "      <th>1239-0.0</th>\n",
              "      <th>21003-0.0</th>\n",
              "      <th>30780-0.0</th>\n",
              "      <th>1438-0.0</th>\n",
              "      <th>30870-0.0</th>\n",
              "      <th>1359-0.0</th>\n",
              "      <th>30770-0.0</th>\n",
              "      <th>21001-0.0</th>\n",
              "      <th>1458-0.0</th>\n",
              "      <th>23100-0.0</th>\n",
              "      <th>6138-0.0</th>\n",
              "      <th>1418-0.0</th>\n",
              "      <th>1478-0.0</th>\n",
              "      <th>4079-0.0</th>\n",
              "      <th>30760-0.0</th>\n",
              "      <th>23101-0.0</th>\n",
              "      <th>2100-0.0</th>\n",
              "      <th>1428-0.0</th>\n",
              "      <th>30640-0.0</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>outcome_cardiomyopathies</th>\n",
              "      <th>outcome_ischemic_heart_disease</th>\n",
              "      <th>outcome_heart_failure</th>\n",
              "      <th>outcome_peripheral_vascular_disease</th>\n",
              "      <th>outcome_cardiac_arrest</th>\n",
              "      <th>outcome_cerebral_infarction</th>\n",
              "      <th>outcome_arrhythmia</th>\n",
              "      <th>outcome_myocardial_infarction</th>\n",
              "      <th>CVD</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>race</th>\n",
              "      <th>age-binned</th>\n",
              "      <th>race-binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.0</td>\n",
              "      <td>34.937</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.622</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>0.508</td>\n",
              "      <td>110.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>54.4035</td>\n",
              "      <td>20.90</td>\n",
              "      <td>74.0</td>\n",
              "      <td>1.593</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>35.6</td>\n",
              "      <td>102.0</td>\n",
              "      <td>6.477</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>3.888</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.977</td>\n",
              "      <td>2.0</td>\n",
              "      <td>26.339</td>\n",
              "      <td>24.5790</td>\n",
              "      <td>3.86</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>1.706</td>\n",
              "      <td>45.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>British</td>\n",
              "      <td>50-59</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.94</td>\n",
              "      <td>4.0</td>\n",
              "      <td>40.900</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.052</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>13.088</td>\n",
              "      <td>166.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.4000</td>\n",
              "      <td>16.00</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.390</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.47</td>\n",
              "      <td>36.5</td>\n",
              "      <td>113.0</td>\n",
              "      <td>5.512</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>3.520</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2.358</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.701</td>\n",
              "      <td>35.0861</td>\n",
              "      <td>7.00</td>\n",
              "      <td>42.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>1.173</td>\n",
              "      <td>74.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.019</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>British</td>\n",
              "      <td>60-69</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.55</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.310</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.515</td>\n",
              "      <td>132.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>32.1000</td>\n",
              "      <td>16.00</td>\n",
              "      <td>66.0</td>\n",
              "      <td>2.005</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>29.5</td>\n",
              "      <td>88.0</td>\n",
              "      <td>7.079</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>4.227</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.655</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.693</td>\n",
              "      <td>19.3835</td>\n",
              "      <td>7.00</td>\n",
              "      <td>15.2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>2.490</td>\n",
              "      <td>36.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.097</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>British</td>\n",
              "      <td>60-69</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.45</td>\n",
              "      <td>2.0</td>\n",
              "      <td>37.300</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.449</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.675</td>\n",
              "      <td>178.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>43.5620</td>\n",
              "      <td>18.00</td>\n",
              "      <td>110.0</td>\n",
              "      <td>1.474</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>28.5</td>\n",
              "      <td>117.0</td>\n",
              "      <td>5.028</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>3.041</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3.108</td>\n",
              "      <td>2.0</td>\n",
              "      <td>25.317</td>\n",
              "      <td>35.1281</td>\n",
              "      <td>7.00</td>\n",
              "      <td>31.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>1.169</td>\n",
              "      <td>79.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.923</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>British</td>\n",
              "      <td>60-69</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>2.0</td>\n",
              "      <td>32.200</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.616</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.04</td>\n",
              "      <td>20.162</td>\n",
              "      <td>178.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>71.1100</td>\n",
              "      <td>22.38</td>\n",
              "      <td>94.0</td>\n",
              "      <td>2.149</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>24.8</td>\n",
              "      <td>100.0</td>\n",
              "      <td>7.958</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>4.983</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.173</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.523</td>\n",
              "      <td>25.8866</td>\n",
              "      <td>1.00</td>\n",
              "      <td>20.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2.053</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.443</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>British</td>\n",
              "      <td>40-49</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89e75112-813e-4108-ad10-1dcb8e16c69d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89e75112-813e-4108-ad10-1dcb8e16c69d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89e75112-813e-4108-ad10-1dcb8e16c69d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_csv('binary_full.csv')\n",
        "pd.set_option('display.max_columns', None)\n",
        "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8628e1b",
      "metadata": {
        "id": "a8628e1b"
      },
      "source": [
        "#### Registering custom activations suitable for tabular problems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c7a0e1cc",
      "metadata": {
        "id": "c7a0e1cc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import get_custom_objects\n",
        "from tensorflow.keras.layers import Activation, LeakyReLU\n",
        "import utilities\n",
        "\n",
        "class Mish(Activation):\n",
        "    '''\n",
        "    .. math::\n",
        "        mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + e^{x}))\n",
        "    Shape:\n",
        "        - Input: Arbitrary. Use the keyword argument `input_shape`\n",
        "        (tuple of integers, does not include the samples axis)\n",
        "        when using this layer as the first layer in a model.\n",
        "        - Output: Same shape as the input.\n",
        "    Examples:\n",
        "        >>> X = Activation('Mish', name=\"conv1_act\")(X_input)\n",
        "    '''\n",
        "\n",
        "    def __init__(self, activation, **kwargs):\n",
        "        super(Mish, self).__init__(activation, **kwargs)\n",
        "        self.__name__ = 'Mish'\n",
        "        \n",
        "def mish(inputs):\n",
        "    return inputs * tf.math.tanh(tf.math.softplus(inputs))\n",
        "\n",
        "\n",
        "# Add gelu so we can use it as a string\n",
        "get_custom_objects().update({'gelu': Activation(utilities.gelu)})\n",
        "\n",
        "# Add mish so we can use it as a string\n",
        "get_custom_objects().update({'mish': Mish(mish)})\n",
        "\n",
        "# Add leaky-relu so we can use it as a string\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79f27ac1",
      "metadata": {
        "id": "79f27ac1"
      },
      "source": [
        "### Build MLP Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9f922ee",
      "metadata": {
        "id": "c9f922ee"
      },
      "source": [
        "#### add batch normalization, custom activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0009fde5",
      "metadata": {
        "id": "0009fde5"
      },
      "outputs": [],
      "source": [
        "def mlp_model( X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation='tanh',opt=SGD, lr=0.000001):\n",
        "    \n",
        "    # define model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1000, activation=activation , input_shape=(X_train.shape[1],)))\n",
        "    model.add(Dense(500, activation=activation))\n",
        "    model.add(Dense(500, activation=activation ))\n",
        "    model.add(Dense(200, activation=activation ))\n",
        "    model.add(Dense(1, activation=tf.nn.sigmoid))\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=opt(learning_rate=lr),\n",
        "        metrics=['acc',utilities.f1_m,utilities.precision_m, utilities.recall_m])\n",
        "\n",
        "    # fit model on train set\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=batch,\n",
        "        epochs=epochs,\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        validation_data=(X_val, y_val),\n",
        "    )\n",
        "    score = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return history, score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "6ad05a1b",
      "metadata": {
        "id": "6ad05a1b"
      },
      "outputs": [],
      "source": [
        "epochs =1000\n",
        "batch = 800\n",
        "sample_methods =['ADASYN', 'over', 'under', 'partial_under']\n",
        "activations=['relu', 'tanh', tf.keras.activations.gelu]\n",
        "optimizers = [SGD, Adam, Adagrad]\n",
        "num_transformers = [StandardScaler(), MinMaxScaler(), QuantileTransformer(output_distribution='uniform')]\n",
        "# test one_hot==True/False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "3e51f06c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3e51f06c",
        "outputId": "9ba47c04-7c2f-4fc5-aed0-6148cbfcadcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "7/7 [==============================] - 2s 103ms/step - loss: 0.6956 - acc: 0.4968 - f1_m: 0.0118 - precision_m: 0.3405 - recall_m: 0.0060 - val_loss: 0.6665 - val_acc: 0.8878 - val_f1_m: 0.0114 - val_precision_m: 0.0319 - val_recall_m: 0.0070\n",
            "Epoch 2/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6954 - acc: 0.4954 - f1_m: 0.0160 - precision_m: 0.3020 - recall_m: 0.0082 - val_loss: 0.6683 - val_acc: 0.8838 - val_f1_m: 0.0249 - val_precision_m: 0.0594 - val_recall_m: 0.0159\n",
            "Epoch 3/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6952 - acc: 0.4950 - f1_m: 0.0317 - precision_m: 0.3707 - recall_m: 0.0166 - val_loss: 0.6698 - val_acc: 0.8778 - val_f1_m: 0.0368 - val_precision_m: 0.0729 - val_recall_m: 0.0247\n",
            "Epoch 4/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6949 - acc: 0.4950 - f1_m: 0.0426 - precision_m: 0.3946 - recall_m: 0.0226 - val_loss: 0.6711 - val_acc: 0.8717 - val_f1_m: 0.0472 - val_precision_m: 0.0793 - val_recall_m: 0.0337\n",
            "Epoch 5/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6947 - acc: 0.4952 - f1_m: 0.0568 - precision_m: 0.4252 - recall_m: 0.0306 - val_loss: 0.6724 - val_acc: 0.8650 - val_f1_m: 0.0664 - val_precision_m: 0.0984 - val_recall_m: 0.0504\n",
            "Epoch 6/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6945 - acc: 0.4968 - f1_m: 0.0786 - precision_m: 0.4705 - recall_m: 0.0429 - val_loss: 0.6738 - val_acc: 0.8527 - val_f1_m: 0.0663 - val_precision_m: 0.0846 - val_recall_m: 0.0548\n",
            "Epoch 7/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6943 - acc: 0.4966 - f1_m: 0.0915 - precision_m: 0.4551 - recall_m: 0.0509 - val_loss: 0.6750 - val_acc: 0.8427 - val_f1_m: 0.0756 - val_precision_m: 0.0860 - val_recall_m: 0.0676\n",
            "Epoch 8/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6941 - acc: 0.4954 - f1_m: 0.1081 - precision_m: 0.4542 - recall_m: 0.0616 - val_loss: 0.6763 - val_acc: 0.8312 - val_f1_m: 0.0812 - val_precision_m: 0.0848 - val_recall_m: 0.0786\n",
            "Epoch 9/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6939 - acc: 0.4976 - f1_m: 0.1453 - precision_m: 0.4896 - recall_m: 0.0853 - val_loss: 0.6775 - val_acc: 0.8176 - val_f1_m: 0.1003 - val_precision_m: 0.0948 - val_recall_m: 0.1076\n",
            "Epoch 10/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6938 - acc: 0.4978 - f1_m: 0.1783 - precision_m: 0.5085 - recall_m: 0.1082 - val_loss: 0.6787 - val_acc: 0.8017 - val_f1_m: 0.1197 - val_precision_m: 0.1044 - val_recall_m: 0.1418\n",
            "Epoch 11/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6936 - acc: 0.5014 - f1_m: 0.2094 - precision_m: 0.5188 - recall_m: 0.1317 - val_loss: 0.6798 - val_acc: 0.7875 - val_f1_m: 0.1354 - val_precision_m: 0.1110 - val_recall_m: 0.1749\n",
            "Epoch 12/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6934 - acc: 0.5016 - f1_m: 0.2330 - precision_m: 0.4967 - recall_m: 0.1525 - val_loss: 0.6808 - val_acc: 0.7718 - val_f1_m: 0.1407 - val_precision_m: 0.1102 - val_recall_m: 0.1965\n",
            "Epoch 13/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6932 - acc: 0.5032 - f1_m: 0.2545 - precision_m: 0.4891 - recall_m: 0.1723 - val_loss: 0.6816 - val_acc: 0.7545 - val_f1_m: 0.1463 - val_precision_m: 0.1100 - val_recall_m: 0.2209\n",
            "Epoch 14/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6930 - acc: 0.5074 - f1_m: 0.2769 - precision_m: 0.5025 - recall_m: 0.1917 - val_loss: 0.6820 - val_acc: 0.7451 - val_f1_m: 0.1513 - val_precision_m: 0.1114 - val_recall_m: 0.2382\n",
            "Epoch 15/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6929 - acc: 0.5094 - f1_m: 0.2991 - precision_m: 0.5174 - recall_m: 0.2105 - val_loss: 0.6824 - val_acc: 0.7386 - val_f1_m: 0.1571 - val_precision_m: 0.1140 - val_recall_m: 0.2555\n",
            "Epoch 16/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6927 - acc: 0.5166 - f1_m: 0.3298 - precision_m: 0.5326 - recall_m: 0.2402 - val_loss: 0.6831 - val_acc: 0.7223 - val_f1_m: 0.1665 - val_precision_m: 0.1173 - val_recall_m: 0.2906\n",
            "Epoch 17/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6925 - acc: 0.5219 - f1_m: 0.3646 - precision_m: 0.5542 - recall_m: 0.2725 - val_loss: 0.6837 - val_acc: 0.7119 - val_f1_m: 0.1715 - val_precision_m: 0.1187 - val_recall_m: 0.3128\n",
            "Epoch 18/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6924 - acc: 0.5241 - f1_m: 0.3811 - precision_m: 0.5459 - recall_m: 0.2934 - val_loss: 0.6848 - val_acc: 0.6828 - val_f1_m: 0.1738 - val_precision_m: 0.1160 - val_recall_m: 0.3510\n",
            "Epoch 19/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6922 - acc: 0.5289 - f1_m: 0.4076 - precision_m: 0.5470 - recall_m: 0.3252 - val_loss: 0.6855 - val_acc: 0.6699 - val_f1_m: 0.1828 - val_precision_m: 0.1199 - val_recall_m: 0.3898\n",
            "Epoch 20/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6921 - acc: 0.5339 - f1_m: 0.4205 - precision_m: 0.5356 - recall_m: 0.3475 - val_loss: 0.6861 - val_acc: 0.6555 - val_f1_m: 0.1917 - val_precision_m: 0.1237 - val_recall_m: 0.4310\n",
            "Epoch 21/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6919 - acc: 0.5411 - f1_m: 0.4504 - precision_m: 0.5604 - recall_m: 0.3771 - val_loss: 0.6863 - val_acc: 0.6496 - val_f1_m: 0.1930 - val_precision_m: 0.1239 - val_recall_m: 0.4414\n",
            "Epoch 22/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6917 - acc: 0.5437 - f1_m: 0.4606 - precision_m: 0.5561 - recall_m: 0.3936 - val_loss: 0.6865 - val_acc: 0.6433 - val_f1_m: 0.1956 - val_precision_m: 0.1248 - val_recall_m: 0.4570\n",
            "Epoch 23/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6916 - acc: 0.5447 - f1_m: 0.4765 - precision_m: 0.5649 - recall_m: 0.4128 - val_loss: 0.6869 - val_acc: 0.6327 - val_f1_m: 0.1954 - val_precision_m: 0.1237 - val_recall_m: 0.4697\n",
            "Epoch 24/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6914 - acc: 0.5479 - f1_m: 0.4759 - precision_m: 0.5566 - recall_m: 0.4162 - val_loss: 0.6872 - val_acc: 0.6247 - val_f1_m: 0.1943 - val_precision_m: 0.1224 - val_recall_m: 0.4761\n",
            "Epoch 25/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6913 - acc: 0.5515 - f1_m: 0.5029 - precision_m: 0.5709 - recall_m: 0.4497 - val_loss: 0.6876 - val_acc: 0.6155 - val_f1_m: 0.1984 - val_precision_m: 0.1240 - val_recall_m: 0.5004\n",
            "Epoch 26/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6911 - acc: 0.5517 - f1_m: 0.5008 - precision_m: 0.5579 - recall_m: 0.4547 - val_loss: 0.6878 - val_acc: 0.6107 - val_f1_m: 0.1985 - val_precision_m: 0.1237 - val_recall_m: 0.5071\n",
            "Epoch 27/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6910 - acc: 0.5541 - f1_m: 0.5142 - precision_m: 0.5711 - recall_m: 0.4681 - val_loss: 0.6878 - val_acc: 0.6107 - val_f1_m: 0.2020 - val_precision_m: 0.1257 - val_recall_m: 0.5187\n",
            "Epoch 28/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6908 - acc: 0.5585 - f1_m: 0.5177 - precision_m: 0.5663 - recall_m: 0.4771 - val_loss: 0.6883 - val_acc: 0.6011 - val_f1_m: 0.2082 - val_precision_m: 0.1287 - val_recall_m: 0.5512\n",
            "Epoch 29/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6907 - acc: 0.5638 - f1_m: 0.5336 - precision_m: 0.5761 - recall_m: 0.4970 - val_loss: 0.6888 - val_acc: 0.5909 - val_f1_m: 0.2087 - val_precision_m: 0.1283 - val_recall_m: 0.5657\n",
            "Epoch 30/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6905 - acc: 0.5692 - f1_m: 0.5563 - precision_m: 0.5825 - recall_m: 0.5329 - val_loss: 0.6892 - val_acc: 0.5827 - val_f1_m: 0.2093 - val_precision_m: 0.1281 - val_recall_m: 0.5785\n",
            "Epoch 31/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6904 - acc: 0.5704 - f1_m: 0.5533 - precision_m: 0.5852 - recall_m: 0.5258 - val_loss: 0.6893 - val_acc: 0.5794 - val_f1_m: 0.2087 - val_precision_m: 0.1276 - val_recall_m: 0.5806\n",
            "Epoch 32/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6902 - acc: 0.5734 - f1_m: 0.5555 - precision_m: 0.5799 - recall_m: 0.5338 - val_loss: 0.6897 - val_acc: 0.5719 - val_f1_m: 0.2094 - val_precision_m: 0.1275 - val_recall_m: 0.5930\n",
            "Epoch 33/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6901 - acc: 0.5746 - f1_m: 0.5668 - precision_m: 0.5761 - recall_m: 0.5593 - val_loss: 0.6901 - val_acc: 0.5660 - val_f1_m: 0.2101 - val_precision_m: 0.1275 - val_recall_m: 0.6043\n",
            "Epoch 34/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6899 - acc: 0.5770 - f1_m: 0.5708 - precision_m: 0.5785 - recall_m: 0.5642 - val_loss: 0.6905 - val_acc: 0.5604 - val_f1_m: 0.2122 - val_precision_m: 0.1283 - val_recall_m: 0.6190\n",
            "Epoch 35/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6898 - acc: 0.5770 - f1_m: 0.5735 - precision_m: 0.5739 - recall_m: 0.5740 - val_loss: 0.6912 - val_acc: 0.5470 - val_f1_m: 0.2114 - val_precision_m: 0.1271 - val_recall_m: 0.6346\n",
            "Epoch 36/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6896 - acc: 0.5784 - f1_m: 0.5746 - precision_m: 0.5636 - recall_m: 0.5865 - val_loss: 0.6914 - val_acc: 0.5439 - val_f1_m: 0.2119 - val_precision_m: 0.1272 - val_recall_m: 0.6406\n",
            "Epoch 37/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6894 - acc: 0.5812 - f1_m: 0.5867 - precision_m: 0.5744 - recall_m: 0.5999 - val_loss: 0.6912 - val_acc: 0.5470 - val_f1_m: 0.2136 - val_precision_m: 0.1284 - val_recall_m: 0.6432\n",
            "Epoch 38/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6893 - acc: 0.5836 - f1_m: 0.5951 - precision_m: 0.5841 - recall_m: 0.6068 - val_loss: 0.6911 - val_acc: 0.5472 - val_f1_m: 0.2137 - val_precision_m: 0.1284 - val_recall_m: 0.6428\n",
            "Epoch 39/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6891 - acc: 0.5854 - f1_m: 0.5946 - precision_m: 0.5827 - recall_m: 0.6071 - val_loss: 0.6913 - val_acc: 0.5445 - val_f1_m: 0.2151 - val_precision_m: 0.1291 - val_recall_m: 0.6523\n",
            "Epoch 40/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6890 - acc: 0.5880 - f1_m: 0.5930 - precision_m: 0.5813 - recall_m: 0.6059 - val_loss: 0.6910 - val_acc: 0.5483 - val_f1_m: 0.2177 - val_precision_m: 0.1308 - val_recall_m: 0.6572\n",
            "Epoch 41/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6888 - acc: 0.5908 - f1_m: 0.5934 - precision_m: 0.5786 - recall_m: 0.6111 - val_loss: 0.6908 - val_acc: 0.5510 - val_f1_m: 0.2182 - val_precision_m: 0.1312 - val_recall_m: 0.6549\n",
            "Epoch 42/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6887 - acc: 0.5918 - f1_m: 0.5941 - precision_m: 0.5915 - recall_m: 0.5981 - val_loss: 0.6904 - val_acc: 0.5587 - val_f1_m: 0.2183 - val_precision_m: 0.1318 - val_recall_m: 0.6436\n",
            "Epoch 43/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6885 - acc: 0.5944 - f1_m: 0.5987 - precision_m: 0.5979 - recall_m: 0.6007 - val_loss: 0.6903 - val_acc: 0.5593 - val_f1_m: 0.2197 - val_precision_m: 0.1326 - val_recall_m: 0.6485\n",
            "Epoch 44/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6884 - acc: 0.5940 - f1_m: 0.6020 - precision_m: 0.5910 - recall_m: 0.6156 - val_loss: 0.6904 - val_acc: 0.5583 - val_f1_m: 0.2209 - val_precision_m: 0.1332 - val_recall_m: 0.6549\n",
            "Epoch 45/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6882 - acc: 0.5934 - f1_m: 0.5917 - precision_m: 0.5871 - recall_m: 0.5968 - val_loss: 0.6903 - val_acc: 0.5600 - val_f1_m: 0.2222 - val_precision_m: 0.1340 - val_recall_m: 0.6569\n",
            "Epoch 46/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6881 - acc: 0.5950 - f1_m: 0.6003 - precision_m: 0.5973 - recall_m: 0.6040 - val_loss: 0.6902 - val_acc: 0.5610 - val_f1_m: 0.2232 - val_precision_m: 0.1347 - val_recall_m: 0.6595\n",
            "Epoch 47/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6879 - acc: 0.5972 - f1_m: 0.5972 - precision_m: 0.5955 - recall_m: 0.5998 - val_loss: 0.6902 - val_acc: 0.5614 - val_f1_m: 0.2234 - val_precision_m: 0.1348 - val_recall_m: 0.6596\n",
            "Epoch 48/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6878 - acc: 0.5964 - f1_m: 0.5986 - precision_m: 0.5918 - recall_m: 0.6062 - val_loss: 0.6905 - val_acc: 0.5566 - val_f1_m: 0.2237 - val_precision_m: 0.1347 - val_recall_m: 0.6678\n",
            "Epoch 49/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6876 - acc: 0.5968 - f1_m: 0.6072 - precision_m: 0.5944 - recall_m: 0.6212 - val_loss: 0.6910 - val_acc: 0.5514 - val_f1_m: 0.2255 - val_precision_m: 0.1354 - val_recall_m: 0.6840\n",
            "Epoch 50/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6875 - acc: 0.5988 - f1_m: 0.6065 - precision_m: 0.5910 - recall_m: 0.6235 - val_loss: 0.6909 - val_acc: 0.5531 - val_f1_m: 0.2256 - val_precision_m: 0.1355 - val_recall_m: 0.6810\n",
            "Epoch 51/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6873 - acc: 0.6016 - f1_m: 0.6141 - precision_m: 0.5929 - recall_m: 0.6384 - val_loss: 0.6908 - val_acc: 0.5527 - val_f1_m: 0.2254 - val_precision_m: 0.1354 - val_recall_m: 0.6810\n",
            "Epoch 52/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6871 - acc: 0.6034 - f1_m: 0.6078 - precision_m: 0.5967 - recall_m: 0.6203 - val_loss: 0.6906 - val_acc: 0.5564 - val_f1_m: 0.2262 - val_precision_m: 0.1361 - val_recall_m: 0.6790\n",
            "Epoch 53/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6870 - acc: 0.6040 - f1_m: 0.6226 - precision_m: 0.6107 - recall_m: 0.6357 - val_loss: 0.6905 - val_acc: 0.5575 - val_f1_m: 0.2284 - val_precision_m: 0.1373 - val_recall_m: 0.6850\n",
            "Epoch 54/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6868 - acc: 0.6049 - f1_m: 0.6102 - precision_m: 0.5954 - recall_m: 0.6265 - val_loss: 0.6907 - val_acc: 0.5543 - val_f1_m: 0.2282 - val_precision_m: 0.1371 - val_recall_m: 0.6896\n",
            "Epoch 55/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6867 - acc: 0.6057 - f1_m: 0.6115 - precision_m: 0.5938 - recall_m: 0.6308 - val_loss: 0.6907 - val_acc: 0.5533 - val_f1_m: 0.2278 - val_precision_m: 0.1368 - val_recall_m: 0.6896\n",
            "Epoch 56/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6865 - acc: 0.6063 - f1_m: 0.6203 - precision_m: 0.6048 - recall_m: 0.6369 - val_loss: 0.6905 - val_acc: 0.5547 - val_f1_m: 0.2272 - val_precision_m: 0.1365 - val_recall_m: 0.6852\n",
            "Epoch 57/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6863 - acc: 0.6065 - f1_m: 0.6165 - precision_m: 0.5995 - recall_m: 0.6349 - val_loss: 0.6906 - val_acc: 0.5537 - val_f1_m: 0.2268 - val_precision_m: 0.1362 - val_recall_m: 0.6852\n",
            "Epoch 58/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6862 - acc: 0.6077 - f1_m: 0.6217 - precision_m: 0.6038 - recall_m: 0.6412 - val_loss: 0.6905 - val_acc: 0.5541 - val_f1_m: 0.2275 - val_precision_m: 0.1366 - val_recall_m: 0.6872\n",
            "Epoch 59/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6860 - acc: 0.6085 - f1_m: 0.6218 - precision_m: 0.6040 - recall_m: 0.6415 - val_loss: 0.6904 - val_acc: 0.5552 - val_f1_m: 0.2279 - val_precision_m: 0.1370 - val_recall_m: 0.6872\n",
            "Epoch 60/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6859 - acc: 0.6101 - f1_m: 0.6231 - precision_m: 0.6063 - recall_m: 0.6416 - val_loss: 0.6905 - val_acc: 0.5529 - val_f1_m: 0.2281 - val_precision_m: 0.1370 - val_recall_m: 0.6913\n",
            "Epoch 61/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6857 - acc: 0.6113 - f1_m: 0.6295 - precision_m: 0.6119 - recall_m: 0.6487 - val_loss: 0.6904 - val_acc: 0.5554 - val_f1_m: 0.2286 - val_precision_m: 0.1374 - val_recall_m: 0.6893\n",
            "Epoch 62/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6855 - acc: 0.6115 - f1_m: 0.6293 - precision_m: 0.6168 - recall_m: 0.6442 - val_loss: 0.6903 - val_acc: 0.5562 - val_f1_m: 0.2289 - val_precision_m: 0.1376 - val_recall_m: 0.6893\n",
            "Epoch 63/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6854 - acc: 0.6127 - f1_m: 0.6283 - precision_m: 0.6075 - recall_m: 0.6514 - val_loss: 0.6905 - val_acc: 0.5545 - val_f1_m: 0.2288 - val_precision_m: 0.1374 - val_recall_m: 0.6918\n",
            "Epoch 64/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6852 - acc: 0.6149 - f1_m: 0.6257 - precision_m: 0.6005 - recall_m: 0.6542 - val_loss: 0.6905 - val_acc: 0.5541 - val_f1_m: 0.2304 - val_precision_m: 0.1383 - val_recall_m: 0.6983\n",
            "Epoch 65/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6850 - acc: 0.6157 - f1_m: 0.6258 - precision_m: 0.6068 - recall_m: 0.6471 - val_loss: 0.6903 - val_acc: 0.5558 - val_f1_m: 0.2305 - val_precision_m: 0.1385 - val_recall_m: 0.6957\n",
            "Epoch 66/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6849 - acc: 0.6159 - f1_m: 0.6226 - precision_m: 0.6002 - recall_m: 0.6469 - val_loss: 0.6901 - val_acc: 0.5570 - val_f1_m: 0.2309 - val_precision_m: 0.1388 - val_recall_m: 0.6953\n",
            "Epoch 67/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6847 - acc: 0.6161 - f1_m: 0.6259 - precision_m: 0.6115 - recall_m: 0.6426 - val_loss: 0.6897 - val_acc: 0.5623 - val_f1_m: 0.2319 - val_precision_m: 0.1397 - val_recall_m: 0.6913\n",
            "Epoch 68/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6845 - acc: 0.6159 - f1_m: 0.6312 - precision_m: 0.6146 - recall_m: 0.6493 - val_loss: 0.6897 - val_acc: 0.5627 - val_f1_m: 0.2332 - val_precision_m: 0.1404 - val_recall_m: 0.6954\n",
            "Epoch 69/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6844 - acc: 0.6183 - f1_m: 0.6275 - precision_m: 0.6080 - recall_m: 0.6489 - val_loss: 0.6904 - val_acc: 0.5539 - val_f1_m: 0.2319 - val_precision_m: 0.1391 - val_recall_m: 0.7041\n",
            "Epoch 70/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6842 - acc: 0.6179 - f1_m: 0.6261 - precision_m: 0.6032 - recall_m: 0.6518 - val_loss: 0.6904 - val_acc: 0.5527 - val_f1_m: 0.2331 - val_precision_m: 0.1398 - val_recall_m: 0.7110\n",
            "Epoch 71/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6841 - acc: 0.6179 - f1_m: 0.6321 - precision_m: 0.6075 - recall_m: 0.6592 - val_loss: 0.6906 - val_acc: 0.5516 - val_f1_m: 0.2349 - val_precision_m: 0.1407 - val_recall_m: 0.7203\n",
            "Epoch 72/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6839 - acc: 0.6191 - f1_m: 0.6419 - precision_m: 0.6215 - recall_m: 0.6648 - val_loss: 0.6904 - val_acc: 0.5539 - val_f1_m: 0.2353 - val_precision_m: 0.1410 - val_recall_m: 0.7183\n",
            "Epoch 73/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6837 - acc: 0.6191 - f1_m: 0.6393 - precision_m: 0.6130 - recall_m: 0.6686 - val_loss: 0.6910 - val_acc: 0.5481 - val_f1_m: 0.2352 - val_precision_m: 0.1406 - val_recall_m: 0.7272\n",
            "Epoch 74/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6835 - acc: 0.6195 - f1_m: 0.6408 - precision_m: 0.6120 - recall_m: 0.6730 - val_loss: 0.6911 - val_acc: 0.5476 - val_f1_m: 0.2361 - val_precision_m: 0.1411 - val_recall_m: 0.7319\n",
            "Epoch 75/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6834 - acc: 0.6207 - f1_m: 0.6439 - precision_m: 0.6124 - recall_m: 0.6790 - val_loss: 0.6914 - val_acc: 0.5455 - val_f1_m: 0.2353 - val_precision_m: 0.1406 - val_recall_m: 0.7319\n",
            "Epoch 76/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6832 - acc: 0.6193 - f1_m: 0.6405 - precision_m: 0.6041 - recall_m: 0.6818 - val_loss: 0.6914 - val_acc: 0.5447 - val_f1_m: 0.2344 - val_precision_m: 0.1400 - val_recall_m: 0.7299\n",
            "Epoch 77/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6830 - acc: 0.6207 - f1_m: 0.6415 - precision_m: 0.6021 - recall_m: 0.6877 - val_loss: 0.6913 - val_acc: 0.5453 - val_f1_m: 0.2346 - val_precision_m: 0.1401 - val_recall_m: 0.7299\n",
            "Epoch 78/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6829 - acc: 0.6209 - f1_m: 0.6449 - precision_m: 0.6105 - recall_m: 0.6837 - val_loss: 0.6909 - val_acc: 0.5508 - val_f1_m: 0.2368 - val_precision_m: 0.1417 - val_recall_m: 0.7299\n",
            "Epoch 79/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6827 - acc: 0.6231 - f1_m: 0.6373 - precision_m: 0.6055 - recall_m: 0.6731 - val_loss: 0.6902 - val_acc: 0.5575 - val_f1_m: 0.2383 - val_precision_m: 0.1430 - val_recall_m: 0.7250\n",
            "Epoch 80/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6825 - acc: 0.6223 - f1_m: 0.6343 - precision_m: 0.6111 - recall_m: 0.6598 - val_loss: 0.6896 - val_acc: 0.5648 - val_f1_m: 0.2409 - val_precision_m: 0.1449 - val_recall_m: 0.7226\n",
            "Epoch 81/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6823 - acc: 0.6231 - f1_m: 0.6384 - precision_m: 0.6132 - recall_m: 0.6663 - val_loss: 0.6893 - val_acc: 0.5675 - val_f1_m: 0.2409 - val_precision_m: 0.1451 - val_recall_m: 0.7179\n",
            "Epoch 82/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6821 - acc: 0.6241 - f1_m: 0.6357 - precision_m: 0.6159 - recall_m: 0.6571 - val_loss: 0.6889 - val_acc: 0.5708 - val_f1_m: 0.2423 - val_precision_m: 0.1461 - val_recall_m: 0.7179\n",
            "Epoch 83/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6820 - acc: 0.6253 - f1_m: 0.6414 - precision_m: 0.6222 - recall_m: 0.6630 - val_loss: 0.6888 - val_acc: 0.5717 - val_f1_m: 0.2431 - val_precision_m: 0.1466 - val_recall_m: 0.7203\n",
            "Epoch 84/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6818 - acc: 0.6255 - f1_m: 0.6406 - precision_m: 0.6224 - recall_m: 0.6602 - val_loss: 0.6886 - val_acc: 0.5742 - val_f1_m: 0.2443 - val_precision_m: 0.1475 - val_recall_m: 0.7203\n",
            "Epoch 85/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6816 - acc: 0.6261 - f1_m: 0.6334 - precision_m: 0.6176 - recall_m: 0.6509 - val_loss: 0.6885 - val_acc: 0.5752 - val_f1_m: 0.2447 - val_precision_m: 0.1478 - val_recall_m: 0.7203\n",
            "Epoch 86/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.6814 - acc: 0.6265 - f1_m: 0.6435 - precision_m: 0.6277 - recall_m: 0.6611 - val_loss: 0.6887 - val_acc: 0.5729 - val_f1_m: 0.2438 - val_precision_m: 0.1471 - val_recall_m: 0.7203\n",
            "Epoch 87/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6812 - acc: 0.6261 - f1_m: 0.6375 - precision_m: 0.6166 - recall_m: 0.6602 - val_loss: 0.6891 - val_acc: 0.5694 - val_f1_m: 0.2434 - val_precision_m: 0.1466 - val_recall_m: 0.7250\n",
            "Epoch 88/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6811 - acc: 0.6259 - f1_m: 0.6387 - precision_m: 0.6162 - recall_m: 0.6632 - val_loss: 0.6889 - val_acc: 0.5704 - val_f1_m: 0.2439 - val_precision_m: 0.1470 - val_recall_m: 0.7250\n",
            "Epoch 89/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6809 - acc: 0.6263 - f1_m: 0.6454 - precision_m: 0.6177 - recall_m: 0.6771 - val_loss: 0.6891 - val_acc: 0.5681 - val_f1_m: 0.2436 - val_precision_m: 0.1467 - val_recall_m: 0.7273\n",
            "Epoch 90/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.6807 - acc: 0.6267 - f1_m: 0.6331 - precision_m: 0.6058 - recall_m: 0.6638 - val_loss: 0.6888 - val_acc: 0.5715 - val_f1_m: 0.2449 - val_precision_m: 0.1477 - val_recall_m: 0.7273\n",
            "Epoch 91/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6805 - acc: 0.6277 - f1_m: 0.6435 - precision_m: 0.6193 - recall_m: 0.6702 - val_loss: 0.6881 - val_acc: 0.5756 - val_f1_m: 0.2438 - val_precision_m: 0.1473 - val_recall_m: 0.7159\n",
            "Epoch 92/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6803 - acc: 0.6277 - f1_m: 0.6465 - precision_m: 0.6240 - recall_m: 0.6712 - val_loss: 0.6876 - val_acc: 0.5792 - val_f1_m: 0.2441 - val_precision_m: 0.1477 - val_recall_m: 0.7116\n",
            "Epoch 93/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6801 - acc: 0.6295 - f1_m: 0.6400 - precision_m: 0.6218 - recall_m: 0.6602 - val_loss: 0.6870 - val_acc: 0.5848 - val_f1_m: 0.2460 - val_precision_m: 0.1492 - val_recall_m: 0.7095\n",
            "Epoch 94/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6799 - acc: 0.6317 - f1_m: 0.6464 - precision_m: 0.6354 - recall_m: 0.6583 - val_loss: 0.6865 - val_acc: 0.5880 - val_f1_m: 0.2451 - val_precision_m: 0.1489 - val_recall_m: 0.7007\n",
            "Epoch 95/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6797 - acc: 0.6333 - f1_m: 0.6359 - precision_m: 0.6243 - recall_m: 0.6489 - val_loss: 0.6861 - val_acc: 0.5907 - val_f1_m: 0.2458 - val_precision_m: 0.1495 - val_recall_m: 0.6987\n",
            "Epoch 96/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6795 - acc: 0.6337 - f1_m: 0.6388 - precision_m: 0.6259 - recall_m: 0.6530 - val_loss: 0.6860 - val_acc: 0.5907 - val_f1_m: 0.2457 - val_precision_m: 0.1495 - val_recall_m: 0.6987\n",
            "Epoch 97/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6794 - acc: 0.6341 - f1_m: 0.6374 - precision_m: 0.6302 - recall_m: 0.6451 - val_loss: 0.6856 - val_acc: 0.5930 - val_f1_m: 0.2463 - val_precision_m: 0.1500 - val_recall_m: 0.6968\n",
            "Epoch 98/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6792 - acc: 0.6341 - f1_m: 0.6455 - precision_m: 0.6343 - recall_m: 0.6572 - val_loss: 0.6854 - val_acc: 0.5947 - val_f1_m: 0.2470 - val_precision_m: 0.1506 - val_recall_m: 0.6968\n",
            "Epoch 99/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.6790 - acc: 0.6343 - f1_m: 0.6352 - precision_m: 0.6255 - recall_m: 0.6458 - val_loss: 0.6852 - val_acc: 0.5963 - val_f1_m: 0.2472 - val_precision_m: 0.1508 - val_recall_m: 0.6944\n",
            "Epoch 100/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6788 - acc: 0.6335 - f1_m: 0.6355 - precision_m: 0.6266 - recall_m: 0.6457 - val_loss: 0.6848 - val_acc: 0.5995 - val_f1_m: 0.2480 - val_precision_m: 0.1515 - val_recall_m: 0.6924\n",
            "Epoch 101/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6786 - acc: 0.6343 - f1_m: 0.6352 - precision_m: 0.6298 - recall_m: 0.6410 - val_loss: 0.6848 - val_acc: 0.5988 - val_f1_m: 0.2484 - val_precision_m: 0.1517 - val_recall_m: 0.6948\n",
            "Epoch 102/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6784 - acc: 0.6349 - f1_m: 0.6433 - precision_m: 0.6340 - recall_m: 0.6535 - val_loss: 0.6848 - val_acc: 0.5978 - val_f1_m: 0.2478 - val_precision_m: 0.1513 - val_recall_m: 0.6948\n",
            "Epoch 103/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6782 - acc: 0.6343 - f1_m: 0.6377 - precision_m: 0.6284 - recall_m: 0.6476 - val_loss: 0.6850 - val_acc: 0.5967 - val_f1_m: 0.2480 - val_precision_m: 0.1513 - val_recall_m: 0.6972\n",
            "Epoch 104/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6780 - acc: 0.6349 - f1_m: 0.6354 - precision_m: 0.6296 - recall_m: 0.6419 - val_loss: 0.6848 - val_acc: 0.5976 - val_f1_m: 0.2484 - val_precision_m: 0.1516 - val_recall_m: 0.6972\n",
            "Epoch 105/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6778 - acc: 0.6349 - f1_m: 0.6359 - precision_m: 0.6275 - recall_m: 0.6450 - val_loss: 0.6847 - val_acc: 0.5982 - val_f1_m: 0.2487 - val_precision_m: 0.1518 - val_recall_m: 0.6972\n",
            "Epoch 106/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6776 - acc: 0.6351 - f1_m: 0.6463 - precision_m: 0.6437 - recall_m: 0.6501 - val_loss: 0.6849 - val_acc: 0.5957 - val_f1_m: 0.2482 - val_precision_m: 0.1513 - val_recall_m: 0.6992\n",
            "Epoch 107/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6774 - acc: 0.6369 - f1_m: 0.6497 - precision_m: 0.6416 - recall_m: 0.6588 - val_loss: 0.6857 - val_acc: 0.5894 - val_f1_m: 0.2482 - val_precision_m: 0.1508 - val_recall_m: 0.7103\n",
            "Epoch 108/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6772 - acc: 0.6365 - f1_m: 0.6427 - precision_m: 0.6262 - recall_m: 0.6607 - val_loss: 0.6861 - val_acc: 0.5840 - val_f1_m: 0.2468 - val_precision_m: 0.1496 - val_recall_m: 0.7143\n",
            "Epoch 109/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6770 - acc: 0.6359 - f1_m: 0.6433 - precision_m: 0.6228 - recall_m: 0.6659 - val_loss: 0.6865 - val_acc: 0.5827 - val_f1_m: 0.2479 - val_precision_m: 0.1501 - val_recall_m: 0.7212\n",
            "Epoch 110/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6768 - acc: 0.6355 - f1_m: 0.6447 - precision_m: 0.6251 - recall_m: 0.6657 - val_loss: 0.6865 - val_acc: 0.5821 - val_f1_m: 0.2482 - val_precision_m: 0.1502 - val_recall_m: 0.7233\n",
            "Epoch 111/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6766 - acc: 0.6357 - f1_m: 0.6492 - precision_m: 0.6319 - recall_m: 0.6678 - val_loss: 0.6857 - val_acc: 0.5869 - val_f1_m: 0.2482 - val_precision_m: 0.1506 - val_recall_m: 0.7148\n",
            "Epoch 112/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6764 - acc: 0.6369 - f1_m: 0.6519 - precision_m: 0.6350 - recall_m: 0.6701 - val_loss: 0.6854 - val_acc: 0.5892 - val_f1_m: 0.2486 - val_precision_m: 0.1510 - val_recall_m: 0.7129\n",
            "Epoch 113/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6761 - acc: 0.6369 - f1_m: 0.6460 - precision_m: 0.6304 - recall_m: 0.6627 - val_loss: 0.6849 - val_acc: 0.5924 - val_f1_m: 0.2500 - val_precision_m: 0.1520 - val_recall_m: 0.7129\n",
            "Epoch 114/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6759 - acc: 0.6381 - f1_m: 0.6453 - precision_m: 0.6335 - recall_m: 0.6578 - val_loss: 0.6844 - val_acc: 0.5938 - val_f1_m: 0.2478 - val_precision_m: 0.1509 - val_recall_m: 0.7017\n",
            "Epoch 115/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6757 - acc: 0.6395 - f1_m: 0.6404 - precision_m: 0.6278 - recall_m: 0.6541 - val_loss: 0.6843 - val_acc: 0.5942 - val_f1_m: 0.2491 - val_precision_m: 0.1517 - val_recall_m: 0.7061\n",
            "Epoch 116/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6755 - acc: 0.6397 - f1_m: 0.6420 - precision_m: 0.6319 - recall_m: 0.6529 - val_loss: 0.6836 - val_acc: 0.5984 - val_f1_m: 0.2488 - val_precision_m: 0.1518 - val_recall_m: 0.6971\n",
            "Epoch 117/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6753 - acc: 0.6403 - f1_m: 0.6498 - precision_m: 0.6401 - recall_m: 0.6601 - val_loss: 0.6834 - val_acc: 0.5982 - val_f1_m: 0.2498 - val_precision_m: 0.1524 - val_recall_m: 0.7017\n",
            "Epoch 118/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6751 - acc: 0.6397 - f1_m: 0.6416 - precision_m: 0.6344 - recall_m: 0.6497 - val_loss: 0.6838 - val_acc: 0.5957 - val_f1_m: 0.2492 - val_precision_m: 0.1518 - val_recall_m: 0.7038\n",
            "Epoch 119/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6749 - acc: 0.6395 - f1_m: 0.6448 - precision_m: 0.6322 - recall_m: 0.6585 - val_loss: 0.6836 - val_acc: 0.5967 - val_f1_m: 0.2497 - val_precision_m: 0.1522 - val_recall_m: 0.7038\n",
            "Epoch 120/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6746 - acc: 0.6399 - f1_m: 0.6402 - precision_m: 0.6341 - recall_m: 0.6475 - val_loss: 0.6834 - val_acc: 0.5982 - val_f1_m: 0.2503 - val_precision_m: 0.1527 - val_recall_m: 0.7038\n",
            "Epoch 121/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6744 - acc: 0.6407 - f1_m: 0.6550 - precision_m: 0.6448 - recall_m: 0.6659 - val_loss: 0.6833 - val_acc: 0.5976 - val_f1_m: 0.2501 - val_precision_m: 0.1525 - val_recall_m: 0.7038\n",
            "Epoch 122/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6742 - acc: 0.6393 - f1_m: 0.6439 - precision_m: 0.6291 - recall_m: 0.6607 - val_loss: 0.6834 - val_acc: 0.5963 - val_f1_m: 0.2495 - val_precision_m: 0.1520 - val_recall_m: 0.7038\n",
            "Epoch 123/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6740 - acc: 0.6393 - f1_m: 0.6487 - precision_m: 0.6341 - recall_m: 0.6646 - val_loss: 0.6832 - val_acc: 0.5965 - val_f1_m: 0.2496 - val_precision_m: 0.1521 - val_recall_m: 0.7038\n",
            "Epoch 124/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6738 - acc: 0.6399 - f1_m: 0.6405 - precision_m: 0.6260 - recall_m: 0.6572 - val_loss: 0.6829 - val_acc: 0.5984 - val_f1_m: 0.2498 - val_precision_m: 0.1524 - val_recall_m: 0.7014\n",
            "Epoch 125/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6735 - acc: 0.6411 - f1_m: 0.6469 - precision_m: 0.6383 - recall_m: 0.6562 - val_loss: 0.6822 - val_acc: 0.6024 - val_f1_m: 0.2516 - val_precision_m: 0.1537 - val_recall_m: 0.7014\n",
            "Epoch 126/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6733 - acc: 0.6409 - f1_m: 0.6507 - precision_m: 0.6404 - recall_m: 0.6619 - val_loss: 0.6814 - val_acc: 0.6089 - val_f1_m: 0.2548 - val_precision_m: 0.1561 - val_recall_m: 0.7014\n",
            "Epoch 127/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6731 - acc: 0.6413 - f1_m: 0.6499 - precision_m: 0.6423 - recall_m: 0.6579 - val_loss: 0.6817 - val_acc: 0.6064 - val_f1_m: 0.2535 - val_precision_m: 0.1552 - val_recall_m: 0.7014\n",
            "Epoch 128/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6729 - acc: 0.6415 - f1_m: 0.6517 - precision_m: 0.6457 - recall_m: 0.6584 - val_loss: 0.6818 - val_acc: 0.6051 - val_f1_m: 0.2529 - val_precision_m: 0.1547 - val_recall_m: 0.7014\n",
            "Epoch 129/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6726 - acc: 0.6413 - f1_m: 0.6376 - precision_m: 0.6316 - recall_m: 0.6445 - val_loss: 0.6820 - val_acc: 0.6024 - val_f1_m: 0.2522 - val_precision_m: 0.1540 - val_recall_m: 0.7037\n",
            "Epoch 130/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6724 - acc: 0.6419 - f1_m: 0.6511 - precision_m: 0.6395 - recall_m: 0.6632 - val_loss: 0.6821 - val_acc: 0.6011 - val_f1_m: 0.2516 - val_precision_m: 0.1536 - val_recall_m: 0.7037\n",
            "Epoch 131/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6722 - acc: 0.6419 - f1_m: 0.6552 - precision_m: 0.6414 - recall_m: 0.6701 - val_loss: 0.6823 - val_acc: 0.5988 - val_f1_m: 0.2511 - val_precision_m: 0.1531 - val_recall_m: 0.7060\n",
            "Epoch 132/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6719 - acc: 0.6417 - f1_m: 0.6502 - precision_m: 0.6335 - recall_m: 0.6687 - val_loss: 0.6824 - val_acc: 0.5969 - val_f1_m: 0.2520 - val_precision_m: 0.1535 - val_recall_m: 0.7124\n",
            "Epoch 133/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6717 - acc: 0.6423 - f1_m: 0.6544 - precision_m: 0.6429 - recall_m: 0.6670 - val_loss: 0.6820 - val_acc: 0.6009 - val_f1_m: 0.2532 - val_precision_m: 0.1545 - val_recall_m: 0.7100\n",
            "Epoch 134/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6715 - acc: 0.6429 - f1_m: 0.6473 - precision_m: 0.6338 - recall_m: 0.6615 - val_loss: 0.6818 - val_acc: 0.6011 - val_f1_m: 0.2533 - val_precision_m: 0.1546 - val_recall_m: 0.7100\n",
            "Epoch 135/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6712 - acc: 0.6429 - f1_m: 0.6512 - precision_m: 0.6417 - recall_m: 0.6615 - val_loss: 0.6815 - val_acc: 0.6024 - val_f1_m: 0.2533 - val_precision_m: 0.1547 - val_recall_m: 0.7080\n",
            "Epoch 136/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6710 - acc: 0.6427 - f1_m: 0.6519 - precision_m: 0.6384 - recall_m: 0.6668 - val_loss: 0.6811 - val_acc: 0.6041 - val_f1_m: 0.2536 - val_precision_m: 0.1550 - val_recall_m: 0.7060\n",
            "Epoch 137/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6708 - acc: 0.6437 - f1_m: 0.6446 - precision_m: 0.6326 - recall_m: 0.6572 - val_loss: 0.6815 - val_acc: 0.6011 - val_f1_m: 0.2533 - val_precision_m: 0.1545 - val_recall_m: 0.7100\n",
            "Epoch 138/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6705 - acc: 0.6449 - f1_m: 0.6525 - precision_m: 0.6389 - recall_m: 0.6668 - val_loss: 0.6815 - val_acc: 0.6011 - val_f1_m: 0.2546 - val_precision_m: 0.1553 - val_recall_m: 0.7148\n",
            "Epoch 139/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6703 - acc: 0.6445 - f1_m: 0.6531 - precision_m: 0.6354 - recall_m: 0.6727 - val_loss: 0.6814 - val_acc: 0.6013 - val_f1_m: 0.2553 - val_precision_m: 0.1557 - val_recall_m: 0.7167\n",
            "Epoch 140/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6700 - acc: 0.6451 - f1_m: 0.6525 - precision_m: 0.6362 - recall_m: 0.6708 - val_loss: 0.6809 - val_acc: 0.6034 - val_f1_m: 0.2533 - val_precision_m: 0.1547 - val_recall_m: 0.7060\n",
            "Epoch 141/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6698 - acc: 0.6451 - f1_m: 0.6511 - precision_m: 0.6450 - recall_m: 0.6587 - val_loss: 0.6804 - val_acc: 0.6059 - val_f1_m: 0.2545 - val_precision_m: 0.1557 - val_recall_m: 0.7060\n",
            "Epoch 142/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6696 - acc: 0.6460 - f1_m: 0.6540 - precision_m: 0.6381 - recall_m: 0.6725 - val_loss: 0.6807 - val_acc: 0.6036 - val_f1_m: 0.2551 - val_precision_m: 0.1558 - val_recall_m: 0.7124\n",
            "Epoch 143/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6693 - acc: 0.6466 - f1_m: 0.6567 - precision_m: 0.6486 - recall_m: 0.6660 - val_loss: 0.6806 - val_acc: 0.6032 - val_f1_m: 0.2549 - val_precision_m: 0.1556 - val_recall_m: 0.7124\n",
            "Epoch 144/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6691 - acc: 0.6460 - f1_m: 0.6548 - precision_m: 0.6446 - recall_m: 0.6662 - val_loss: 0.6811 - val_acc: 0.6018 - val_f1_m: 0.2555 - val_precision_m: 0.1558 - val_recall_m: 0.7167\n",
            "Epoch 145/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6688 - acc: 0.6462 - f1_m: 0.6546 - precision_m: 0.6386 - recall_m: 0.6720 - val_loss: 0.6812 - val_acc: 0.6007 - val_f1_m: 0.2578 - val_precision_m: 0.1570 - val_recall_m: 0.7280\n",
            "Epoch 146/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6686 - acc: 0.6464 - f1_m: 0.6567 - precision_m: 0.6441 - recall_m: 0.6707 - val_loss: 0.6810 - val_acc: 0.6013 - val_f1_m: 0.2581 - val_precision_m: 0.1572 - val_recall_m: 0.7280\n",
            "Epoch 147/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6683 - acc: 0.6464 - f1_m: 0.6586 - precision_m: 0.6457 - recall_m: 0.6725 - val_loss: 0.6807 - val_acc: 0.6026 - val_f1_m: 0.2581 - val_precision_m: 0.1574 - val_recall_m: 0.7260\n",
            "Epoch 148/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6681 - acc: 0.6472 - f1_m: 0.6517 - precision_m: 0.6441 - recall_m: 0.6613 - val_loss: 0.6806 - val_acc: 0.6024 - val_f1_m: 0.2580 - val_precision_m: 0.1573 - val_recall_m: 0.7260\n",
            "Epoch 149/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6678 - acc: 0.6472 - f1_m: 0.6454 - precision_m: 0.6354 - recall_m: 0.6575 - val_loss: 0.6807 - val_acc: 0.6018 - val_f1_m: 0.2583 - val_precision_m: 0.1574 - val_recall_m: 0.7280\n",
            "Epoch 150/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6676 - acc: 0.6470 - f1_m: 0.6548 - precision_m: 0.6427 - recall_m: 0.6681 - val_loss: 0.6808 - val_acc: 0.6005 - val_f1_m: 0.2577 - val_precision_m: 0.1569 - val_recall_m: 0.7280\n",
            "Epoch 151/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6673 - acc: 0.6468 - f1_m: 0.6590 - precision_m: 0.6436 - recall_m: 0.6757 - val_loss: 0.6805 - val_acc: 0.6018 - val_f1_m: 0.2583 - val_precision_m: 0.1574 - val_recall_m: 0.7280\n",
            "Epoch 152/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6671 - acc: 0.6472 - f1_m: 0.6524 - precision_m: 0.6333 - recall_m: 0.6738 - val_loss: 0.6806 - val_acc: 0.6011 - val_f1_m: 0.2580 - val_precision_m: 0.1572 - val_recall_m: 0.7280\n",
            "Epoch 153/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6668 - acc: 0.6474 - f1_m: 0.6564 - precision_m: 0.6406 - recall_m: 0.6736 - val_loss: 0.6800 - val_acc: 0.6022 - val_f1_m: 0.2579 - val_precision_m: 0.1573 - val_recall_m: 0.7260\n",
            "Epoch 154/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6666 - acc: 0.6466 - f1_m: 0.6520 - precision_m: 0.6400 - recall_m: 0.6647 - val_loss: 0.6791 - val_acc: 0.6045 - val_f1_m: 0.2585 - val_precision_m: 0.1577 - val_recall_m: 0.7237\n",
            "Epoch 155/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6663 - acc: 0.6472 - f1_m: 0.6504 - precision_m: 0.6398 - recall_m: 0.6620 - val_loss: 0.6781 - val_acc: 0.6084 - val_f1_m: 0.2586 - val_precision_m: 0.1581 - val_recall_m: 0.7166\n",
            "Epoch 156/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6660 - acc: 0.6484 - f1_m: 0.6577 - precision_m: 0.6469 - recall_m: 0.6689 - val_loss: 0.6774 - val_acc: 0.6103 - val_f1_m: 0.2571 - val_precision_m: 0.1575 - val_recall_m: 0.7085\n",
            "Epoch 157/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6658 - acc: 0.6478 - f1_m: 0.6542 - precision_m: 0.6443 - recall_m: 0.6647 - val_loss: 0.6775 - val_acc: 0.6097 - val_f1_m: 0.2580 - val_precision_m: 0.1579 - val_recall_m: 0.7127\n",
            "Epoch 158/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6655 - acc: 0.6476 - f1_m: 0.6572 - precision_m: 0.6455 - recall_m: 0.6697 - val_loss: 0.6773 - val_acc: 0.6103 - val_f1_m: 0.2583 - val_precision_m: 0.1581 - val_recall_m: 0.7127\n",
            "Epoch 159/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6653 - acc: 0.6482 - f1_m: 0.6517 - precision_m: 0.6407 - recall_m: 0.6632 - val_loss: 0.6774 - val_acc: 0.6095 - val_f1_m: 0.2579 - val_precision_m: 0.1578 - val_recall_m: 0.7127\n",
            "Epoch 160/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6650 - acc: 0.6482 - f1_m: 0.6515 - precision_m: 0.6358 - recall_m: 0.6697 - val_loss: 0.6773 - val_acc: 0.6091 - val_f1_m: 0.2589 - val_precision_m: 0.1584 - val_recall_m: 0.7168\n",
            "Epoch 161/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6647 - acc: 0.6486 - f1_m: 0.6533 - precision_m: 0.6395 - recall_m: 0.6681 - val_loss: 0.6765 - val_acc: 0.6126 - val_f1_m: 0.2588 - val_precision_m: 0.1587 - val_recall_m: 0.7102\n",
            "Epoch 162/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6645 - acc: 0.6502 - f1_m: 0.6551 - precision_m: 0.6509 - recall_m: 0.6600 - val_loss: 0.6755 - val_acc: 0.6172 - val_f1_m: 0.2582 - val_precision_m: 0.1588 - val_recall_m: 0.6995\n",
            "Epoch 163/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6642 - acc: 0.6500 - f1_m: 0.6514 - precision_m: 0.6436 - recall_m: 0.6597 - val_loss: 0.6750 - val_acc: 0.6187 - val_f1_m: 0.2583 - val_precision_m: 0.1590 - val_recall_m: 0.6974\n",
            "Epoch 164/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6639 - acc: 0.6496 - f1_m: 0.6474 - precision_m: 0.6462 - recall_m: 0.6489 - val_loss: 0.6739 - val_acc: 0.6226 - val_f1_m: 0.2604 - val_precision_m: 0.1605 - val_recall_m: 0.6974\n",
            "Epoch 165/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6637 - acc: 0.6508 - f1_m: 0.6502 - precision_m: 0.6488 - recall_m: 0.6520 - val_loss: 0.6740 - val_acc: 0.6214 - val_f1_m: 0.2597 - val_precision_m: 0.1600 - val_recall_m: 0.6974\n",
            "Epoch 166/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6634 - acc: 0.6512 - f1_m: 0.6540 - precision_m: 0.6514 - recall_m: 0.6569 - val_loss: 0.6739 - val_acc: 0.6218 - val_f1_m: 0.2599 - val_precision_m: 0.1602 - val_recall_m: 0.6974\n",
            "Epoch 167/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6631 - acc: 0.6520 - f1_m: 0.6436 - precision_m: 0.6441 - recall_m: 0.6437 - val_loss: 0.6736 - val_acc: 0.6218 - val_f1_m: 0.2599 - val_precision_m: 0.1602 - val_recall_m: 0.6974\n",
            "Epoch 168/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6629 - acc: 0.6516 - f1_m: 0.6560 - precision_m: 0.6545 - recall_m: 0.6577 - val_loss: 0.6733 - val_acc: 0.6229 - val_f1_m: 0.2604 - val_precision_m: 0.1606 - val_recall_m: 0.6974\n",
            "Epoch 169/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6626 - acc: 0.6520 - f1_m: 0.6521 - precision_m: 0.6564 - recall_m: 0.6496 - val_loss: 0.6735 - val_acc: 0.6220 - val_f1_m: 0.2606 - val_precision_m: 0.1606 - val_recall_m: 0.6997\n",
            "Epoch 170/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.6623 - acc: 0.6528 - f1_m: 0.6521 - precision_m: 0.6469 - recall_m: 0.6578 - val_loss: 0.6739 - val_acc: 0.6204 - val_f1_m: 0.2622 - val_precision_m: 0.1613 - val_recall_m: 0.7084\n",
            "Epoch 171/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6620 - acc: 0.6532 - f1_m: 0.6601 - precision_m: 0.6541 - recall_m: 0.6666 - val_loss: 0.6735 - val_acc: 0.6218 - val_f1_m: 0.2624 - val_precision_m: 0.1616 - val_recall_m: 0.7065\n",
            "Epoch 172/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6618 - acc: 0.6524 - f1_m: 0.6408 - precision_m: 0.6364 - recall_m: 0.6452 - val_loss: 0.6730 - val_acc: 0.6229 - val_f1_m: 0.2623 - val_precision_m: 0.1616 - val_recall_m: 0.7042\n",
            "Epoch 173/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6615 - acc: 0.6524 - f1_m: 0.6519 - precision_m: 0.6516 - recall_m: 0.6526 - val_loss: 0.6721 - val_acc: 0.6264 - val_f1_m: 0.2629 - val_precision_m: 0.1623 - val_recall_m: 0.6997\n",
            "Epoch 174/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6612 - acc: 0.6516 - f1_m: 0.6431 - precision_m: 0.6406 - recall_m: 0.6462 - val_loss: 0.6724 - val_acc: 0.6243 - val_f1_m: 0.2625 - val_precision_m: 0.1619 - val_recall_m: 0.7021\n",
            "Epoch 175/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6609 - acc: 0.6514 - f1_m: 0.6546 - precision_m: 0.6523 - recall_m: 0.6572 - val_loss: 0.6722 - val_acc: 0.6249 - val_f1_m: 0.2634 - val_precision_m: 0.1625 - val_recall_m: 0.7042\n",
            "Epoch 176/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6607 - acc: 0.6518 - f1_m: 0.6622 - precision_m: 0.6621 - recall_m: 0.6628 - val_loss: 0.6722 - val_acc: 0.6239 - val_f1_m: 0.2647 - val_precision_m: 0.1631 - val_recall_m: 0.7108\n",
            "Epoch 177/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6604 - acc: 0.6526 - f1_m: 0.6576 - precision_m: 0.6548 - recall_m: 0.6607 - val_loss: 0.6731 - val_acc: 0.6206 - val_f1_m: 0.2641 - val_precision_m: 0.1624 - val_recall_m: 0.7155\n",
            "Epoch 178/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6601 - acc: 0.6538 - f1_m: 0.6516 - precision_m: 0.6514 - recall_m: 0.6530 - val_loss: 0.6733 - val_acc: 0.6201 - val_f1_m: 0.2639 - val_precision_m: 0.1622 - val_recall_m: 0.7155\n",
            "Epoch 179/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6598 - acc: 0.6536 - f1_m: 0.6616 - precision_m: 0.6588 - recall_m: 0.6653 - val_loss: 0.6728 - val_acc: 0.6210 - val_f1_m: 0.2644 - val_precision_m: 0.1626 - val_recall_m: 0.7155\n",
            "Epoch 180/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6595 - acc: 0.6538 - f1_m: 0.6662 - precision_m: 0.6554 - recall_m: 0.6782 - val_loss: 0.6732 - val_acc: 0.6201 - val_f1_m: 0.2645 - val_precision_m: 0.1626 - val_recall_m: 0.7178\n",
            "Epoch 181/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6593 - acc: 0.6534 - f1_m: 0.6541 - precision_m: 0.6437 - recall_m: 0.6658 - val_loss: 0.6722 - val_acc: 0.6222 - val_f1_m: 0.2650 - val_precision_m: 0.1631 - val_recall_m: 0.7155\n",
            "Epoch 182/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6590 - acc: 0.6528 - f1_m: 0.6515 - precision_m: 0.6485 - recall_m: 0.6547 - val_loss: 0.6712 - val_acc: 0.6256 - val_f1_m: 0.2662 - val_precision_m: 0.1641 - val_recall_m: 0.7131\n",
            "Epoch 183/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6587 - acc: 0.6524 - f1_m: 0.6503 - precision_m: 0.6462 - recall_m: 0.6545 - val_loss: 0.6709 - val_acc: 0.6264 - val_f1_m: 0.2666 - val_precision_m: 0.1644 - val_recall_m: 0.7131\n",
            "Epoch 184/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6584 - acc: 0.6522 - f1_m: 0.6533 - precision_m: 0.6510 - recall_m: 0.6563 - val_loss: 0.6707 - val_acc: 0.6266 - val_f1_m: 0.2667 - val_precision_m: 0.1645 - val_recall_m: 0.7131\n",
            "Epoch 185/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6581 - acc: 0.6526 - f1_m: 0.6536 - precision_m: 0.6519 - recall_m: 0.6563 - val_loss: 0.6701 - val_acc: 0.6279 - val_f1_m: 0.2662 - val_precision_m: 0.1643 - val_recall_m: 0.7089\n",
            "Epoch 186/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6578 - acc: 0.6520 - f1_m: 0.6512 - precision_m: 0.6512 - recall_m: 0.6516 - val_loss: 0.6698 - val_acc: 0.6287 - val_f1_m: 0.2666 - val_precision_m: 0.1647 - val_recall_m: 0.7089\n",
            "Epoch 187/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6575 - acc: 0.6530 - f1_m: 0.6473 - precision_m: 0.6480 - recall_m: 0.6471 - val_loss: 0.6693 - val_acc: 0.6300 - val_f1_m: 0.2673 - val_precision_m: 0.1652 - val_recall_m: 0.7089\n",
            "Epoch 188/1000\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.6572 - acc: 0.6526 - f1_m: 0.6513 - precision_m: 0.6461 - recall_m: 0.6585 - val_loss: 0.6689 - val_acc: 0.6316 - val_f1_m: 0.2676 - val_precision_m: 0.1656 - val_recall_m: 0.7068\n",
            "Epoch 189/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.6569 - acc: 0.6518 - f1_m: 0.6518 - precision_m: 0.6518 - recall_m: 0.6520 - val_loss: 0.6680 - val_acc: 0.6333 - val_f1_m: 0.2679 - val_precision_m: 0.1659 - val_recall_m: 0.7049\n",
            "Epoch 190/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6566 - acc: 0.6514 - f1_m: 0.6468 - precision_m: 0.6452 - recall_m: 0.6489 - val_loss: 0.6679 - val_acc: 0.6335 - val_f1_m: 0.2686 - val_precision_m: 0.1664 - val_recall_m: 0.7068\n",
            "Epoch 191/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6564 - acc: 0.6514 - f1_m: 0.6512 - precision_m: 0.6532 - recall_m: 0.6498 - val_loss: 0.6671 - val_acc: 0.6344 - val_f1_m: 0.2684 - val_precision_m: 0.1663 - val_recall_m: 0.7049\n",
            "Epoch 192/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6561 - acc: 0.6514 - f1_m: 0.6485 - precision_m: 0.6556 - recall_m: 0.6423 - val_loss: 0.6667 - val_acc: 0.6356 - val_f1_m: 0.2691 - val_precision_m: 0.1669 - val_recall_m: 0.7049\n",
            "Epoch 193/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6558 - acc: 0.6520 - f1_m: 0.6486 - precision_m: 0.6474 - recall_m: 0.6510 - val_loss: 0.6668 - val_acc: 0.6344 - val_f1_m: 0.2684 - val_precision_m: 0.1663 - val_recall_m: 0.7049\n",
            "Epoch 194/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6555 - acc: 0.6514 - f1_m: 0.6525 - precision_m: 0.6534 - recall_m: 0.6523 - val_loss: 0.6666 - val_acc: 0.6350 - val_f1_m: 0.2700 - val_precision_m: 0.1673 - val_recall_m: 0.7091\n",
            "Epoch 195/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6552 - acc: 0.6508 - f1_m: 0.6562 - precision_m: 0.6552 - recall_m: 0.6577 - val_loss: 0.6669 - val_acc: 0.6344 - val_f1_m: 0.2714 - val_precision_m: 0.1680 - val_recall_m: 0.7161\n",
            "Epoch 196/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6549 - acc: 0.6514 - f1_m: 0.6499 - precision_m: 0.6472 - recall_m: 0.6534 - val_loss: 0.6671 - val_acc: 0.6333 - val_f1_m: 0.2709 - val_precision_m: 0.1676 - val_recall_m: 0.7161\n",
            "Epoch 197/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6546 - acc: 0.6516 - f1_m: 0.6449 - precision_m: 0.6441 - recall_m: 0.6460 - val_loss: 0.6667 - val_acc: 0.6337 - val_f1_m: 0.2711 - val_precision_m: 0.1677 - val_recall_m: 0.7161\n",
            "Epoch 198/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6543 - acc: 0.6510 - f1_m: 0.6533 - precision_m: 0.6497 - recall_m: 0.6577 - val_loss: 0.6659 - val_acc: 0.6362 - val_f1_m: 0.2719 - val_precision_m: 0.1685 - val_recall_m: 0.7140\n",
            "Epoch 199/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6540 - acc: 0.6518 - f1_m: 0.6502 - precision_m: 0.6551 - recall_m: 0.6457 - val_loss: 0.6652 - val_acc: 0.6375 - val_f1_m: 0.2720 - val_precision_m: 0.1687 - val_recall_m: 0.7117\n",
            "Epoch 200/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6537 - acc: 0.6518 - f1_m: 0.6533 - precision_m: 0.6521 - recall_m: 0.6552 - val_loss: 0.6652 - val_acc: 0.6373 - val_f1_m: 0.2719 - val_precision_m: 0.1686 - val_recall_m: 0.7117\n",
            "Epoch 201/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.6534 - acc: 0.6518 - f1_m: 0.6556 - precision_m: 0.6538 - recall_m: 0.6585 - val_loss: 0.6650 - val_acc: 0.6373 - val_f1_m: 0.2725 - val_precision_m: 0.1689 - val_recall_m: 0.7140\n",
            "Epoch 202/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6531 - acc: 0.6518 - f1_m: 0.6491 - precision_m: 0.6542 - recall_m: 0.6451 - val_loss: 0.6646 - val_acc: 0.6375 - val_f1_m: 0.2720 - val_precision_m: 0.1687 - val_recall_m: 0.7117\n",
            "Epoch 203/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6528 - acc: 0.6530 - f1_m: 0.6551 - precision_m: 0.6559 - recall_m: 0.6555 - val_loss: 0.6640 - val_acc: 0.6394 - val_f1_m: 0.2725 - val_precision_m: 0.1692 - val_recall_m: 0.7097\n",
            "Epoch 204/1000\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.6525 - acc: 0.6530 - f1_m: 0.6424 - precision_m: 0.6456 - recall_m: 0.6395 - val_loss: 0.6638 - val_acc: 0.6398 - val_f1_m: 0.2727 - val_precision_m: 0.1694 - val_recall_m: 0.7097\n",
            "Epoch 205/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6522 - acc: 0.6532 - f1_m: 0.6496 - precision_m: 0.6552 - recall_m: 0.6446 - val_loss: 0.6636 - val_acc: 0.6400 - val_f1_m: 0.2734 - val_precision_m: 0.1698 - val_recall_m: 0.7120\n",
            "Epoch 206/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6519 - acc: 0.6544 - f1_m: 0.6564 - precision_m: 0.6610 - recall_m: 0.6522 - val_loss: 0.6642 - val_acc: 0.6373 - val_f1_m: 0.2725 - val_precision_m: 0.1689 - val_recall_m: 0.7140\n",
            "Epoch 207/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6516 - acc: 0.6532 - f1_m: 0.6510 - precision_m: 0.6539 - recall_m: 0.6486 - val_loss: 0.6652 - val_acc: 0.6352 - val_f1_m: 0.2726 - val_precision_m: 0.1687 - val_recall_m: 0.7184\n",
            "Epoch 208/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6513 - acc: 0.6540 - f1_m: 0.6585 - precision_m: 0.6593 - recall_m: 0.6594 - val_loss: 0.6659 - val_acc: 0.6329 - val_f1_m: 0.2719 - val_precision_m: 0.1681 - val_recall_m: 0.7204\n",
            "Epoch 209/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6510 - acc: 0.6548 - f1_m: 0.6570 - precision_m: 0.6563 - recall_m: 0.6584 - val_loss: 0.6655 - val_acc: 0.6337 - val_f1_m: 0.2724 - val_precision_m: 0.1685 - val_recall_m: 0.7204\n",
            "Epoch 210/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6507 - acc: 0.6552 - f1_m: 0.6562 - precision_m: 0.6524 - recall_m: 0.6604 - val_loss: 0.6657 - val_acc: 0.6329 - val_f1_m: 0.2719 - val_precision_m: 0.1681 - val_recall_m: 0.7204\n",
            "Epoch 211/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6504 - acc: 0.6554 - f1_m: 0.6473 - precision_m: 0.6446 - recall_m: 0.6504 - val_loss: 0.6652 - val_acc: 0.6331 - val_f1_m: 0.2721 - val_precision_m: 0.1682 - val_recall_m: 0.7204\n",
            "Epoch 212/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6501 - acc: 0.6562 - f1_m: 0.6485 - precision_m: 0.6444 - recall_m: 0.6529 - val_loss: 0.6642 - val_acc: 0.6356 - val_f1_m: 0.2728 - val_precision_m: 0.1689 - val_recall_m: 0.7184\n",
            "Epoch 213/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6498 - acc: 0.6564 - f1_m: 0.6607 - precision_m: 0.6580 - recall_m: 0.6646 - val_loss: 0.6644 - val_acc: 0.6341 - val_f1_m: 0.2726 - val_precision_m: 0.1686 - val_recall_m: 0.7204\n",
            "Epoch 214/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6495 - acc: 0.6568 - f1_m: 0.6602 - precision_m: 0.6528 - recall_m: 0.6690 - val_loss: 0.6649 - val_acc: 0.6329 - val_f1_m: 0.2719 - val_precision_m: 0.1681 - val_recall_m: 0.7204\n",
            "Epoch 215/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6492 - acc: 0.6574 - f1_m: 0.6607 - precision_m: 0.6603 - recall_m: 0.6620 - val_loss: 0.6648 - val_acc: 0.6333 - val_f1_m: 0.2721 - val_precision_m: 0.1683 - val_recall_m: 0.7204\n",
            "Epoch 216/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6489 - acc: 0.6572 - f1_m: 0.6592 - precision_m: 0.6527 - recall_m: 0.6663 - val_loss: 0.6645 - val_acc: 0.6333 - val_f1_m: 0.2721 - val_precision_m: 0.1683 - val_recall_m: 0.7204\n",
            "Epoch 217/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6486 - acc: 0.6570 - f1_m: 0.6643 - precision_m: 0.6625 - recall_m: 0.6668 - val_loss: 0.6637 - val_acc: 0.6352 - val_f1_m: 0.2726 - val_precision_m: 0.1688 - val_recall_m: 0.7184\n",
            "Epoch 218/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6483 - acc: 0.6580 - f1_m: 0.6581 - precision_m: 0.6542 - recall_m: 0.6622 - val_loss: 0.6640 - val_acc: 0.6344 - val_f1_m: 0.2727 - val_precision_m: 0.1687 - val_recall_m: 0.7204\n",
            "Epoch 219/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6480 - acc: 0.6578 - f1_m: 0.6563 - precision_m: 0.6573 - recall_m: 0.6562 - val_loss: 0.6639 - val_acc: 0.6341 - val_f1_m: 0.2726 - val_precision_m: 0.1687 - val_recall_m: 0.7204\n",
            "Epoch 220/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6477 - acc: 0.6578 - f1_m: 0.6509 - precision_m: 0.6457 - recall_m: 0.6565 - val_loss: 0.6640 - val_acc: 0.6335 - val_f1_m: 0.2723 - val_precision_m: 0.1684 - val_recall_m: 0.7204\n",
            "Epoch 221/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6474 - acc: 0.6580 - f1_m: 0.6580 - precision_m: 0.6516 - recall_m: 0.6651 - val_loss: 0.6630 - val_acc: 0.6352 - val_f1_m: 0.2720 - val_precision_m: 0.1684 - val_recall_m: 0.7160\n",
            "Epoch 222/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6471 - acc: 0.6578 - f1_m: 0.6562 - precision_m: 0.6482 - recall_m: 0.6665 - val_loss: 0.6623 - val_acc: 0.6369 - val_f1_m: 0.2728 - val_precision_m: 0.1691 - val_recall_m: 0.7160\n",
            "Epoch 223/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6468 - acc: 0.6578 - f1_m: 0.6641 - precision_m: 0.6644 - recall_m: 0.6639 - val_loss: 0.6608 - val_acc: 0.6410 - val_f1_m: 0.2752 - val_precision_m: 0.1710 - val_recall_m: 0.7160\n",
            "Epoch 224/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6465 - acc: 0.6580 - f1_m: 0.6535 - precision_m: 0.6546 - recall_m: 0.6526 - val_loss: 0.6611 - val_acc: 0.6398 - val_f1_m: 0.2745 - val_precision_m: 0.1704 - val_recall_m: 0.7160\n",
            "Epoch 225/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6462 - acc: 0.6584 - f1_m: 0.6558 - precision_m: 0.6541 - recall_m: 0.6579 - val_loss: 0.6610 - val_acc: 0.6398 - val_f1_m: 0.2745 - val_precision_m: 0.1704 - val_recall_m: 0.7160\n",
            "Epoch 226/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6459 - acc: 0.6584 - f1_m: 0.6617 - precision_m: 0.6625 - recall_m: 0.6616 - val_loss: 0.6611 - val_acc: 0.6396 - val_f1_m: 0.2750 - val_precision_m: 0.1706 - val_recall_m: 0.7180\n",
            "Epoch 227/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6455 - acc: 0.6586 - f1_m: 0.6605 - precision_m: 0.6583 - recall_m: 0.6633 - val_loss: 0.6609 - val_acc: 0.6396 - val_f1_m: 0.2750 - val_precision_m: 0.1706 - val_recall_m: 0.7180\n",
            "Epoch 228/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6452 - acc: 0.6590 - f1_m: 0.6604 - precision_m: 0.6658 - recall_m: 0.6564 - val_loss: 0.6609 - val_acc: 0.6398 - val_f1_m: 0.2751 - val_precision_m: 0.1707 - val_recall_m: 0.7180\n",
            "Epoch 229/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6449 - acc: 0.6580 - f1_m: 0.6520 - precision_m: 0.6527 - recall_m: 0.6518 - val_loss: 0.6613 - val_acc: 0.6385 - val_f1_m: 0.2744 - val_precision_m: 0.1701 - val_recall_m: 0.7180\n",
            "Epoch 230/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6446 - acc: 0.6586 - f1_m: 0.6550 - precision_m: 0.6557 - recall_m: 0.6552 - val_loss: 0.6612 - val_acc: 0.6387 - val_f1_m: 0.2745 - val_precision_m: 0.1702 - val_recall_m: 0.7180\n",
            "Epoch 231/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6443 - acc: 0.6592 - f1_m: 0.6680 - precision_m: 0.6657 - recall_m: 0.6704 - val_loss: 0.6616 - val_acc: 0.6369 - val_f1_m: 0.2735 - val_precision_m: 0.1695 - val_recall_m: 0.7180\n",
            "Epoch 232/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6440 - acc: 0.6600 - f1_m: 0.6694 - precision_m: 0.6732 - recall_m: 0.6679 - val_loss: 0.6623 - val_acc: 0.6344 - val_f1_m: 0.2721 - val_precision_m: 0.1684 - val_recall_m: 0.7180\n",
            "Epoch 233/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6437 - acc: 0.6594 - f1_m: 0.6601 - precision_m: 0.6520 - recall_m: 0.6686 - val_loss: 0.6633 - val_acc: 0.6304 - val_f1_m: 0.2706 - val_precision_m: 0.1672 - val_recall_m: 0.7200\n",
            "Epoch 234/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6434 - acc: 0.6592 - f1_m: 0.6640 - precision_m: 0.6573 - recall_m: 0.6717 - val_loss: 0.6631 - val_acc: 0.6304 - val_f1_m: 0.2706 - val_precision_m: 0.1672 - val_recall_m: 0.7200\n",
            "Epoch 235/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6431 - acc: 0.6602 - f1_m: 0.6637 - precision_m: 0.6563 - recall_m: 0.6718 - val_loss: 0.6618 - val_acc: 0.6344 - val_f1_m: 0.2721 - val_precision_m: 0.1685 - val_recall_m: 0.7180\n",
            "Epoch 236/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6428 - acc: 0.6602 - f1_m: 0.6680 - precision_m: 0.6637 - recall_m: 0.6725 - val_loss: 0.6605 - val_acc: 0.6375 - val_f1_m: 0.2738 - val_precision_m: 0.1697 - val_recall_m: 0.7180\n",
            "Epoch 237/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6425 - acc: 0.6614 - f1_m: 0.6625 - precision_m: 0.6567 - recall_m: 0.6694 - val_loss: 0.6598 - val_acc: 0.6385 - val_f1_m: 0.2744 - val_precision_m: 0.1702 - val_recall_m: 0.7180\n",
            "Epoch 238/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6422 - acc: 0.6602 - f1_m: 0.6615 - precision_m: 0.6611 - recall_m: 0.6620 - val_loss: 0.6579 - val_acc: 0.6421 - val_f1_m: 0.2763 - val_precision_m: 0.1717 - val_recall_m: 0.7180\n",
            "Epoch 239/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6418 - acc: 0.6614 - f1_m: 0.6618 - precision_m: 0.6634 - recall_m: 0.6609 - val_loss: 0.6576 - val_acc: 0.6423 - val_f1_m: 0.2764 - val_precision_m: 0.1718 - val_recall_m: 0.7180\n",
            "Epoch 240/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6415 - acc: 0.6616 - f1_m: 0.6646 - precision_m: 0.6680 - recall_m: 0.6614 - val_loss: 0.6570 - val_acc: 0.6435 - val_f1_m: 0.2771 - val_precision_m: 0.1723 - val_recall_m: 0.7180\n",
            "Epoch 241/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6412 - acc: 0.6616 - f1_m: 0.6657 - precision_m: 0.6653 - recall_m: 0.6666 - val_loss: 0.6565 - val_acc: 0.6450 - val_f1_m: 0.2780 - val_precision_m: 0.1730 - val_recall_m: 0.7180\n",
            "Epoch 242/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6409 - acc: 0.6614 - f1_m: 0.6528 - precision_m: 0.6525 - recall_m: 0.6535 - val_loss: 0.6561 - val_acc: 0.6461 - val_f1_m: 0.2786 - val_precision_m: 0.1734 - val_recall_m: 0.7180\n",
            "Epoch 243/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6406 - acc: 0.6618 - f1_m: 0.6602 - precision_m: 0.6648 - recall_m: 0.6561 - val_loss: 0.6554 - val_acc: 0.6473 - val_f1_m: 0.2793 - val_precision_m: 0.1739 - val_recall_m: 0.7180\n",
            "Epoch 244/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6403 - acc: 0.6626 - f1_m: 0.6654 - precision_m: 0.6707 - recall_m: 0.6609 - val_loss: 0.6549 - val_acc: 0.6477 - val_f1_m: 0.2789 - val_precision_m: 0.1738 - val_recall_m: 0.7160\n",
            "Epoch 245/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6400 - acc: 0.6624 - f1_m: 0.6648 - precision_m: 0.6689 - recall_m: 0.6608 - val_loss: 0.6554 - val_acc: 0.6461 - val_f1_m: 0.2785 - val_precision_m: 0.1734 - val_recall_m: 0.7180\n",
            "Epoch 246/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6397 - acc: 0.6614 - f1_m: 0.6599 - precision_m: 0.6593 - recall_m: 0.6619 - val_loss: 0.6559 - val_acc: 0.6444 - val_f1_m: 0.2776 - val_precision_m: 0.1727 - val_recall_m: 0.7180\n",
            "Epoch 247/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6393 - acc: 0.6618 - f1_m: 0.6585 - precision_m: 0.6577 - recall_m: 0.6596 - val_loss: 0.6548 - val_acc: 0.6467 - val_f1_m: 0.2783 - val_precision_m: 0.1733 - val_recall_m: 0.7160\n",
            "Epoch 248/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6390 - acc: 0.6618 - f1_m: 0.6678 - precision_m: 0.6694 - recall_m: 0.6664 - val_loss: 0.6537 - val_acc: 0.6494 - val_f1_m: 0.2799 - val_precision_m: 0.1746 - val_recall_m: 0.7160\n",
            "Epoch 249/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6387 - acc: 0.6638 - f1_m: 0.6574 - precision_m: 0.6696 - recall_m: 0.6475 - val_loss: 0.6530 - val_acc: 0.6504 - val_f1_m: 0.2805 - val_precision_m: 0.1751 - val_recall_m: 0.7160\n",
            "Epoch 250/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6384 - acc: 0.6640 - f1_m: 0.6629 - precision_m: 0.6682 - recall_m: 0.6587 - val_loss: 0.6530 - val_acc: 0.6502 - val_f1_m: 0.2804 - val_precision_m: 0.1750 - val_recall_m: 0.7160\n",
            "Epoch 251/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6381 - acc: 0.6632 - f1_m: 0.6599 - precision_m: 0.6636 - recall_m: 0.6564 - val_loss: 0.6534 - val_acc: 0.6488 - val_f1_m: 0.2796 - val_precision_m: 0.1743 - val_recall_m: 0.7160\n",
            "Epoch 252/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6378 - acc: 0.6632 - f1_m: 0.6627 - precision_m: 0.6629 - recall_m: 0.6632 - val_loss: 0.6530 - val_acc: 0.6490 - val_f1_m: 0.2797 - val_precision_m: 0.1745 - val_recall_m: 0.7160\n",
            "Epoch 253/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6375 - acc: 0.6634 - f1_m: 0.6631 - precision_m: 0.6688 - recall_m: 0.6579 - val_loss: 0.6522 - val_acc: 0.6509 - val_f1_m: 0.2801 - val_precision_m: 0.1749 - val_recall_m: 0.7140\n",
            "Epoch 254/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6372 - acc: 0.6636 - f1_m: 0.6559 - precision_m: 0.6558 - recall_m: 0.6566 - val_loss: 0.6527 - val_acc: 0.6492 - val_f1_m: 0.2792 - val_precision_m: 0.1742 - val_recall_m: 0.7140\n",
            "Epoch 255/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6369 - acc: 0.6636 - f1_m: 0.6537 - precision_m: 0.6572 - recall_m: 0.6507 - val_loss: 0.6518 - val_acc: 0.6513 - val_f1_m: 0.2804 - val_precision_m: 0.1751 - val_recall_m: 0.7140\n",
            "Epoch 256/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6366 - acc: 0.6630 - f1_m: 0.6571 - precision_m: 0.6600 - recall_m: 0.6547 - val_loss: 0.6513 - val_acc: 0.6515 - val_f1_m: 0.2805 - val_precision_m: 0.1752 - val_recall_m: 0.7140\n",
            "Epoch 257/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6363 - acc: 0.6626 - f1_m: 0.6675 - precision_m: 0.6718 - recall_m: 0.6639 - val_loss: 0.6505 - val_acc: 0.6529 - val_f1_m: 0.2814 - val_precision_m: 0.1759 - val_recall_m: 0.7140\n",
            "Epoch 258/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6360 - acc: 0.6630 - f1_m: 0.6616 - precision_m: 0.6704 - recall_m: 0.6537 - val_loss: 0.6501 - val_acc: 0.6534 - val_f1_m: 0.2816 - val_precision_m: 0.1760 - val_recall_m: 0.7140\n",
            "Epoch 259/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6357 - acc: 0.6628 - f1_m: 0.6586 - precision_m: 0.6642 - recall_m: 0.6535 - val_loss: 0.6503 - val_acc: 0.6519 - val_f1_m: 0.2808 - val_precision_m: 0.1754 - val_recall_m: 0.7140\n",
            "Epoch 260/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6354 - acc: 0.6634 - f1_m: 0.6539 - precision_m: 0.6523 - recall_m: 0.6570 - val_loss: 0.6508 - val_acc: 0.6509 - val_f1_m: 0.2802 - val_precision_m: 0.1749 - val_recall_m: 0.7140\n",
            "Epoch 261/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6351 - acc: 0.6634 - f1_m: 0.6578 - precision_m: 0.6591 - recall_m: 0.6568 - val_loss: 0.6499 - val_acc: 0.6519 - val_f1_m: 0.2808 - val_precision_m: 0.1754 - val_recall_m: 0.7140\n",
            "Epoch 262/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6348 - acc: 0.6630 - f1_m: 0.6544 - precision_m: 0.6643 - recall_m: 0.6459 - val_loss: 0.6479 - val_acc: 0.6550 - val_f1_m: 0.2814 - val_precision_m: 0.1761 - val_recall_m: 0.7100\n",
            "Epoch 263/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6345 - acc: 0.6646 - f1_m: 0.6598 - precision_m: 0.6670 - recall_m: 0.6528 - val_loss: 0.6468 - val_acc: 0.6563 - val_f1_m: 0.2814 - val_precision_m: 0.1763 - val_recall_m: 0.7080\n",
            "Epoch 264/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6342 - acc: 0.6650 - f1_m: 0.6557 - precision_m: 0.6669 - recall_m: 0.6451 - val_loss: 0.6456 - val_acc: 0.6588 - val_f1_m: 0.2829 - val_precision_m: 0.1774 - val_recall_m: 0.7080\n",
            "Epoch 265/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6339 - acc: 0.6648 - f1_m: 0.6564 - precision_m: 0.6745 - recall_m: 0.6411 - val_loss: 0.6453 - val_acc: 0.6582 - val_f1_m: 0.2818 - val_precision_m: 0.1767 - val_recall_m: 0.7061\n",
            "Epoch 266/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6336 - acc: 0.6640 - f1_m: 0.6621 - precision_m: 0.6670 - recall_m: 0.6584 - val_loss: 0.6470 - val_acc: 0.6550 - val_f1_m: 0.2807 - val_precision_m: 0.1757 - val_recall_m: 0.7080\n",
            "Epoch 267/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6333 - acc: 0.6648 - f1_m: 0.6590 - precision_m: 0.6676 - recall_m: 0.6509 - val_loss: 0.6472 - val_acc: 0.6548 - val_f1_m: 0.2812 - val_precision_m: 0.1760 - val_recall_m: 0.7101\n",
            "Epoch 268/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6331 - acc: 0.6646 - f1_m: 0.6621 - precision_m: 0.6691 - recall_m: 0.6556 - val_loss: 0.6475 - val_acc: 0.6538 - val_f1_m: 0.2806 - val_precision_m: 0.1755 - val_recall_m: 0.7101\n",
            "Epoch 269/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6328 - acc: 0.6648 - f1_m: 0.6649 - precision_m: 0.6658 - recall_m: 0.6651 - val_loss: 0.6474 - val_acc: 0.6538 - val_f1_m: 0.2806 - val_precision_m: 0.1755 - val_recall_m: 0.7101\n",
            "Epoch 270/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6325 - acc: 0.6648 - f1_m: 0.6665 - precision_m: 0.6761 - recall_m: 0.6578 - val_loss: 0.6463 - val_acc: 0.6561 - val_f1_m: 0.2819 - val_precision_m: 0.1765 - val_recall_m: 0.7101\n",
            "Epoch 271/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6322 - acc: 0.6654 - f1_m: 0.6669 - precision_m: 0.6699 - recall_m: 0.6645 - val_loss: 0.6462 - val_acc: 0.6559 - val_f1_m: 0.2817 - val_precision_m: 0.1764 - val_recall_m: 0.7101\n",
            "Epoch 272/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6319 - acc: 0.6652 - f1_m: 0.6532 - precision_m: 0.6583 - recall_m: 0.6487 - val_loss: 0.6454 - val_acc: 0.6575 - val_f1_m: 0.2822 - val_precision_m: 0.1769 - val_recall_m: 0.7080\n",
            "Epoch 273/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6316 - acc: 0.6656 - f1_m: 0.6527 - precision_m: 0.6613 - recall_m: 0.6450 - val_loss: 0.6450 - val_acc: 0.6575 - val_f1_m: 0.2815 - val_precision_m: 0.1765 - val_recall_m: 0.7061\n",
            "Epoch 274/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6313 - acc: 0.6654 - f1_m: 0.6604 - precision_m: 0.6764 - recall_m: 0.6475 - val_loss: 0.6442 - val_acc: 0.6598 - val_f1_m: 0.2822 - val_precision_m: 0.1772 - val_recall_m: 0.7041\n",
            "Epoch 275/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6310 - acc: 0.6652 - f1_m: 0.6678 - precision_m: 0.6729 - recall_m: 0.6646 - val_loss: 0.6441 - val_acc: 0.6594 - val_f1_m: 0.2814 - val_precision_m: 0.1767 - val_recall_m: 0.7021\n",
            "Epoch 276/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6307 - acc: 0.6652 - f1_m: 0.6580 - precision_m: 0.6696 - recall_m: 0.6473 - val_loss: 0.6440 - val_acc: 0.6592 - val_f1_m: 0.2813 - val_precision_m: 0.1766 - val_recall_m: 0.7021\n",
            "Epoch 277/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6304 - acc: 0.6658 - f1_m: 0.6593 - precision_m: 0.6691 - recall_m: 0.6502 - val_loss: 0.6444 - val_acc: 0.6584 - val_f1_m: 0.2808 - val_precision_m: 0.1762 - val_recall_m: 0.7021\n",
            "Epoch 278/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6301 - acc: 0.6652 - f1_m: 0.6652 - precision_m: 0.6713 - recall_m: 0.6598 - val_loss: 0.6444 - val_acc: 0.6586 - val_f1_m: 0.2815 - val_precision_m: 0.1766 - val_recall_m: 0.7041\n",
            "Epoch 279/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6299 - acc: 0.6656 - f1_m: 0.6632 - precision_m: 0.6697 - recall_m: 0.6572 - val_loss: 0.6437 - val_acc: 0.6592 - val_f1_m: 0.2819 - val_precision_m: 0.1769 - val_recall_m: 0.7041\n",
            "Epoch 280/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6296 - acc: 0.6654 - f1_m: 0.6654 - precision_m: 0.6682 - recall_m: 0.6635 - val_loss: 0.6438 - val_acc: 0.6588 - val_f1_m: 0.2816 - val_precision_m: 0.1767 - val_recall_m: 0.7041\n",
            "Epoch 281/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6293 - acc: 0.6658 - f1_m: 0.6582 - precision_m: 0.6631 - recall_m: 0.6537 - val_loss: 0.6432 - val_acc: 0.6588 - val_f1_m: 0.2810 - val_precision_m: 0.1763 - val_recall_m: 0.7015\n",
            "Epoch 282/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6290 - acc: 0.6654 - f1_m: 0.6634 - precision_m: 0.6710 - recall_m: 0.6563 - val_loss: 0.6424 - val_acc: 0.6601 - val_f1_m: 0.2804 - val_precision_m: 0.1762 - val_recall_m: 0.6970\n",
            "Epoch 283/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6287 - acc: 0.6656 - f1_m: 0.6634 - precision_m: 0.6735 - recall_m: 0.6540 - val_loss: 0.6421 - val_acc: 0.6605 - val_f1_m: 0.2800 - val_precision_m: 0.1760 - val_recall_m: 0.6950\n",
            "Epoch 284/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6284 - acc: 0.6662 - f1_m: 0.6562 - precision_m: 0.6706 - recall_m: 0.6437 - val_loss: 0.6409 - val_acc: 0.6619 - val_f1_m: 0.2808 - val_precision_m: 0.1766 - val_recall_m: 0.6950\n",
            "Epoch 285/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6282 - acc: 0.6668 - f1_m: 0.6536 - precision_m: 0.6684 - recall_m: 0.6405 - val_loss: 0.6411 - val_acc: 0.6617 - val_f1_m: 0.2807 - val_precision_m: 0.1766 - val_recall_m: 0.6950\n",
            "Epoch 286/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6279 - acc: 0.6668 - f1_m: 0.6587 - precision_m: 0.6645 - recall_m: 0.6536 - val_loss: 0.6421 - val_acc: 0.6605 - val_f1_m: 0.2813 - val_precision_m: 0.1768 - val_recall_m: 0.6995\n",
            "Epoch 287/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6276 - acc: 0.6672 - f1_m: 0.6643 - precision_m: 0.6676 - recall_m: 0.6623 - val_loss: 0.6421 - val_acc: 0.6603 - val_f1_m: 0.2818 - val_precision_m: 0.1770 - val_recall_m: 0.7016\n",
            "Epoch 288/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6273 - acc: 0.6678 - f1_m: 0.6638 - precision_m: 0.6724 - recall_m: 0.6557 - val_loss: 0.6409 - val_acc: 0.6619 - val_f1_m: 0.2815 - val_precision_m: 0.1771 - val_recall_m: 0.6976\n",
            "Epoch 289/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6270 - acc: 0.6678 - f1_m: 0.6630 - precision_m: 0.6682 - recall_m: 0.6586 - val_loss: 0.6406 - val_acc: 0.6621 - val_f1_m: 0.2811 - val_precision_m: 0.1768 - val_recall_m: 0.6953\n",
            "Epoch 290/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6268 - acc: 0.6676 - f1_m: 0.6666 - precision_m: 0.6787 - recall_m: 0.6553 - val_loss: 0.6387 - val_acc: 0.6640 - val_f1_m: 0.2809 - val_precision_m: 0.1770 - val_recall_m: 0.6901\n",
            "Epoch 291/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6265 - acc: 0.6680 - f1_m: 0.6597 - precision_m: 0.6773 - recall_m: 0.6448 - val_loss: 0.6397 - val_acc: 0.6634 - val_f1_m: 0.2818 - val_precision_m: 0.1774 - val_recall_m: 0.6953\n",
            "Epoch 292/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6262 - acc: 0.6682 - f1_m: 0.6646 - precision_m: 0.6742 - recall_m: 0.6558 - val_loss: 0.6419 - val_acc: 0.6596 - val_f1_m: 0.2822 - val_precision_m: 0.1772 - val_recall_m: 0.7040\n",
            "Epoch 293/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6259 - acc: 0.6674 - f1_m: 0.6556 - precision_m: 0.6610 - recall_m: 0.6511 - val_loss: 0.6416 - val_acc: 0.6596 - val_f1_m: 0.2816 - val_precision_m: 0.1769 - val_recall_m: 0.7016\n",
            "Epoch 294/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6257 - acc: 0.6682 - f1_m: 0.6640 - precision_m: 0.6732 - recall_m: 0.6554 - val_loss: 0.6407 - val_acc: 0.6615 - val_f1_m: 0.2827 - val_precision_m: 0.1777 - val_recall_m: 0.7016\n",
            "Epoch 295/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6254 - acc: 0.6680 - f1_m: 0.6660 - precision_m: 0.6702 - recall_m: 0.6627 - val_loss: 0.6394 - val_acc: 0.6636 - val_f1_m: 0.2813 - val_precision_m: 0.1772 - val_recall_m: 0.6927\n",
            "Epoch 296/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6251 - acc: 0.6688 - f1_m: 0.6692 - precision_m: 0.6785 - recall_m: 0.6604 - val_loss: 0.6386 - val_acc: 0.6644 - val_f1_m: 0.2818 - val_precision_m: 0.1776 - val_recall_m: 0.6927\n",
            "Epoch 297/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6248 - acc: 0.6698 - f1_m: 0.6715 - precision_m: 0.6827 - recall_m: 0.6609 - val_loss: 0.6380 - val_acc: 0.6653 - val_f1_m: 0.2823 - val_precision_m: 0.1780 - val_recall_m: 0.6927\n",
            "Epoch 298/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6246 - acc: 0.6698 - f1_m: 0.6632 - precision_m: 0.6733 - recall_m: 0.6542 - val_loss: 0.6399 - val_acc: 0.6634 - val_f1_m: 0.2845 - val_precision_m: 0.1790 - val_recall_m: 0.7037\n",
            "Epoch 299/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6243 - acc: 0.6688 - f1_m: 0.6587 - precision_m: 0.6664 - recall_m: 0.6516 - val_loss: 0.6407 - val_acc: 0.6615 - val_f1_m: 0.2840 - val_precision_m: 0.1784 - val_recall_m: 0.7062\n",
            "Epoch 300/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6240 - acc: 0.6690 - f1_m: 0.6681 - precision_m: 0.6762 - recall_m: 0.6608 - val_loss: 0.6408 - val_acc: 0.6609 - val_f1_m: 0.2836 - val_precision_m: 0.1782 - val_recall_m: 0.7062\n",
            "Epoch 301/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6238 - acc: 0.6688 - f1_m: 0.6681 - precision_m: 0.6691 - recall_m: 0.6679 - val_loss: 0.6417 - val_acc: 0.6584 - val_f1_m: 0.2828 - val_precision_m: 0.1774 - val_recall_m: 0.7082\n",
            "Epoch 302/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6235 - acc: 0.6692 - f1_m: 0.6589 - precision_m: 0.6712 - recall_m: 0.6489 - val_loss: 0.6408 - val_acc: 0.6601 - val_f1_m: 0.2832 - val_precision_m: 0.1778 - val_recall_m: 0.7062\n",
            "Epoch 303/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6233 - acc: 0.6696 - f1_m: 0.6671 - precision_m: 0.6745 - recall_m: 0.6604 - val_loss: 0.6400 - val_acc: 0.6609 - val_f1_m: 0.2830 - val_precision_m: 0.1778 - val_recall_m: 0.7037\n",
            "Epoch 304/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6230 - acc: 0.6702 - f1_m: 0.6643 - precision_m: 0.6675 - recall_m: 0.6616 - val_loss: 0.6392 - val_acc: 0.6626 - val_f1_m: 0.2840 - val_precision_m: 0.1786 - val_recall_m: 0.7037\n",
            "Epoch 305/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6227 - acc: 0.6704 - f1_m: 0.6665 - precision_m: 0.6819 - recall_m: 0.6535 - val_loss: 0.6383 - val_acc: 0.6636 - val_f1_m: 0.2833 - val_precision_m: 0.1784 - val_recall_m: 0.6994\n",
            "Epoch 306/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6225 - acc: 0.6704 - f1_m: 0.6607 - precision_m: 0.6713 - recall_m: 0.6513 - val_loss: 0.6385 - val_acc: 0.6636 - val_f1_m: 0.2840 - val_precision_m: 0.1787 - val_recall_m: 0.7013\n",
            "Epoch 307/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6222 - acc: 0.6704 - f1_m: 0.6641 - precision_m: 0.6698 - recall_m: 0.6585 - val_loss: 0.6375 - val_acc: 0.6651 - val_f1_m: 0.2842 - val_precision_m: 0.1790 - val_recall_m: 0.6994\n",
            "Epoch 308/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.6220 - acc: 0.6708 - f1_m: 0.6633 - precision_m: 0.6673 - recall_m: 0.6613 - val_loss: 0.6359 - val_acc: 0.6680 - val_f1_m: 0.2840 - val_precision_m: 0.1794 - val_recall_m: 0.6928\n",
            "Epoch 309/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6217 - acc: 0.6708 - f1_m: 0.6618 - precision_m: 0.6758 - recall_m: 0.6489 - val_loss: 0.6339 - val_acc: 0.6715 - val_f1_m: 0.2856 - val_precision_m: 0.1808 - val_recall_m: 0.6903\n",
            "Epoch 310/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6215 - acc: 0.6702 - f1_m: 0.6651 - precision_m: 0.6727 - recall_m: 0.6581 - val_loss: 0.6343 - val_acc: 0.6705 - val_f1_m: 0.2850 - val_precision_m: 0.1803 - val_recall_m: 0.6903\n",
            "Epoch 311/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6212 - acc: 0.6704 - f1_m: 0.6721 - precision_m: 0.6820 - recall_m: 0.6626 - val_loss: 0.6346 - val_acc: 0.6705 - val_f1_m: 0.2856 - val_precision_m: 0.1806 - val_recall_m: 0.6928\n",
            "Epoch 312/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6210 - acc: 0.6704 - f1_m: 0.6665 - precision_m: 0.6811 - recall_m: 0.6542 - val_loss: 0.6352 - val_acc: 0.6692 - val_f1_m: 0.2861 - val_precision_m: 0.1807 - val_recall_m: 0.6974\n",
            "Epoch 313/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6207 - acc: 0.6712 - f1_m: 0.6584 - precision_m: 0.6666 - recall_m: 0.6507 - val_loss: 0.6364 - val_acc: 0.6665 - val_f1_m: 0.2850 - val_precision_m: 0.1797 - val_recall_m: 0.6994\n",
            "Epoch 314/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6205 - acc: 0.6728 - f1_m: 0.6694 - precision_m: 0.6785 - recall_m: 0.6609 - val_loss: 0.6364 - val_acc: 0.6674 - val_f1_m: 0.2869 - val_precision_m: 0.1809 - val_recall_m: 0.7033\n",
            "Epoch 315/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6202 - acc: 0.6732 - f1_m: 0.6659 - precision_m: 0.6751 - recall_m: 0.6576 - val_loss: 0.6372 - val_acc: 0.6665 - val_f1_m: 0.2870 - val_precision_m: 0.1809 - val_recall_m: 0.7053\n",
            "Epoch 316/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6200 - acc: 0.6730 - f1_m: 0.6713 - precision_m: 0.6766 - recall_m: 0.6664 - val_loss: 0.6382 - val_acc: 0.6649 - val_f1_m: 0.2860 - val_precision_m: 0.1801 - val_recall_m: 0.7053\n",
            "Epoch 317/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6198 - acc: 0.6734 - f1_m: 0.6745 - precision_m: 0.6760 - recall_m: 0.6733 - val_loss: 0.6387 - val_acc: 0.6646 - val_f1_m: 0.2866 - val_precision_m: 0.1804 - val_recall_m: 0.7077\n",
            "Epoch 318/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6195 - acc: 0.6736 - f1_m: 0.6700 - precision_m: 0.6731 - recall_m: 0.6671 - val_loss: 0.6387 - val_acc: 0.6649 - val_f1_m: 0.2867 - val_precision_m: 0.1805 - val_recall_m: 0.7077\n",
            "Epoch 319/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6193 - acc: 0.6738 - f1_m: 0.6653 - precision_m: 0.6720 - recall_m: 0.6595 - val_loss: 0.6380 - val_acc: 0.6661 - val_f1_m: 0.2875 - val_precision_m: 0.1811 - val_recall_m: 0.7077\n",
            "Epoch 320/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6190 - acc: 0.6742 - f1_m: 0.6758 - precision_m: 0.6791 - recall_m: 0.6729 - val_loss: 0.6379 - val_acc: 0.6661 - val_f1_m: 0.2874 - val_precision_m: 0.1811 - val_recall_m: 0.7077\n",
            "Epoch 321/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6188 - acc: 0.6748 - f1_m: 0.6666 - precision_m: 0.6735 - recall_m: 0.6608 - val_loss: 0.6379 - val_acc: 0.6657 - val_f1_m: 0.2872 - val_precision_m: 0.1809 - val_recall_m: 0.7077\n",
            "Epoch 322/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6186 - acc: 0.6752 - f1_m: 0.6729 - precision_m: 0.6766 - recall_m: 0.6698 - val_loss: 0.6370 - val_acc: 0.6661 - val_f1_m: 0.2868 - val_precision_m: 0.1807 - val_recall_m: 0.7053\n",
            "Epoch 323/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6183 - acc: 0.6750 - f1_m: 0.6765 - precision_m: 0.6854 - recall_m: 0.6692 - val_loss: 0.6367 - val_acc: 0.6667 - val_f1_m: 0.2872 - val_precision_m: 0.1810 - val_recall_m: 0.7053\n",
            "Epoch 324/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6181 - acc: 0.6756 - f1_m: 0.6808 - precision_m: 0.6900 - recall_m: 0.6730 - val_loss: 0.6371 - val_acc: 0.6657 - val_f1_m: 0.2866 - val_precision_m: 0.1805 - val_recall_m: 0.7053\n",
            "Epoch 325/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6178 - acc: 0.6752 - f1_m: 0.6900 - precision_m: 0.6899 - recall_m: 0.6908 - val_loss: 0.6373 - val_acc: 0.6655 - val_f1_m: 0.2864 - val_precision_m: 0.1804 - val_recall_m: 0.7053\n",
            "Epoch 326/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6176 - acc: 0.6764 - f1_m: 0.6761 - precision_m: 0.6788 - recall_m: 0.6739 - val_loss: 0.6359 - val_acc: 0.6676 - val_f1_m: 0.2870 - val_precision_m: 0.1810 - val_recall_m: 0.7033\n",
            "Epoch 327/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6174 - acc: 0.6758 - f1_m: 0.6764 - precision_m: 0.6838 - recall_m: 0.6700 - val_loss: 0.6352 - val_acc: 0.6684 - val_f1_m: 0.2876 - val_precision_m: 0.1815 - val_recall_m: 0.7033\n",
            "Epoch 328/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6171 - acc: 0.6760 - f1_m: 0.6784 - precision_m: 0.6804 - recall_m: 0.6775 - val_loss: 0.6347 - val_acc: 0.6697 - val_f1_m: 0.2876 - val_precision_m: 0.1817 - val_recall_m: 0.7010\n",
            "Epoch 329/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6168 - acc: 0.6764 - f1_m: 0.6754 - precision_m: 0.6807 - recall_m: 0.6705 - val_loss: 0.6331 - val_acc: 0.6715 - val_f1_m: 0.2889 - val_precision_m: 0.1827 - val_recall_m: 0.7010\n",
            "Epoch 330/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6166 - acc: 0.6778 - f1_m: 0.6755 - precision_m: 0.6823 - recall_m: 0.6691 - val_loss: 0.6328 - val_acc: 0.6718 - val_f1_m: 0.2878 - val_precision_m: 0.1821 - val_recall_m: 0.6966\n",
            "Epoch 331/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6164 - acc: 0.6774 - f1_m: 0.6706 - precision_m: 0.6804 - recall_m: 0.6614 - val_loss: 0.6312 - val_acc: 0.6724 - val_f1_m: 0.2861 - val_precision_m: 0.1813 - val_recall_m: 0.6897\n",
            "Epoch 332/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6162 - acc: 0.6774 - f1_m: 0.6702 - precision_m: 0.6850 - recall_m: 0.6575 - val_loss: 0.6302 - val_acc: 0.6736 - val_f1_m: 0.2869 - val_precision_m: 0.1819 - val_recall_m: 0.6897\n",
            "Epoch 333/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6159 - acc: 0.6782 - f1_m: 0.6713 - precision_m: 0.6785 - recall_m: 0.6656 - val_loss: 0.6314 - val_acc: 0.6724 - val_f1_m: 0.2868 - val_precision_m: 0.1816 - val_recall_m: 0.6922\n",
            "Epoch 334/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6157 - acc: 0.6786 - f1_m: 0.6768 - precision_m: 0.6825 - recall_m: 0.6727 - val_loss: 0.6306 - val_acc: 0.6732 - val_f1_m: 0.2867 - val_precision_m: 0.1817 - val_recall_m: 0.6897\n",
            "Epoch 335/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6155 - acc: 0.6780 - f1_m: 0.6688 - precision_m: 0.6748 - recall_m: 0.6640 - val_loss: 0.6286 - val_acc: 0.6757 - val_f1_m: 0.2882 - val_precision_m: 0.1829 - val_recall_m: 0.6897\n",
            "Epoch 336/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6153 - acc: 0.6778 - f1_m: 0.6698 - precision_m: 0.6801 - recall_m: 0.6602 - val_loss: 0.6260 - val_acc: 0.6793 - val_f1_m: 0.2904 - val_precision_m: 0.1847 - val_recall_m: 0.6897\n",
            "Epoch 337/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6151 - acc: 0.6776 - f1_m: 0.6751 - precision_m: 0.6924 - recall_m: 0.6597 - val_loss: 0.6248 - val_acc: 0.6814 - val_f1_m: 0.2910 - val_precision_m: 0.1853 - val_recall_m: 0.6873\n",
            "Epoch 338/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6148 - acc: 0.6772 - f1_m: 0.6778 - precision_m: 0.6936 - recall_m: 0.6636 - val_loss: 0.6278 - val_acc: 0.6761 - val_f1_m: 0.2885 - val_precision_m: 0.1831 - val_recall_m: 0.6897\n",
            "Epoch 339/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6146 - acc: 0.6786 - f1_m: 0.6776 - precision_m: 0.6919 - recall_m: 0.6651 - val_loss: 0.6296 - val_acc: 0.6745 - val_f1_m: 0.2881 - val_precision_m: 0.1827 - val_recall_m: 0.6916\n",
            "Epoch 340/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6144 - acc: 0.6798 - f1_m: 0.6773 - precision_m: 0.6844 - recall_m: 0.6708 - val_loss: 0.6321 - val_acc: 0.6701 - val_f1_m: 0.2874 - val_precision_m: 0.1816 - val_recall_m: 0.6986\n",
            "Epoch 341/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6142 - acc: 0.6808 - f1_m: 0.6802 - precision_m: 0.6808 - recall_m: 0.6798 - val_loss: 0.6348 - val_acc: 0.6667 - val_f1_m: 0.2867 - val_precision_m: 0.1808 - val_recall_m: 0.7029\n",
            "Epoch 342/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6140 - acc: 0.6806 - f1_m: 0.6786 - precision_m: 0.6799 - recall_m: 0.6778 - val_loss: 0.6332 - val_acc: 0.6686 - val_f1_m: 0.2865 - val_precision_m: 0.1810 - val_recall_m: 0.6986\n",
            "Epoch 343/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6137 - acc: 0.6812 - f1_m: 0.6818 - precision_m: 0.6862 - recall_m: 0.6777 - val_loss: 0.6310 - val_acc: 0.6722 - val_f1_m: 0.2879 - val_precision_m: 0.1822 - val_recall_m: 0.6962\n",
            "Epoch 344/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6135 - acc: 0.6812 - f1_m: 0.6713 - precision_m: 0.6748 - recall_m: 0.6683 - val_loss: 0.6309 - val_acc: 0.6720 - val_f1_m: 0.2878 - val_precision_m: 0.1821 - val_recall_m: 0.6962\n",
            "Epoch 345/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6133 - acc: 0.6808 - f1_m: 0.6702 - precision_m: 0.6751 - recall_m: 0.6656 - val_loss: 0.6298 - val_acc: 0.6730 - val_f1_m: 0.2885 - val_precision_m: 0.1827 - val_recall_m: 0.6962\n",
            "Epoch 346/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6131 - acc: 0.6806 - f1_m: 0.6813 - precision_m: 0.6885 - recall_m: 0.6744 - val_loss: 0.6274 - val_acc: 0.6766 - val_f1_m: 0.2887 - val_precision_m: 0.1833 - val_recall_m: 0.6892\n",
            "Epoch 347/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6129 - acc: 0.6796 - f1_m: 0.6817 - precision_m: 0.6931 - recall_m: 0.6713 - val_loss: 0.6266 - val_acc: 0.6778 - val_f1_m: 0.2895 - val_precision_m: 0.1840 - val_recall_m: 0.6892\n",
            "Epoch 348/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6127 - acc: 0.6796 - f1_m: 0.6743 - precision_m: 0.6854 - recall_m: 0.6643 - val_loss: 0.6274 - val_acc: 0.6763 - val_f1_m: 0.2886 - val_precision_m: 0.1832 - val_recall_m: 0.6892\n",
            "Epoch 349/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6125 - acc: 0.6812 - f1_m: 0.6815 - precision_m: 0.6891 - recall_m: 0.6742 - val_loss: 0.6286 - val_acc: 0.6757 - val_f1_m: 0.2903 - val_precision_m: 0.1841 - val_recall_m: 0.6962\n",
            "Epoch 350/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6123 - acc: 0.6820 - f1_m: 0.6755 - precision_m: 0.6818 - recall_m: 0.6694 - val_loss: 0.6289 - val_acc: 0.6751 - val_f1_m: 0.2906 - val_precision_m: 0.1842 - val_recall_m: 0.6987\n",
            "Epoch 351/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6121 - acc: 0.6826 - f1_m: 0.6874 - precision_m: 0.6926 - recall_m: 0.6833 - val_loss: 0.6273 - val_acc: 0.6768 - val_f1_m: 0.2896 - val_precision_m: 0.1839 - val_recall_m: 0.6912\n",
            "Epoch 352/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6119 - acc: 0.6826 - f1_m: 0.6775 - precision_m: 0.6819 - recall_m: 0.6736 - val_loss: 0.6280 - val_acc: 0.6761 - val_f1_m: 0.2906 - val_precision_m: 0.1844 - val_recall_m: 0.6962\n",
            "Epoch 353/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6117 - acc: 0.6824 - f1_m: 0.6818 - precision_m: 0.6843 - recall_m: 0.6801 - val_loss: 0.6266 - val_acc: 0.6782 - val_f1_m: 0.2906 - val_precision_m: 0.1847 - val_recall_m: 0.6915\n",
            "Epoch 354/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6115 - acc: 0.6810 - f1_m: 0.6832 - precision_m: 0.6919 - recall_m: 0.6750 - val_loss: 0.6239 - val_acc: 0.6824 - val_f1_m: 0.2925 - val_precision_m: 0.1864 - val_recall_m: 0.6895\n",
            "Epoch 355/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6113 - acc: 0.6808 - f1_m: 0.6743 - precision_m: 0.6847 - recall_m: 0.6647 - val_loss: 0.6230 - val_acc: 0.6830 - val_f1_m: 0.2923 - val_precision_m: 0.1864 - val_recall_m: 0.6875\n",
            "Epoch 356/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6111 - acc: 0.6816 - f1_m: 0.6757 - precision_m: 0.6941 - recall_m: 0.6597 - val_loss: 0.6220 - val_acc: 0.6845 - val_f1_m: 0.2933 - val_precision_m: 0.1873 - val_recall_m: 0.6875\n",
            "Epoch 357/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6109 - acc: 0.6812 - f1_m: 0.6733 - precision_m: 0.6803 - recall_m: 0.6670 - val_loss: 0.6241 - val_acc: 0.6818 - val_f1_m: 0.2928 - val_precision_m: 0.1865 - val_recall_m: 0.6915\n",
            "Epoch 358/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6107 - acc: 0.6820 - f1_m: 0.6851 - precision_m: 0.6962 - recall_m: 0.6751 - val_loss: 0.6255 - val_acc: 0.6799 - val_f1_m: 0.2916 - val_precision_m: 0.1855 - val_recall_m: 0.6915\n",
            "Epoch 359/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6105 - acc: 0.6824 - f1_m: 0.6823 - precision_m: 0.6866 - recall_m: 0.6784 - val_loss: 0.6271 - val_acc: 0.6789 - val_f1_m: 0.2924 - val_precision_m: 0.1858 - val_recall_m: 0.6958\n",
            "Epoch 360/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6103 - acc: 0.6826 - f1_m: 0.6823 - precision_m: 0.6848 - recall_m: 0.6805 - val_loss: 0.6276 - val_acc: 0.6780 - val_f1_m: 0.2931 - val_precision_m: 0.1861 - val_recall_m: 0.7007\n",
            "Epoch 361/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6101 - acc: 0.6826 - f1_m: 0.6843 - precision_m: 0.6909 - recall_m: 0.6787 - val_loss: 0.6269 - val_acc: 0.6784 - val_f1_m: 0.2928 - val_precision_m: 0.1860 - val_recall_m: 0.6984\n",
            "Epoch 362/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6099 - acc: 0.6834 - f1_m: 0.6760 - precision_m: 0.6856 - recall_m: 0.6680 - val_loss: 0.6278 - val_acc: 0.6778 - val_f1_m: 0.2936 - val_precision_m: 0.1863 - val_recall_m: 0.7027\n",
            "Epoch 363/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.6097 - acc: 0.6838 - f1_m: 0.6843 - precision_m: 0.6854 - recall_m: 0.6834 - val_loss: 0.6271 - val_acc: 0.6784 - val_f1_m: 0.2934 - val_precision_m: 0.1863 - val_recall_m: 0.7007\n",
            "Epoch 364/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6095 - acc: 0.6834 - f1_m: 0.6830 - precision_m: 0.6880 - recall_m: 0.6783 - val_loss: 0.6254 - val_acc: 0.6801 - val_f1_m: 0.2932 - val_precision_m: 0.1865 - val_recall_m: 0.6958\n",
            "Epoch 365/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6093 - acc: 0.6832 - f1_m: 0.6746 - precision_m: 0.6782 - recall_m: 0.6717 - val_loss: 0.6236 - val_acc: 0.6820 - val_f1_m: 0.2930 - val_precision_m: 0.1867 - val_recall_m: 0.6914\n",
            "Epoch 366/1000\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.6092 - acc: 0.6844 - f1_m: 0.6779 - precision_m: 0.6890 - recall_m: 0.6674 - val_loss: 0.6215 - val_acc: 0.6849 - val_f1_m: 0.2950 - val_precision_m: 0.1883 - val_recall_m: 0.6914\n",
            "Epoch 367/1000\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.6090 - acc: 0.6844 - f1_m: 0.6783 - precision_m: 0.6912 - recall_m: 0.6663 - val_loss: 0.6208 - val_acc: 0.6858 - val_f1_m: 0.2949 - val_precision_m: 0.1884 - val_recall_m: 0.6888\n",
            "Epoch 368/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6088 - acc: 0.6842 - f1_m: 0.6775 - precision_m: 0.6911 - recall_m: 0.6649 - val_loss: 0.6220 - val_acc: 0.6841 - val_f1_m: 0.2944 - val_precision_m: 0.1879 - val_recall_m: 0.6914\n",
            "Epoch 369/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6086 - acc: 0.6840 - f1_m: 0.6777 - precision_m: 0.6881 - recall_m: 0.6679 - val_loss: 0.6221 - val_acc: 0.6837 - val_f1_m: 0.2942 - val_precision_m: 0.1876 - val_recall_m: 0.6914\n",
            "Epoch 370/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6084 - acc: 0.6844 - f1_m: 0.6746 - precision_m: 0.6892 - recall_m: 0.6621 - val_loss: 0.6225 - val_acc: 0.6839 - val_f1_m: 0.2950 - val_precision_m: 0.1881 - val_recall_m: 0.6938\n",
            "Epoch 371/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6083 - acc: 0.6844 - f1_m: 0.6798 - precision_m: 0.6873 - recall_m: 0.6727 - val_loss: 0.6226 - val_acc: 0.6835 - val_f1_m: 0.2948 - val_precision_m: 0.1879 - val_recall_m: 0.6938\n",
            "Epoch 372/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6081 - acc: 0.6856 - f1_m: 0.6747 - precision_m: 0.6785 - recall_m: 0.6716 - val_loss: 0.6234 - val_acc: 0.6826 - val_f1_m: 0.2954 - val_precision_m: 0.1882 - val_recall_m: 0.6981\n",
            "Epoch 373/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6079 - acc: 0.6848 - f1_m: 0.6825 - precision_m: 0.6873 - recall_m: 0.6788 - val_loss: 0.6204 - val_acc: 0.6855 - val_f1_m: 0.2941 - val_precision_m: 0.1879 - val_recall_m: 0.6869\n",
            "Epoch 374/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6078 - acc: 0.6844 - f1_m: 0.6725 - precision_m: 0.6849 - recall_m: 0.6612 - val_loss: 0.6197 - val_acc: 0.6868 - val_f1_m: 0.2949 - val_precision_m: 0.1885 - val_recall_m: 0.6869\n",
            "Epoch 375/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6076 - acc: 0.6846 - f1_m: 0.6812 - precision_m: 0.6895 - recall_m: 0.6733 - val_loss: 0.6195 - val_acc: 0.6868 - val_f1_m: 0.2949 - val_precision_m: 0.1885 - val_recall_m: 0.6869\n",
            "Epoch 376/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6074 - acc: 0.6840 - f1_m: 0.6745 - precision_m: 0.6785 - recall_m: 0.6729 - val_loss: 0.6189 - val_acc: 0.6868 - val_f1_m: 0.2942 - val_precision_m: 0.1882 - val_recall_m: 0.6849\n",
            "Epoch 377/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6072 - acc: 0.6842 - f1_m: 0.6725 - precision_m: 0.6875 - recall_m: 0.6592 - val_loss: 0.6166 - val_acc: 0.6893 - val_f1_m: 0.2958 - val_precision_m: 0.1894 - val_recall_m: 0.6849\n",
            "Epoch 378/1000\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.6071 - acc: 0.6824 - f1_m: 0.6753 - precision_m: 0.6957 - recall_m: 0.6571 - val_loss: 0.6142 - val_acc: 0.6926 - val_f1_m: 0.2975 - val_precision_m: 0.1910 - val_recall_m: 0.6829\n",
            "Epoch 379/1000\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.6069 - acc: 0.6830 - f1_m: 0.6723 - precision_m: 0.6846 - recall_m: 0.6610 - val_loss: 0.6153 - val_acc: 0.6910 - val_f1_m: 0.2963 - val_precision_m: 0.1900 - val_recall_m: 0.6829\n",
            "Epoch 380/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6068 - acc: 0.6834 - f1_m: 0.6753 - precision_m: 0.6957 - recall_m: 0.6575 - val_loss: 0.6171 - val_acc: 0.6895 - val_f1_m: 0.2959 - val_precision_m: 0.1895 - val_recall_m: 0.6849\n",
            "Epoch 381/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6066 - acc: 0.6850 - f1_m: 0.6824 - precision_m: 0.6926 - recall_m: 0.6727 - val_loss: 0.6197 - val_acc: 0.6855 - val_f1_m: 0.2940 - val_precision_m: 0.1878 - val_recall_m: 0.6872\n",
            "Epoch 382/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6064 - acc: 0.6860 - f1_m: 0.6861 - precision_m: 0.6924 - recall_m: 0.6805 - val_loss: 0.6208 - val_acc: 0.6847 - val_f1_m: 0.2948 - val_precision_m: 0.1882 - val_recall_m: 0.6916\n",
            "Epoch 383/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6063 - acc: 0.6866 - f1_m: 0.6860 - precision_m: 0.6929 - recall_m: 0.6795 - val_loss: 0.6230 - val_acc: 0.6816 - val_f1_m: 0.2941 - val_precision_m: 0.1873 - val_recall_m: 0.6956\n",
            "Epoch 384/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6061 - acc: 0.6877 - f1_m: 0.6783 - precision_m: 0.6840 - recall_m: 0.6731 - val_loss: 0.6231 - val_acc: 0.6812 - val_f1_m: 0.2938 - val_precision_m: 0.1870 - val_recall_m: 0.6956\n",
            "Epoch 385/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6060 - acc: 0.6868 - f1_m: 0.6805 - precision_m: 0.6870 - recall_m: 0.6749 - val_loss: 0.6208 - val_acc: 0.6839 - val_f1_m: 0.2942 - val_precision_m: 0.1876 - val_recall_m: 0.6916\n",
            "Epoch 386/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6058 - acc: 0.6866 - f1_m: 0.6844 - precision_m: 0.6908 - recall_m: 0.6787 - val_loss: 0.6189 - val_acc: 0.6868 - val_f1_m: 0.2955 - val_precision_m: 0.1889 - val_recall_m: 0.6892\n",
            "Epoch 387/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6056 - acc: 0.6860 - f1_m: 0.6818 - precision_m: 0.6854 - recall_m: 0.6802 - val_loss: 0.6177 - val_acc: 0.6885 - val_f1_m: 0.2959 - val_precision_m: 0.1894 - val_recall_m: 0.6872\n",
            "Epoch 388/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6055 - acc: 0.6854 - f1_m: 0.6822 - precision_m: 0.6957 - recall_m: 0.6698 - val_loss: 0.6170 - val_acc: 0.6893 - val_f1_m: 0.2958 - val_precision_m: 0.1894 - val_recall_m: 0.6852\n",
            "Epoch 389/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6053 - acc: 0.6866 - f1_m: 0.6815 - precision_m: 0.6872 - recall_m: 0.6769 - val_loss: 0.6189 - val_acc: 0.6868 - val_f1_m: 0.2962 - val_precision_m: 0.1892 - val_recall_m: 0.6916\n",
            "Epoch 390/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6052 - acc: 0.6874 - f1_m: 0.6788 - precision_m: 0.6856 - recall_m: 0.6726 - val_loss: 0.6191 - val_acc: 0.6862 - val_f1_m: 0.2958 - val_precision_m: 0.1889 - val_recall_m: 0.6916\n",
            "Epoch 391/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6050 - acc: 0.6877 - f1_m: 0.6820 - precision_m: 0.6914 - recall_m: 0.6732 - val_loss: 0.6179 - val_acc: 0.6870 - val_f1_m: 0.2949 - val_precision_m: 0.1885 - val_recall_m: 0.6872\n",
            "Epoch 392/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6048 - acc: 0.6874 - f1_m: 0.6762 - precision_m: 0.6822 - recall_m: 0.6711 - val_loss: 0.6168 - val_acc: 0.6883 - val_f1_m: 0.2957 - val_precision_m: 0.1891 - val_recall_m: 0.6872\n",
            "Epoch 393/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6047 - acc: 0.6887 - f1_m: 0.6836 - precision_m: 0.6948 - recall_m: 0.6728 - val_loss: 0.6145 - val_acc: 0.6922 - val_f1_m: 0.2978 - val_precision_m: 0.1910 - val_recall_m: 0.6852\n",
            "Epoch 394/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6045 - acc: 0.6883 - f1_m: 0.6849 - precision_m: 0.6967 - recall_m: 0.6737 - val_loss: 0.6136 - val_acc: 0.6933 - val_f1_m: 0.2985 - val_precision_m: 0.1917 - val_recall_m: 0.6852\n",
            "Epoch 395/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6044 - acc: 0.6879 - f1_m: 0.6763 - precision_m: 0.6908 - recall_m: 0.6628 - val_loss: 0.6129 - val_acc: 0.6939 - val_f1_m: 0.2990 - val_precision_m: 0.1920 - val_recall_m: 0.6852\n",
            "Epoch 396/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.6042 - acc: 0.6887 - f1_m: 0.6871 - precision_m: 0.7022 - recall_m: 0.6734 - val_loss: 0.6143 - val_acc: 0.6918 - val_f1_m: 0.2975 - val_precision_m: 0.1908 - val_recall_m: 0.6852\n",
            "Epoch 397/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6041 - acc: 0.6899 - f1_m: 0.6774 - precision_m: 0.6859 - recall_m: 0.6694 - val_loss: 0.6155 - val_acc: 0.6908 - val_f1_m: 0.2974 - val_precision_m: 0.1905 - val_recall_m: 0.6872\n",
            "Epoch 398/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6039 - acc: 0.6903 - f1_m: 0.6902 - precision_m: 0.7000 - recall_m: 0.6811 - val_loss: 0.6148 - val_acc: 0.6912 - val_f1_m: 0.2977 - val_precision_m: 0.1908 - val_recall_m: 0.6872\n",
            "Epoch 399/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6038 - acc: 0.6901 - f1_m: 0.6803 - precision_m: 0.6865 - recall_m: 0.6752 - val_loss: 0.6157 - val_acc: 0.6903 - val_f1_m: 0.2971 - val_precision_m: 0.1903 - val_recall_m: 0.6872\n",
            "Epoch 400/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6037 - acc: 0.6901 - f1_m: 0.6882 - precision_m: 0.7024 - recall_m: 0.6753 - val_loss: 0.6135 - val_acc: 0.6924 - val_f1_m: 0.2979 - val_precision_m: 0.1911 - val_recall_m: 0.6852\n",
            "Epoch 401/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6035 - acc: 0.6903 - f1_m: 0.6923 - precision_m: 0.7057 - recall_m: 0.6799 - val_loss: 0.6140 - val_acc: 0.6924 - val_f1_m: 0.2986 - val_precision_m: 0.1915 - val_recall_m: 0.6872\n",
            "Epoch 402/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6033 - acc: 0.6913 - f1_m: 0.6876 - precision_m: 0.6982 - recall_m: 0.6778 - val_loss: 0.6171 - val_acc: 0.6883 - val_f1_m: 0.2965 - val_precision_m: 0.1896 - val_recall_m: 0.6896\n",
            "Epoch 403/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6032 - acc: 0.6895 - f1_m: 0.6849 - precision_m: 0.6987 - recall_m: 0.6732 - val_loss: 0.6196 - val_acc: 0.6849 - val_f1_m: 0.2950 - val_precision_m: 0.1882 - val_recall_m: 0.6920\n",
            "Epoch 404/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6031 - acc: 0.6895 - f1_m: 0.6824 - precision_m: 0.6890 - recall_m: 0.6763 - val_loss: 0.6232 - val_acc: 0.6807 - val_f1_m: 0.2935 - val_precision_m: 0.1866 - val_recall_m: 0.6960\n",
            "Epoch 405/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6030 - acc: 0.6899 - f1_m: 0.6963 - precision_m: 0.6954 - recall_m: 0.6976 - val_loss: 0.6238 - val_acc: 0.6812 - val_f1_m: 0.2963 - val_precision_m: 0.1883 - val_recall_m: 0.7047\n",
            "Epoch 406/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6028 - acc: 0.6899 - f1_m: 0.6829 - precision_m: 0.6838 - recall_m: 0.6827 - val_loss: 0.6216 - val_acc: 0.6828 - val_f1_m: 0.2942 - val_precision_m: 0.1874 - val_recall_m: 0.6940\n",
            "Epoch 407/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.6027 - acc: 0.6899 - f1_m: 0.6941 - precision_m: 0.6967 - recall_m: 0.6917 - val_loss: 0.6187 - val_acc: 0.6866 - val_f1_m: 0.2961 - val_precision_m: 0.1891 - val_recall_m: 0.6920\n",
            "Epoch 408/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6025 - acc: 0.6901 - f1_m: 0.6911 - precision_m: 0.7013 - recall_m: 0.6818 - val_loss: 0.6175 - val_acc: 0.6883 - val_f1_m: 0.2972 - val_precision_m: 0.1900 - val_recall_m: 0.6920\n",
            "Epoch 409/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6024 - acc: 0.6901 - f1_m: 0.6855 - precision_m: 0.6868 - recall_m: 0.6850 - val_loss: 0.6178 - val_acc: 0.6878 - val_f1_m: 0.2970 - val_precision_m: 0.1898 - val_recall_m: 0.6920\n",
            "Epoch 410/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6022 - acc: 0.6909 - f1_m: 0.6852 - precision_m: 0.6922 - recall_m: 0.6785 - val_loss: 0.6157 - val_acc: 0.6893 - val_f1_m: 0.2979 - val_precision_m: 0.1905 - val_recall_m: 0.6920\n",
            "Epoch 411/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6021 - acc: 0.6911 - f1_m: 0.6856 - precision_m: 0.6925 - recall_m: 0.6791 - val_loss: 0.6151 - val_acc: 0.6893 - val_f1_m: 0.2979 - val_precision_m: 0.1905 - val_recall_m: 0.6920\n",
            "Epoch 412/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6019 - acc: 0.6909 - f1_m: 0.6820 - precision_m: 0.6908 - recall_m: 0.6741 - val_loss: 0.6136 - val_acc: 0.6912 - val_f1_m: 0.2971 - val_precision_m: 0.1904 - val_recall_m: 0.6852\n",
            "Epoch 413/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6018 - acc: 0.6907 - f1_m: 0.6920 - precision_m: 0.6994 - recall_m: 0.6853 - val_loss: 0.6128 - val_acc: 0.6924 - val_f1_m: 0.2979 - val_precision_m: 0.1912 - val_recall_m: 0.6852\n",
            "Epoch 414/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6017 - acc: 0.6917 - f1_m: 0.6907 - precision_m: 0.7067 - recall_m: 0.6765 - val_loss: 0.6117 - val_acc: 0.6937 - val_f1_m: 0.2982 - val_precision_m: 0.1915 - val_recall_m: 0.6829\n",
            "Epoch 415/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6015 - acc: 0.6911 - f1_m: 0.6900 - precision_m: 0.6987 - recall_m: 0.6820 - val_loss: 0.6137 - val_acc: 0.6918 - val_f1_m: 0.2990 - val_precision_m: 0.1916 - val_recall_m: 0.6900\n",
            "Epoch 416/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6014 - acc: 0.6911 - f1_m: 0.6876 - precision_m: 0.6975 - recall_m: 0.6783 - val_loss: 0.6147 - val_acc: 0.6903 - val_f1_m: 0.2986 - val_precision_m: 0.1912 - val_recall_m: 0.6920\n",
            "Epoch 417/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6013 - acc: 0.6909 - f1_m: 0.6910 - precision_m: 0.6997 - recall_m: 0.6830 - val_loss: 0.6159 - val_acc: 0.6885 - val_f1_m: 0.2980 - val_precision_m: 0.1904 - val_recall_m: 0.6940\n",
            "Epoch 418/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6011 - acc: 0.6913 - f1_m: 0.6885 - precision_m: 0.6949 - recall_m: 0.6827 - val_loss: 0.6163 - val_acc: 0.6883 - val_f1_m: 0.2978 - val_precision_m: 0.1903 - val_recall_m: 0.6940\n",
            "Epoch 419/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6010 - acc: 0.6905 - f1_m: 0.6811 - precision_m: 0.6900 - recall_m: 0.6731 - val_loss: 0.6165 - val_acc: 0.6885 - val_f1_m: 0.2980 - val_precision_m: 0.1904 - val_recall_m: 0.6940\n",
            "Epoch 420/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6009 - acc: 0.6911 - f1_m: 0.6810 - precision_m: 0.6913 - recall_m: 0.6717 - val_loss: 0.6143 - val_acc: 0.6916 - val_f1_m: 0.3001 - val_precision_m: 0.1922 - val_recall_m: 0.6940\n",
            "Epoch 421/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6008 - acc: 0.6919 - f1_m: 0.6792 - precision_m: 0.6880 - recall_m: 0.6709 - val_loss: 0.6126 - val_acc: 0.6933 - val_f1_m: 0.2993 - val_precision_m: 0.1921 - val_recall_m: 0.6873\n",
            "Epoch 422/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6006 - acc: 0.6919 - f1_m: 0.6858 - precision_m: 0.6988 - recall_m: 0.6737 - val_loss: 0.6116 - val_acc: 0.6949 - val_f1_m: 0.3005 - val_precision_m: 0.1931 - val_recall_m: 0.6873\n",
            "Epoch 423/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6005 - acc: 0.6917 - f1_m: 0.6869 - precision_m: 0.6926 - recall_m: 0.6824 - val_loss: 0.6123 - val_acc: 0.6943 - val_f1_m: 0.3006 - val_precision_m: 0.1930 - val_recall_m: 0.6893\n",
            "Epoch 424/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6004 - acc: 0.6921 - f1_m: 0.6888 - precision_m: 0.7028 - recall_m: 0.6761 - val_loss: 0.6115 - val_acc: 0.6956 - val_f1_m: 0.3009 - val_precision_m: 0.1934 - val_recall_m: 0.6873\n",
            "Epoch 425/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6003 - acc: 0.6919 - f1_m: 0.6828 - precision_m: 0.6938 - recall_m: 0.6724 - val_loss: 0.6120 - val_acc: 0.6952 - val_f1_m: 0.3005 - val_precision_m: 0.1931 - val_recall_m: 0.6873\n",
            "Epoch 426/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6001 - acc: 0.6919 - f1_m: 0.6826 - precision_m: 0.6974 - recall_m: 0.6697 - val_loss: 0.6129 - val_acc: 0.6939 - val_f1_m: 0.2998 - val_precision_m: 0.1925 - val_recall_m: 0.6874\n",
            "Epoch 427/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.6000 - acc: 0.6917 - f1_m: 0.6886 - precision_m: 0.6984 - recall_m: 0.6793 - val_loss: 0.6142 - val_acc: 0.6933 - val_f1_m: 0.3006 - val_precision_m: 0.1928 - val_recall_m: 0.6917\n",
            "Epoch 428/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5999 - acc: 0.6915 - f1_m: 0.6925 - precision_m: 0.7045 - recall_m: 0.6822 - val_loss: 0.6153 - val_acc: 0.6920 - val_f1_m: 0.3010 - val_precision_m: 0.1927 - val_recall_m: 0.6960\n",
            "Epoch 429/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5998 - acc: 0.6917 - f1_m: 0.6869 - precision_m: 0.6950 - recall_m: 0.6793 - val_loss: 0.6145 - val_acc: 0.6937 - val_f1_m: 0.3009 - val_precision_m: 0.1930 - val_recall_m: 0.6914\n",
            "Epoch 430/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5997 - acc: 0.6923 - f1_m: 0.6889 - precision_m: 0.6897 - recall_m: 0.6899 - val_loss: 0.6159 - val_acc: 0.6903 - val_f1_m: 0.2993 - val_precision_m: 0.1915 - val_recall_m: 0.6937\n",
            "Epoch 431/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5995 - acc: 0.6911 - f1_m: 0.6810 - precision_m: 0.6900 - recall_m: 0.6726 - val_loss: 0.6130 - val_acc: 0.6949 - val_f1_m: 0.3005 - val_precision_m: 0.1931 - val_recall_m: 0.6868\n",
            "Epoch 432/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5994 - acc: 0.6917 - f1_m: 0.6830 - precision_m: 0.6918 - recall_m: 0.6746 - val_loss: 0.6117 - val_acc: 0.6954 - val_f1_m: 0.3001 - val_precision_m: 0.1929 - val_recall_m: 0.6848\n",
            "Epoch 433/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5993 - acc: 0.6917 - f1_m: 0.6860 - precision_m: 0.6993 - recall_m: 0.6742 - val_loss: 0.6123 - val_acc: 0.6952 - val_f1_m: 0.3006 - val_precision_m: 0.1932 - val_recall_m: 0.6868\n",
            "Epoch 434/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5992 - acc: 0.6911 - f1_m: 0.6879 - precision_m: 0.6921 - recall_m: 0.6846 - val_loss: 0.6140 - val_acc: 0.6939 - val_f1_m: 0.2998 - val_precision_m: 0.1924 - val_recall_m: 0.6868\n",
            "Epoch 435/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5990 - acc: 0.6905 - f1_m: 0.6935 - precision_m: 0.6969 - recall_m: 0.6919 - val_loss: 0.6122 - val_acc: 0.6956 - val_f1_m: 0.3008 - val_precision_m: 0.1933 - val_recall_m: 0.6868\n",
            "Epoch 436/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5989 - acc: 0.6917 - f1_m: 0.6846 - precision_m: 0.6908 - recall_m: 0.6792 - val_loss: 0.6104 - val_acc: 0.6962 - val_f1_m: 0.3005 - val_precision_m: 0.1932 - val_recall_m: 0.6844\n",
            "Epoch 437/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5988 - acc: 0.6911 - f1_m: 0.6887 - precision_m: 0.7040 - recall_m: 0.6750 - val_loss: 0.6076 - val_acc: 0.6979 - val_f1_m: 0.3004 - val_precision_m: 0.1935 - val_recall_m: 0.6804\n",
            "Epoch 438/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5987 - acc: 0.6917 - f1_m: 0.6872 - precision_m: 0.6989 - recall_m: 0.6766 - val_loss: 0.6073 - val_acc: 0.6977 - val_f1_m: 0.3003 - val_precision_m: 0.1934 - val_recall_m: 0.6804\n",
            "Epoch 439/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5986 - acc: 0.6917 - f1_m: 0.6863 - precision_m: 0.6965 - recall_m: 0.6767 - val_loss: 0.6075 - val_acc: 0.6979 - val_f1_m: 0.3004 - val_precision_m: 0.1936 - val_recall_m: 0.6804\n",
            "Epoch 440/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5985 - acc: 0.6919 - f1_m: 0.6865 - precision_m: 0.7000 - recall_m: 0.6740 - val_loss: 0.6070 - val_acc: 0.6981 - val_f1_m: 0.3006 - val_precision_m: 0.1937 - val_recall_m: 0.6804\n",
            "Epoch 441/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5984 - acc: 0.6921 - f1_m: 0.6801 - precision_m: 0.6954 - recall_m: 0.6665 - val_loss: 0.6087 - val_acc: 0.6975 - val_f1_m: 0.3014 - val_precision_m: 0.1940 - val_recall_m: 0.6844\n",
            "Epoch 442/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5982 - acc: 0.6925 - f1_m: 0.6875 - precision_m: 0.6976 - recall_m: 0.6781 - val_loss: 0.6116 - val_acc: 0.6956 - val_f1_m: 0.3009 - val_precision_m: 0.1934 - val_recall_m: 0.6868\n",
            "Epoch 443/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5981 - acc: 0.6925 - f1_m: 0.6877 - precision_m: 0.6938 - recall_m: 0.6822 - val_loss: 0.6131 - val_acc: 0.6941 - val_f1_m: 0.2999 - val_precision_m: 0.1926 - val_recall_m: 0.6868\n",
            "Epoch 444/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5980 - acc: 0.6929 - f1_m: 0.6851 - precision_m: 0.6912 - recall_m: 0.6800 - val_loss: 0.6112 - val_acc: 0.6960 - val_f1_m: 0.3011 - val_precision_m: 0.1936 - val_recall_m: 0.6868\n",
            "Epoch 445/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5979 - acc: 0.6929 - f1_m: 0.6914 - precision_m: 0.7023 - recall_m: 0.6814 - val_loss: 0.6100 - val_acc: 0.6962 - val_f1_m: 0.3005 - val_precision_m: 0.1933 - val_recall_m: 0.6844\n",
            "Epoch 446/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5978 - acc: 0.6927 - f1_m: 0.6836 - precision_m: 0.6967 - recall_m: 0.6719 - val_loss: 0.6096 - val_acc: 0.6966 - val_f1_m: 0.3008 - val_precision_m: 0.1935 - val_recall_m: 0.6844\n",
            "Epoch 447/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5977 - acc: 0.6925 - f1_m: 0.6913 - precision_m: 0.7024 - recall_m: 0.6811 - val_loss: 0.6092 - val_acc: 0.6972 - val_f1_m: 0.3012 - val_precision_m: 0.1938 - val_recall_m: 0.6844\n",
            "Epoch 448/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5976 - acc: 0.6923 - f1_m: 0.6885 - precision_m: 0.6960 - recall_m: 0.6816 - val_loss: 0.6114 - val_acc: 0.6954 - val_f1_m: 0.3008 - val_precision_m: 0.1933 - val_recall_m: 0.6868\n",
            "Epoch 449/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5975 - acc: 0.6923 - f1_m: 0.6871 - precision_m: 0.6981 - recall_m: 0.6770 - val_loss: 0.6110 - val_acc: 0.6958 - val_f1_m: 0.3010 - val_precision_m: 0.1935 - val_recall_m: 0.6868\n",
            "Epoch 450/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5974 - acc: 0.6925 - f1_m: 0.6874 - precision_m: 0.6915 - recall_m: 0.6841 - val_loss: 0.6110 - val_acc: 0.6960 - val_f1_m: 0.3012 - val_precision_m: 0.1936 - val_recall_m: 0.6868\n",
            "Epoch 451/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5973 - acc: 0.6923 - f1_m: 0.6950 - precision_m: 0.7007 - recall_m: 0.6907 - val_loss: 0.6092 - val_acc: 0.6977 - val_f1_m: 0.3015 - val_precision_m: 0.1941 - val_recall_m: 0.6844\n",
            "Epoch 452/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5972 - acc: 0.6929 - f1_m: 0.6845 - precision_m: 0.6953 - recall_m: 0.6746 - val_loss: 0.6077 - val_acc: 0.6989 - val_f1_m: 0.3024 - val_precision_m: 0.1947 - val_recall_m: 0.6844\n",
            "Epoch 453/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5971 - acc: 0.6931 - f1_m: 0.6894 - precision_m: 0.6959 - recall_m: 0.6839 - val_loss: 0.6079 - val_acc: 0.6987 - val_f1_m: 0.3022 - val_precision_m: 0.1946 - val_recall_m: 0.6844\n",
            "Epoch 454/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5970 - acc: 0.6929 - f1_m: 0.6838 - precision_m: 0.6947 - recall_m: 0.6743 - val_loss: 0.6083 - val_acc: 0.6981 - val_f1_m: 0.3018 - val_precision_m: 0.1943 - val_recall_m: 0.6844\n",
            "Epoch 455/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5968 - acc: 0.6929 - f1_m: 0.6929 - precision_m: 0.7076 - recall_m: 0.6797 - val_loss: 0.6076 - val_acc: 0.6989 - val_f1_m: 0.3016 - val_precision_m: 0.1943 - val_recall_m: 0.6819\n",
            "Epoch 456/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5967 - acc: 0.6931 - f1_m: 0.6913 - precision_m: 0.7038 - recall_m: 0.6798 - val_loss: 0.6102 - val_acc: 0.6970 - val_f1_m: 0.3026 - val_precision_m: 0.1946 - val_recall_m: 0.6888\n",
            "Epoch 457/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5966 - acc: 0.6925 - f1_m: 0.6949 - precision_m: 0.7042 - recall_m: 0.6863 - val_loss: 0.6125 - val_acc: 0.6945 - val_f1_m: 0.3015 - val_precision_m: 0.1936 - val_recall_m: 0.6909\n",
            "Epoch 458/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5966 - acc: 0.6923 - f1_m: 0.6886 - precision_m: 0.6888 - recall_m: 0.6894 - val_loss: 0.6148 - val_acc: 0.6926 - val_f1_m: 0.3008 - val_precision_m: 0.1928 - val_recall_m: 0.6929\n",
            "Epoch 459/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5965 - acc: 0.6923 - f1_m: 0.6973 - precision_m: 0.7000 - recall_m: 0.6950 - val_loss: 0.6126 - val_acc: 0.6943 - val_f1_m: 0.3014 - val_precision_m: 0.1935 - val_recall_m: 0.6909\n",
            "Epoch 460/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5964 - acc: 0.6923 - f1_m: 0.6916 - precision_m: 0.7018 - recall_m: 0.6822 - val_loss: 0.6104 - val_acc: 0.6966 - val_f1_m: 0.3029 - val_precision_m: 0.1947 - val_recall_m: 0.6909\n",
            "Epoch 461/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5962 - acc: 0.6929 - f1_m: 0.6827 - precision_m: 0.6880 - recall_m: 0.6781 - val_loss: 0.6102 - val_acc: 0.6968 - val_f1_m: 0.3030 - val_precision_m: 0.1948 - val_recall_m: 0.6909\n",
            "Epoch 462/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5961 - acc: 0.6933 - f1_m: 0.6867 - precision_m: 0.6961 - recall_m: 0.6777 - val_loss: 0.6086 - val_acc: 0.6983 - val_f1_m: 0.3025 - val_precision_m: 0.1947 - val_recall_m: 0.6859\n",
            "Epoch 463/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5960 - acc: 0.6931 - f1_m: 0.6861 - precision_m: 0.6971 - recall_m: 0.6759 - val_loss: 0.6091 - val_acc: 0.6981 - val_f1_m: 0.3031 - val_precision_m: 0.1950 - val_recall_m: 0.6883\n",
            "Epoch 464/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5959 - acc: 0.6929 - f1_m: 0.6853 - precision_m: 0.6983 - recall_m: 0.6742 - val_loss: 0.6105 - val_acc: 0.6970 - val_f1_m: 0.3037 - val_precision_m: 0.1952 - val_recall_m: 0.6929\n",
            "Epoch 465/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5959 - acc: 0.6929 - f1_m: 0.6860 - precision_m: 0.6957 - recall_m: 0.6771 - val_loss: 0.6133 - val_acc: 0.6933 - val_f1_m: 0.3013 - val_precision_m: 0.1932 - val_recall_m: 0.6929\n",
            "Epoch 466/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5958 - acc: 0.6931 - f1_m: 0.6885 - precision_m: 0.6970 - recall_m: 0.6809 - val_loss: 0.6139 - val_acc: 0.6929 - val_f1_m: 0.3010 - val_precision_m: 0.1929 - val_recall_m: 0.6929\n",
            "Epoch 467/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5957 - acc: 0.6935 - f1_m: 0.6944 - precision_m: 0.6963 - recall_m: 0.6932 - val_loss: 0.6128 - val_acc: 0.6941 - val_f1_m: 0.3018 - val_precision_m: 0.1936 - val_recall_m: 0.6929\n",
            "Epoch 468/1000\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.5956 - acc: 0.6923 - f1_m: 0.6883 - precision_m: 0.6971 - recall_m: 0.6801 - val_loss: 0.6108 - val_acc: 0.6964 - val_f1_m: 0.3026 - val_precision_m: 0.1945 - val_recall_m: 0.6903\n",
            "Epoch 469/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5955 - acc: 0.6927 - f1_m: 0.6848 - precision_m: 0.6987 - recall_m: 0.6734 - val_loss: 0.6106 - val_acc: 0.6966 - val_f1_m: 0.3028 - val_precision_m: 0.1946 - val_recall_m: 0.6903\n",
            "Epoch 470/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5954 - acc: 0.6929 - f1_m: 0.6917 - precision_m: 0.6999 - recall_m: 0.6841 - val_loss: 0.6092 - val_acc: 0.6989 - val_f1_m: 0.3044 - val_precision_m: 0.1960 - val_recall_m: 0.6903\n",
            "Epoch 471/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5953 - acc: 0.6935 - f1_m: 0.6941 - precision_m: 0.7075 - recall_m: 0.6821 - val_loss: 0.6094 - val_acc: 0.6983 - val_f1_m: 0.3040 - val_precision_m: 0.1956 - val_recall_m: 0.6903\n",
            "Epoch 472/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5952 - acc: 0.6929 - f1_m: 0.6916 - precision_m: 0.6930 - recall_m: 0.6912 - val_loss: 0.6119 - val_acc: 0.6960 - val_f1_m: 0.3024 - val_precision_m: 0.1943 - val_recall_m: 0.6903\n",
            "Epoch 473/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5951 - acc: 0.6929 - f1_m: 0.6967 - precision_m: 0.7016 - recall_m: 0.6927 - val_loss: 0.6103 - val_acc: 0.6975 - val_f1_m: 0.3034 - val_precision_m: 0.1952 - val_recall_m: 0.6903\n",
            "Epoch 474/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5950 - acc: 0.6939 - f1_m: 0.6934 - precision_m: 0.6980 - recall_m: 0.6895 - val_loss: 0.6080 - val_acc: 0.6993 - val_f1_m: 0.3047 - val_precision_m: 0.1963 - val_recall_m: 0.6903\n",
            "Epoch 475/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5949 - acc: 0.6937 - f1_m: 0.6853 - precision_m: 0.6984 - recall_m: 0.6735 - val_loss: 0.6039 - val_acc: 0.7037 - val_f1_m: 0.3058 - val_precision_m: 0.1977 - val_recall_m: 0.6839\n",
            "Epoch 476/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5948 - acc: 0.6945 - f1_m: 0.6899 - precision_m: 0.6999 - recall_m: 0.6805 - val_loss: 0.6036 - val_acc: 0.7041 - val_f1_m: 0.3061 - val_precision_m: 0.1979 - val_recall_m: 0.6839\n",
            "Epoch 477/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5947 - acc: 0.6945 - f1_m: 0.6859 - precision_m: 0.6992 - recall_m: 0.6734 - val_loss: 0.6047 - val_acc: 0.7033 - val_f1_m: 0.3062 - val_precision_m: 0.1978 - val_recall_m: 0.6859\n",
            "Epoch 478/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5946 - acc: 0.6941 - f1_m: 0.6955 - precision_m: 0.7073 - recall_m: 0.6845 - val_loss: 0.6059 - val_acc: 0.7027 - val_f1_m: 0.3064 - val_precision_m: 0.1978 - val_recall_m: 0.6879\n",
            "Epoch 479/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5945 - acc: 0.6939 - f1_m: 0.6884 - precision_m: 0.7000 - recall_m: 0.6775 - val_loss: 0.6059 - val_acc: 0.7023 - val_f1_m: 0.3061 - val_precision_m: 0.1976 - val_recall_m: 0.6879\n",
            "Epoch 480/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.5944 - acc: 0.6939 - f1_m: 0.6850 - precision_m: 0.6936 - recall_m: 0.6772 - val_loss: 0.6054 - val_acc: 0.7029 - val_f1_m: 0.3065 - val_precision_m: 0.1980 - val_recall_m: 0.6879\n",
            "Epoch 481/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5943 - acc: 0.6939 - f1_m: 0.6855 - precision_m: 0.6971 - recall_m: 0.6746 - val_loss: 0.6055 - val_acc: 0.7029 - val_f1_m: 0.3065 - val_precision_m: 0.1980 - val_recall_m: 0.6879\n",
            "Epoch 482/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5943 - acc: 0.6939 - f1_m: 0.6935 - precision_m: 0.7043 - recall_m: 0.6845 - val_loss: 0.6054 - val_acc: 0.7031 - val_f1_m: 0.3060 - val_precision_m: 0.1977 - val_recall_m: 0.6859\n",
            "Epoch 483/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5942 - acc: 0.6941 - f1_m: 0.6918 - precision_m: 0.7034 - recall_m: 0.6809 - val_loss: 0.6049 - val_acc: 0.7035 - val_f1_m: 0.3063 - val_precision_m: 0.1979 - val_recall_m: 0.6859\n",
            "Epoch 484/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5941 - acc: 0.6941 - f1_m: 0.6875 - precision_m: 0.7001 - recall_m: 0.6758 - val_loss: 0.6057 - val_acc: 0.7025 - val_f1_m: 0.3062 - val_precision_m: 0.1976 - val_recall_m: 0.6879\n",
            "Epoch 485/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5940 - acc: 0.6937 - f1_m: 0.6893 - precision_m: 0.6955 - recall_m: 0.6838 - val_loss: 0.6066 - val_acc: 0.7014 - val_f1_m: 0.3055 - val_precision_m: 0.1971 - val_recall_m: 0.6879\n",
            "Epoch 486/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5939 - acc: 0.6941 - f1_m: 0.6949 - precision_m: 0.7060 - recall_m: 0.6845 - val_loss: 0.6053 - val_acc: 0.7033 - val_f1_m: 0.3068 - val_precision_m: 0.1982 - val_recall_m: 0.6879\n",
            "Epoch 487/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5938 - acc: 0.6943 - f1_m: 0.6918 - precision_m: 0.6957 - recall_m: 0.6899 - val_loss: 0.6051 - val_acc: 0.7035 - val_f1_m: 0.3069 - val_precision_m: 0.1983 - val_recall_m: 0.6879\n",
            "Epoch 488/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5938 - acc: 0.6943 - f1_m: 0.6888 - precision_m: 0.6985 - recall_m: 0.6797 - val_loss: 0.6042 - val_acc: 0.7037 - val_f1_m: 0.3064 - val_precision_m: 0.1980 - val_recall_m: 0.6859\n",
            "Epoch 489/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5937 - acc: 0.6941 - f1_m: 0.6855 - precision_m: 0.7019 - recall_m: 0.6717 - val_loss: 0.6043 - val_acc: 0.7035 - val_f1_m: 0.3063 - val_precision_m: 0.1979 - val_recall_m: 0.6859\n",
            "Epoch 490/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5936 - acc: 0.6943 - f1_m: 0.6886 - precision_m: 0.6968 - recall_m: 0.6808 - val_loss: 0.6064 - val_acc: 0.7014 - val_f1_m: 0.3062 - val_precision_m: 0.1975 - val_recall_m: 0.6899\n",
            "Epoch 491/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5935 - acc: 0.6943 - f1_m: 0.6939 - precision_m: 0.7024 - recall_m: 0.6861 - val_loss: 0.6081 - val_acc: 0.7000 - val_f1_m: 0.3065 - val_precision_m: 0.1974 - val_recall_m: 0.6943\n",
            "Epoch 492/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5934 - acc: 0.6943 - f1_m: 0.6914 - precision_m: 0.6988 - recall_m: 0.6846 - val_loss: 0.6081 - val_acc: 0.6997 - val_f1_m: 0.3064 - val_precision_m: 0.1973 - val_recall_m: 0.6943\n",
            "Epoch 493/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5934 - acc: 0.6943 - f1_m: 0.6837 - precision_m: 0.6872 - recall_m: 0.6810 - val_loss: 0.6076 - val_acc: 0.7004 - val_f1_m: 0.3068 - val_precision_m: 0.1977 - val_recall_m: 0.6943\n",
            "Epoch 494/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5933 - acc: 0.6947 - f1_m: 0.6918 - precision_m: 0.7013 - recall_m: 0.6829 - val_loss: 0.6053 - val_acc: 0.7031 - val_f1_m: 0.3080 - val_precision_m: 0.1988 - val_recall_m: 0.6919\n",
            "Epoch 495/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5932 - acc: 0.6951 - f1_m: 0.6927 - precision_m: 0.7003 - recall_m: 0.6859 - val_loss: 0.6035 - val_acc: 0.7048 - val_f1_m: 0.3079 - val_precision_m: 0.1991 - val_recall_m: 0.6879\n",
            "Epoch 496/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5932 - acc: 0.6957 - f1_m: 0.6839 - precision_m: 0.6955 - recall_m: 0.6735 - val_loss: 0.6052 - val_acc: 0.7031 - val_f1_m: 0.3080 - val_precision_m: 0.1988 - val_recall_m: 0.6919\n",
            "Epoch 497/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5930 - acc: 0.6963 - f1_m: 0.6924 - precision_m: 0.7075 - recall_m: 0.6788 - val_loss: 0.6034 - val_acc: 0.7048 - val_f1_m: 0.3085 - val_precision_m: 0.1995 - val_recall_m: 0.6899\n",
            "Epoch 498/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5930 - acc: 0.6961 - f1_m: 0.6919 - precision_m: 0.7035 - recall_m: 0.6814 - val_loss: 0.6050 - val_acc: 0.7029 - val_f1_m: 0.3078 - val_precision_m: 0.1987 - val_recall_m: 0.6919\n",
            "Epoch 499/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5929 - acc: 0.6951 - f1_m: 0.6867 - precision_m: 0.6962 - recall_m: 0.6777 - val_loss: 0.6071 - val_acc: 0.6997 - val_f1_m: 0.3070 - val_precision_m: 0.1976 - val_recall_m: 0.6963\n",
            "Epoch 500/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5928 - acc: 0.6947 - f1_m: 0.6896 - precision_m: 0.6953 - recall_m: 0.6840 - val_loss: 0.6079 - val_acc: 0.6985 - val_f1_m: 0.3061 - val_precision_m: 0.1969 - val_recall_m: 0.6963\n",
            "Epoch 501/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5927 - acc: 0.6947 - f1_m: 0.6966 - precision_m: 0.7071 - recall_m: 0.6871 - val_loss: 0.6070 - val_acc: 0.6993 - val_f1_m: 0.3067 - val_precision_m: 0.1974 - val_recall_m: 0.6963\n",
            "Epoch 502/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5927 - acc: 0.6949 - f1_m: 0.6945 - precision_m: 0.7081 - recall_m: 0.6826 - val_loss: 0.6087 - val_acc: 0.6970 - val_f1_m: 0.3051 - val_precision_m: 0.1960 - val_recall_m: 0.6963\n",
            "Epoch 503/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5926 - acc: 0.6935 - f1_m: 0.6926 - precision_m: 0.6911 - recall_m: 0.6962 - val_loss: 0.6088 - val_acc: 0.6968 - val_f1_m: 0.3049 - val_precision_m: 0.1959 - val_recall_m: 0.6963\n",
            "Epoch 504/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5925 - acc: 0.6957 - f1_m: 0.6899 - precision_m: 0.6992 - recall_m: 0.6813 - val_loss: 0.6048 - val_acc: 0.7014 - val_f1_m: 0.3074 - val_precision_m: 0.1982 - val_recall_m: 0.6939\n",
            "Epoch 505/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5924 - acc: 0.6975 - f1_m: 0.6898 - precision_m: 0.6992 - recall_m: 0.6810 - val_loss: 0.6038 - val_acc: 0.7027 - val_f1_m: 0.3077 - val_precision_m: 0.1985 - val_recall_m: 0.6919\n",
            "Epoch 506/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5923 - acc: 0.6977 - f1_m: 0.7013 - precision_m: 0.7134 - recall_m: 0.6902 - val_loss: 0.6047 - val_acc: 0.7012 - val_f1_m: 0.3073 - val_precision_m: 0.1980 - val_recall_m: 0.6939\n",
            "Epoch 507/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5923 - acc: 0.6973 - f1_m: 0.6848 - precision_m: 0.6943 - recall_m: 0.6756 - val_loss: 0.6042 - val_acc: 0.7014 - val_f1_m: 0.3074 - val_precision_m: 0.1981 - val_recall_m: 0.6939\n",
            "Epoch 508/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5922 - acc: 0.6973 - f1_m: 0.6901 - precision_m: 0.7018 - recall_m: 0.6792 - val_loss: 0.6036 - val_acc: 0.7018 - val_f1_m: 0.3071 - val_precision_m: 0.1980 - val_recall_m: 0.6919\n",
            "Epoch 509/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5921 - acc: 0.6971 - f1_m: 0.6889 - precision_m: 0.7040 - recall_m: 0.6761 - val_loss: 0.6052 - val_acc: 0.7006 - val_f1_m: 0.3068 - val_precision_m: 0.1976 - val_recall_m: 0.6939\n",
            "Epoch 510/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5920 - acc: 0.6965 - f1_m: 0.6819 - precision_m: 0.6883 - recall_m: 0.6764 - val_loss: 0.6049 - val_acc: 0.7008 - val_f1_m: 0.3069 - val_precision_m: 0.1977 - val_recall_m: 0.6939\n",
            "Epoch 511/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5920 - acc: 0.6969 - f1_m: 0.6987 - precision_m: 0.7139 - recall_m: 0.6852 - val_loss: 0.6035 - val_acc: 0.7010 - val_f1_m: 0.3064 - val_precision_m: 0.1975 - val_recall_m: 0.6919\n",
            "Epoch 512/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5919 - acc: 0.6975 - f1_m: 0.6939 - precision_m: 0.7002 - recall_m: 0.6881 - val_loss: 0.6028 - val_acc: 0.7020 - val_f1_m: 0.3072 - val_precision_m: 0.1981 - val_recall_m: 0.6919\n",
            "Epoch 513/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5918 - acc: 0.6973 - f1_m: 0.6977 - precision_m: 0.7075 - recall_m: 0.6891 - val_loss: 0.6037 - val_acc: 0.7010 - val_f1_m: 0.3071 - val_precision_m: 0.1978 - val_recall_m: 0.6939\n",
            "Epoch 514/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5917 - acc: 0.6969 - f1_m: 0.6901 - precision_m: 0.6960 - recall_m: 0.6849 - val_loss: 0.6030 - val_acc: 0.7014 - val_f1_m: 0.3067 - val_precision_m: 0.1977 - val_recall_m: 0.6919\n",
            "Epoch 515/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5917 - acc: 0.6979 - f1_m: 0.6825 - precision_m: 0.6878 - recall_m: 0.6786 - val_loss: 0.5994 - val_acc: 0.7069 - val_f1_m: 0.3109 - val_precision_m: 0.2013 - val_recall_m: 0.6919\n",
            "Epoch 516/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5917 - acc: 0.6985 - f1_m: 0.6898 - precision_m: 0.7088 - recall_m: 0.6728 - val_loss: 0.5959 - val_acc: 0.7104 - val_f1_m: 0.3121 - val_precision_m: 0.2026 - val_recall_m: 0.6879\n",
            "Epoch 517/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5916 - acc: 0.6985 - f1_m: 0.6917 - precision_m: 0.7083 - recall_m: 0.6762 - val_loss: 0.5982 - val_acc: 0.7075 - val_f1_m: 0.3101 - val_precision_m: 0.2009 - val_recall_m: 0.6879\n",
            "Epoch 518/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5915 - acc: 0.6981 - f1_m: 0.6898 - precision_m: 0.7028 - recall_m: 0.6781 - val_loss: 0.6020 - val_acc: 0.7031 - val_f1_m: 0.3080 - val_precision_m: 0.1987 - val_recall_m: 0.6919\n",
            "Epoch 519/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5914 - acc: 0.6969 - f1_m: 0.6806 - precision_m: 0.6869 - recall_m: 0.6752 - val_loss: 0.6033 - val_acc: 0.7018 - val_f1_m: 0.3076 - val_precision_m: 0.1983 - val_recall_m: 0.6939\n",
            "Epoch 520/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5913 - acc: 0.6967 - f1_m: 0.6857 - precision_m: 0.6939 - recall_m: 0.6778 - val_loss: 0.6013 - val_acc: 0.7041 - val_f1_m: 0.3081 - val_precision_m: 0.1991 - val_recall_m: 0.6900\n",
            "Epoch 521/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5913 - acc: 0.6985 - f1_m: 0.7007 - precision_m: 0.7097 - recall_m: 0.6925 - val_loss: 0.5988 - val_acc: 0.7062 - val_f1_m: 0.3097 - val_precision_m: 0.2005 - val_recall_m: 0.6900\n",
            "Epoch 522/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5912 - acc: 0.6983 - f1_m: 0.6925 - precision_m: 0.7025 - recall_m: 0.6831 - val_loss: 0.5986 - val_acc: 0.7064 - val_f1_m: 0.3099 - val_precision_m: 0.2006 - val_recall_m: 0.6900\n",
            "Epoch 523/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5911 - acc: 0.6977 - f1_m: 0.6936 - precision_m: 0.7089 - recall_m: 0.6795 - val_loss: 0.5994 - val_acc: 0.7060 - val_f1_m: 0.3096 - val_precision_m: 0.2003 - val_recall_m: 0.6900\n",
            "Epoch 524/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5910 - acc: 0.6979 - f1_m: 0.6885 - precision_m: 0.7023 - recall_m: 0.6760 - val_loss: 0.6015 - val_acc: 0.7037 - val_f1_m: 0.3078 - val_precision_m: 0.1988 - val_recall_m: 0.6900\n",
            "Epoch 525/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5910 - acc: 0.6971 - f1_m: 0.6985 - precision_m: 0.7043 - recall_m: 0.6931 - val_loss: 0.6049 - val_acc: 0.6993 - val_f1_m: 0.3065 - val_precision_m: 0.1972 - val_recall_m: 0.6959\n",
            "Epoch 526/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5909 - acc: 0.6961 - f1_m: 0.6962 - precision_m: 0.6989 - recall_m: 0.6943 - val_loss: 0.6050 - val_acc: 0.6997 - val_f1_m: 0.3069 - val_precision_m: 0.1975 - val_recall_m: 0.6959\n",
            "Epoch 527/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5908 - acc: 0.6961 - f1_m: 0.6968 - precision_m: 0.7043 - recall_m: 0.6900 - val_loss: 0.6043 - val_acc: 0.7002 - val_f1_m: 0.3058 - val_precision_m: 0.1970 - val_recall_m: 0.6920\n",
            "Epoch 528/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5908 - acc: 0.6973 - f1_m: 0.6971 - precision_m: 0.7063 - recall_m: 0.6887 - val_loss: 0.6023 - val_acc: 0.7023 - val_f1_m: 0.3068 - val_precision_m: 0.1980 - val_recall_m: 0.6900\n",
            "Epoch 529/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5907 - acc: 0.6975 - f1_m: 0.6893 - precision_m: 0.6930 - recall_m: 0.6869 - val_loss: 0.6023 - val_acc: 0.7023 - val_f1_m: 0.3068 - val_precision_m: 0.1980 - val_recall_m: 0.6900\n",
            "Epoch 530/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5906 - acc: 0.6977 - f1_m: 0.6962 - precision_m: 0.7038 - recall_m: 0.6899 - val_loss: 0.6004 - val_acc: 0.7039 - val_f1_m: 0.3080 - val_precision_m: 0.1990 - val_recall_m: 0.6900\n",
            "Epoch 531/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5906 - acc: 0.6975 - f1_m: 0.6958 - precision_m: 0.7083 - recall_m: 0.6840 - val_loss: 0.5996 - val_acc: 0.7054 - val_f1_m: 0.3090 - val_precision_m: 0.1998 - val_recall_m: 0.6900\n",
            "Epoch 532/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5905 - acc: 0.6977 - f1_m: 0.6956 - precision_m: 0.7049 - recall_m: 0.6867 - val_loss: 0.5999 - val_acc: 0.7050 - val_f1_m: 0.3087 - val_precision_m: 0.1996 - val_recall_m: 0.6900\n",
            "Epoch 533/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5905 - acc: 0.6975 - f1_m: 0.6975 - precision_m: 0.7011 - recall_m: 0.6955 - val_loss: 0.5995 - val_acc: 0.7054 - val_f1_m: 0.3090 - val_precision_m: 0.1998 - val_recall_m: 0.6900\n",
            "Epoch 534/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5904 - acc: 0.6977 - f1_m: 0.6810 - precision_m: 0.6872 - recall_m: 0.6761 - val_loss: 0.5973 - val_acc: 0.7075 - val_f1_m: 0.3106 - val_precision_m: 0.2011 - val_recall_m: 0.6900\n",
            "Epoch 535/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5904 - acc: 0.6973 - f1_m: 0.6979 - precision_m: 0.7054 - recall_m: 0.6914 - val_loss: 0.5942 - val_acc: 0.7102 - val_f1_m: 0.3127 - val_precision_m: 0.2029 - val_recall_m: 0.6900\n",
            "Epoch 536/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5903 - acc: 0.6973 - f1_m: 0.6905 - precision_m: 0.7045 - recall_m: 0.6774 - val_loss: 0.5931 - val_acc: 0.7110 - val_f1_m: 0.3133 - val_precision_m: 0.2035 - val_recall_m: 0.6900\n",
            "Epoch 537/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.5903 - acc: 0.6973 - f1_m: 0.6825 - precision_m: 0.6947 - recall_m: 0.6713 - val_loss: 0.5938 - val_acc: 0.7102 - val_f1_m: 0.3127 - val_precision_m: 0.2029 - val_recall_m: 0.6900\n",
            "Epoch 538/1000\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.5902 - acc: 0.6977 - f1_m: 0.6880 - precision_m: 0.7071 - recall_m: 0.6710 - val_loss: 0.5961 - val_acc: 0.7079 - val_f1_m: 0.3109 - val_precision_m: 0.2014 - val_recall_m: 0.6900\n",
            "Epoch 539/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5901 - acc: 0.6975 - f1_m: 0.6950 - precision_m: 0.7055 - recall_m: 0.6851 - val_loss: 0.5996 - val_acc: 0.7048 - val_f1_m: 0.3086 - val_precision_m: 0.1995 - val_recall_m: 0.6900\n",
            "Epoch 540/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5900 - acc: 0.6977 - f1_m: 0.6911 - precision_m: 0.7042 - recall_m: 0.6795 - val_loss: 0.6036 - val_acc: 0.7004 - val_f1_m: 0.3073 - val_precision_m: 0.1979 - val_recall_m: 0.6960\n",
            "Epoch 541/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5900 - acc: 0.6973 - f1_m: 0.6880 - precision_m: 0.6896 - recall_m: 0.6873 - val_loss: 0.6052 - val_acc: 0.6983 - val_f1_m: 0.3057 - val_precision_m: 0.1966 - val_recall_m: 0.6960\n",
            "Epoch 542/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5899 - acc: 0.6971 - f1_m: 0.6965 - precision_m: 0.7044 - recall_m: 0.6891 - val_loss: 0.6036 - val_acc: 0.7000 - val_f1_m: 0.3070 - val_precision_m: 0.1977 - val_recall_m: 0.6960\n",
            "Epoch 543/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5898 - acc: 0.6971 - f1_m: 0.6918 - precision_m: 0.6981 - recall_m: 0.6858 - val_loss: 0.6009 - val_acc: 0.7027 - val_f1_m: 0.3071 - val_precision_m: 0.1983 - val_recall_m: 0.6900\n",
            "Epoch 544/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5898 - acc: 0.6983 - f1_m: 0.6890 - precision_m: 0.6990 - recall_m: 0.6798 - val_loss: 0.5990 - val_acc: 0.7041 - val_f1_m: 0.3082 - val_precision_m: 0.1992 - val_recall_m: 0.6900\n",
            "Epoch 545/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5898 - acc: 0.6981 - f1_m: 0.6916 - precision_m: 0.7003 - recall_m: 0.6837 - val_loss: 0.5967 - val_acc: 0.7071 - val_f1_m: 0.3103 - val_precision_m: 0.2009 - val_recall_m: 0.6900\n",
            "Epoch 546/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5897 - acc: 0.6983 - f1_m: 0.6965 - precision_m: 0.7114 - recall_m: 0.6827 - val_loss: 0.5966 - val_acc: 0.7071 - val_f1_m: 0.3103 - val_precision_m: 0.2009 - val_recall_m: 0.6900\n",
            "Epoch 547/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5896 - acc: 0.6985 - f1_m: 0.6883 - precision_m: 0.7002 - recall_m: 0.6770 - val_loss: 0.5969 - val_acc: 0.7062 - val_f1_m: 0.3097 - val_precision_m: 0.2005 - val_recall_m: 0.6900\n",
            "Epoch 548/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5896 - acc: 0.6989 - f1_m: 0.6926 - precision_m: 0.7066 - recall_m: 0.6795 - val_loss: 0.5995 - val_acc: 0.7039 - val_f1_m: 0.3086 - val_precision_m: 0.1993 - val_recall_m: 0.6920\n",
            "Epoch 549/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5895 - acc: 0.6973 - f1_m: 0.6900 - precision_m: 0.6995 - recall_m: 0.6808 - val_loss: 0.6019 - val_acc: 0.7016 - val_f1_m: 0.3082 - val_precision_m: 0.1986 - val_recall_m: 0.6960\n",
            "Epoch 550/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5895 - acc: 0.6983 - f1_m: 0.6907 - precision_m: 0.6943 - recall_m: 0.6877 - val_loss: 0.6032 - val_acc: 0.7006 - val_f1_m: 0.3075 - val_precision_m: 0.1981 - val_recall_m: 0.6960\n",
            "Epoch 551/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5894 - acc: 0.6975 - f1_m: 0.6965 - precision_m: 0.6978 - recall_m: 0.6961 - val_loss: 0.6010 - val_acc: 0.7023 - val_f1_m: 0.3080 - val_precision_m: 0.1987 - val_recall_m: 0.6940\n",
            "Epoch 552/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5893 - acc: 0.6981 - f1_m: 0.6961 - precision_m: 0.7059 - recall_m: 0.6867 - val_loss: 0.5992 - val_acc: 0.7041 - val_f1_m: 0.3094 - val_precision_m: 0.1999 - val_recall_m: 0.6940\n",
            "Epoch 553/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5893 - acc: 0.6985 - f1_m: 0.6957 - precision_m: 0.7035 - recall_m: 0.6886 - val_loss: 0.5986 - val_acc: 0.7043 - val_f1_m: 0.3096 - val_precision_m: 0.2000 - val_recall_m: 0.6940\n",
            "Epoch 554/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5892 - acc: 0.6989 - f1_m: 0.6924 - precision_m: 0.7028 - recall_m: 0.6829 - val_loss: 0.5975 - val_acc: 0.7048 - val_f1_m: 0.3086 - val_precision_m: 0.1995 - val_recall_m: 0.6900\n",
            "Epoch 555/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5892 - acc: 0.6985 - f1_m: 0.6837 - precision_m: 0.6843 - recall_m: 0.6879 - val_loss: 0.5979 - val_acc: 0.7052 - val_f1_m: 0.3095 - val_precision_m: 0.2001 - val_recall_m: 0.6920\n",
            "Epoch 556/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5891 - acc: 0.6985 - f1_m: 0.6945 - precision_m: 0.7059 - recall_m: 0.6835 - val_loss: 0.5940 - val_acc: 0.7083 - val_f1_m: 0.3107 - val_precision_m: 0.2014 - val_recall_m: 0.6879\n",
            "Epoch 557/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5891 - acc: 0.6985 - f1_m: 0.6901 - precision_m: 0.7112 - recall_m: 0.6719 - val_loss: 0.5939 - val_acc: 0.7083 - val_f1_m: 0.3100 - val_precision_m: 0.2011 - val_recall_m: 0.6854\n",
            "Epoch 558/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5890 - acc: 0.6991 - f1_m: 0.6971 - precision_m: 0.7055 - recall_m: 0.6900 - val_loss: 0.5974 - val_acc: 0.7050 - val_f1_m: 0.3100 - val_precision_m: 0.2004 - val_recall_m: 0.6940\n",
            "Epoch 559/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5889 - acc: 0.6987 - f1_m: 0.6952 - precision_m: 0.7081 - recall_m: 0.6838 - val_loss: 0.5987 - val_acc: 0.7037 - val_f1_m: 0.3092 - val_precision_m: 0.1997 - val_recall_m: 0.6940\n",
            "Epoch 560/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5889 - acc: 0.6989 - f1_m: 0.6971 - precision_m: 0.7003 - recall_m: 0.6953 - val_loss: 0.6008 - val_acc: 0.7014 - val_f1_m: 0.3074 - val_precision_m: 0.1982 - val_recall_m: 0.6940\n",
            "Epoch 561/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5888 - acc: 0.6993 - f1_m: 0.7004 - precision_m: 0.7067 - recall_m: 0.6944 - val_loss: 0.6014 - val_acc: 0.7016 - val_f1_m: 0.3081 - val_precision_m: 0.1986 - val_recall_m: 0.6960\n",
            "Epoch 562/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5888 - acc: 0.6995 - f1_m: 0.6956 - precision_m: 0.7029 - recall_m: 0.6888 - val_loss: 0.6014 - val_acc: 0.7016 - val_f1_m: 0.3081 - val_precision_m: 0.1986 - val_recall_m: 0.6960\n",
            "Epoch 563/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5887 - acc: 0.6995 - f1_m: 0.6938 - precision_m: 0.6968 - recall_m: 0.6918 - val_loss: 0.6013 - val_acc: 0.7016 - val_f1_m: 0.3081 - val_precision_m: 0.1986 - val_recall_m: 0.6960\n",
            "Epoch 564/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5887 - acc: 0.6993 - f1_m: 0.6862 - precision_m: 0.6978 - recall_m: 0.6761 - val_loss: 0.5996 - val_acc: 0.7031 - val_f1_m: 0.3087 - val_precision_m: 0.1992 - val_recall_m: 0.6940\n",
            "Epoch 565/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5886 - acc: 0.6995 - f1_m: 0.6938 - precision_m: 0.7059 - recall_m: 0.6830 - val_loss: 0.6011 - val_acc: 0.7020 - val_f1_m: 0.3085 - val_precision_m: 0.1989 - val_recall_m: 0.6960\n",
            "Epoch 566/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5886 - acc: 0.6993 - f1_m: 0.6977 - precision_m: 0.7038 - recall_m: 0.6921 - val_loss: 0.6001 - val_acc: 0.7027 - val_f1_m: 0.3083 - val_precision_m: 0.1989 - val_recall_m: 0.6940\n",
            "Epoch 567/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5885 - acc: 0.6995 - f1_m: 0.6908 - precision_m: 0.6964 - recall_m: 0.6855 - val_loss: 0.6006 - val_acc: 0.7029 - val_f1_m: 0.3091 - val_precision_m: 0.1994 - val_recall_m: 0.6960\n",
            "Epoch 568/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5885 - acc: 0.6995 - f1_m: 0.6959 - precision_m: 0.7066 - recall_m: 0.6862 - val_loss: 0.5989 - val_acc: 0.7033 - val_f1_m: 0.3082 - val_precision_m: 0.1990 - val_recall_m: 0.6920\n",
            "Epoch 569/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5884 - acc: 0.6995 - f1_m: 0.6962 - precision_m: 0.7044 - recall_m: 0.6884 - val_loss: 0.6000 - val_acc: 0.7027 - val_f1_m: 0.3077 - val_precision_m: 0.1986 - val_recall_m: 0.6920\n",
            "Epoch 570/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5884 - acc: 0.6991 - f1_m: 0.6910 - precision_m: 0.6982 - recall_m: 0.6844 - val_loss: 0.6011 - val_acc: 0.7025 - val_f1_m: 0.3095 - val_precision_m: 0.1995 - val_recall_m: 0.6986\n",
            "Epoch 571/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5883 - acc: 0.6995 - f1_m: 0.6948 - precision_m: 0.7063 - recall_m: 0.6844 - val_loss: 0.5994 - val_acc: 0.7031 - val_f1_m: 0.3080 - val_precision_m: 0.1989 - val_recall_m: 0.6920\n",
            "Epoch 572/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5883 - acc: 0.6991 - f1_m: 0.6962 - precision_m: 0.7066 - recall_m: 0.6873 - val_loss: 0.6008 - val_acc: 0.7027 - val_f1_m: 0.3090 - val_precision_m: 0.1993 - val_recall_m: 0.6965\n",
            "Epoch 573/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5882 - acc: 0.6995 - f1_m: 0.6896 - precision_m: 0.6964 - recall_m: 0.6832 - val_loss: 0.6011 - val_acc: 0.7027 - val_f1_m: 0.3090 - val_precision_m: 0.1993 - val_recall_m: 0.6965\n",
            "Epoch 574/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5882 - acc: 0.6991 - f1_m: 0.6981 - precision_m: 0.7029 - recall_m: 0.6937 - val_loss: 0.6020 - val_acc: 0.7025 - val_f1_m: 0.3095 - val_precision_m: 0.1995 - val_recall_m: 0.6986\n",
            "Epoch 575/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5881 - acc: 0.6997 - f1_m: 0.6981 - precision_m: 0.7040 - recall_m: 0.6923 - val_loss: 0.6009 - val_acc: 0.7031 - val_f1_m: 0.3094 - val_precision_m: 0.1996 - val_recall_m: 0.6965\n",
            "Epoch 576/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5880 - acc: 0.6995 - f1_m: 0.7015 - precision_m: 0.7120 - recall_m: 0.6925 - val_loss: 0.6012 - val_acc: 0.7029 - val_f1_m: 0.3092 - val_precision_m: 0.1995 - val_recall_m: 0.6965\n",
            "Epoch 577/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5880 - acc: 0.6993 - f1_m: 0.6917 - precision_m: 0.6953 - recall_m: 0.6882 - val_loss: 0.6019 - val_acc: 0.7023 - val_f1_m: 0.3087 - val_precision_m: 0.1990 - val_recall_m: 0.6965\n",
            "Epoch 578/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5880 - acc: 0.6989 - f1_m: 0.6955 - precision_m: 0.7048 - recall_m: 0.6868 - val_loss: 0.5997 - val_acc: 0.7031 - val_f1_m: 0.3080 - val_precision_m: 0.1988 - val_recall_m: 0.6920\n",
            "Epoch 579/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5879 - acc: 0.6993 - f1_m: 0.6951 - precision_m: 0.6986 - recall_m: 0.6926 - val_loss: 0.5992 - val_acc: 0.7031 - val_f1_m: 0.3080 - val_precision_m: 0.1988 - val_recall_m: 0.6920\n",
            "Epoch 580/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5878 - acc: 0.6999 - f1_m: 0.6984 - precision_m: 0.7076 - recall_m: 0.6900 - val_loss: 0.5974 - val_acc: 0.7041 - val_f1_m: 0.3080 - val_precision_m: 0.1991 - val_recall_m: 0.6894\n",
            "Epoch 581/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5878 - acc: 0.7005 - f1_m: 0.6930 - precision_m: 0.7028 - recall_m: 0.6839 - val_loss: 0.5951 - val_acc: 0.7054 - val_f1_m: 0.3083 - val_precision_m: 0.1995 - val_recall_m: 0.6874\n",
            "Epoch 582/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5878 - acc: 0.7005 - f1_m: 0.6952 - precision_m: 0.7021 - recall_m: 0.6892 - val_loss: 0.5956 - val_acc: 0.7052 - val_f1_m: 0.3081 - val_precision_m: 0.1993 - val_recall_m: 0.6874\n",
            "Epoch 583/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5877 - acc: 0.7003 - f1_m: 0.6997 - precision_m: 0.7062 - recall_m: 0.6947 - val_loss: 0.5957 - val_acc: 0.7048 - val_f1_m: 0.3078 - val_precision_m: 0.1991 - val_recall_m: 0.6874\n",
            "Epoch 584/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5877 - acc: 0.7007 - f1_m: 0.6986 - precision_m: 0.7075 - recall_m: 0.6916 - val_loss: 0.5949 - val_acc: 0.7058 - val_f1_m: 0.3086 - val_precision_m: 0.1997 - val_recall_m: 0.6874\n",
            "Epoch 585/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5876 - acc: 0.7007 - f1_m: 0.6993 - precision_m: 0.7061 - recall_m: 0.6937 - val_loss: 0.5956 - val_acc: 0.7050 - val_f1_m: 0.3080 - val_precision_m: 0.1992 - val_recall_m: 0.6874\n",
            "Epoch 586/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5876 - acc: 0.7009 - f1_m: 0.6993 - precision_m: 0.7062 - recall_m: 0.6933 - val_loss: 0.5944 - val_acc: 0.7060 - val_f1_m: 0.3087 - val_precision_m: 0.1998 - val_recall_m: 0.6874\n",
            "Epoch 587/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5875 - acc: 0.6999 - f1_m: 0.6963 - precision_m: 0.7071 - recall_m: 0.6860 - val_loss: 0.5945 - val_acc: 0.7058 - val_f1_m: 0.3086 - val_precision_m: 0.1997 - val_recall_m: 0.6874\n",
            "Epoch 588/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.5875 - acc: 0.7003 - f1_m: 0.6933 - precision_m: 0.7094 - recall_m: 0.6786 - val_loss: 0.5950 - val_acc: 0.7052 - val_f1_m: 0.3081 - val_precision_m: 0.1993 - val_recall_m: 0.6874\n",
            "Epoch 589/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5874 - acc: 0.7009 - f1_m: 0.6925 - precision_m: 0.6995 - recall_m: 0.6863 - val_loss: 0.5971 - val_acc: 0.7046 - val_f1_m: 0.3084 - val_precision_m: 0.1993 - val_recall_m: 0.6900\n",
            "Epoch 590/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5873 - acc: 0.7011 - f1_m: 0.6936 - precision_m: 0.7086 - recall_m: 0.6805 - val_loss: 0.5966 - val_acc: 0.7050 - val_f1_m: 0.3086 - val_precision_m: 0.1996 - val_recall_m: 0.6900\n",
            "Epoch 591/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5873 - acc: 0.7013 - f1_m: 0.6965 - precision_m: 0.7038 - recall_m: 0.6896 - val_loss: 0.5974 - val_acc: 0.7048 - val_f1_m: 0.3085 - val_precision_m: 0.1994 - val_recall_m: 0.6900\n",
            "Epoch 592/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.5873 - acc: 0.6999 - f1_m: 0.6900 - precision_m: 0.6995 - recall_m: 0.6812 - val_loss: 0.5995 - val_acc: 0.7037 - val_f1_m: 0.3090 - val_precision_m: 0.1995 - val_recall_m: 0.6940\n",
            "Epoch 593/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5872 - acc: 0.7007 - f1_m: 0.6988 - precision_m: 0.7085 - recall_m: 0.6901 - val_loss: 0.5996 - val_acc: 0.7039 - val_f1_m: 0.3099 - val_precision_m: 0.2001 - val_recall_m: 0.6959\n",
            "Epoch 594/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5872 - acc: 0.7007 - f1_m: 0.6993 - precision_m: 0.7028 - recall_m: 0.6962 - val_loss: 0.6013 - val_acc: 0.7031 - val_f1_m: 0.3092 - val_precision_m: 0.1995 - val_recall_m: 0.6959\n",
            "Epoch 595/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5871 - acc: 0.7007 - f1_m: 0.6980 - precision_m: 0.7058 - recall_m: 0.6909 - val_loss: 0.6008 - val_acc: 0.7035 - val_f1_m: 0.3095 - val_precision_m: 0.1998 - val_recall_m: 0.6959\n",
            "Epoch 596/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5871 - acc: 0.7007 - f1_m: 0.6957 - precision_m: 0.7060 - recall_m: 0.6867 - val_loss: 0.5990 - val_acc: 0.7043 - val_f1_m: 0.3094 - val_precision_m: 0.1999 - val_recall_m: 0.6940\n",
            "Epoch 597/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5870 - acc: 0.7011 - f1_m: 0.7012 - precision_m: 0.7078 - recall_m: 0.6951 - val_loss: 0.5974 - val_acc: 0.7048 - val_f1_m: 0.3085 - val_precision_m: 0.1994 - val_recall_m: 0.6900\n",
            "Epoch 598/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5870 - acc: 0.7009 - f1_m: 0.7014 - precision_m: 0.7146 - recall_m: 0.6895 - val_loss: 0.5970 - val_acc: 0.7050 - val_f1_m: 0.3086 - val_precision_m: 0.1996 - val_recall_m: 0.6900\n",
            "Epoch 599/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5869 - acc: 0.7013 - f1_m: 0.6925 - precision_m: 0.7062 - recall_m: 0.6807 - val_loss: 0.5984 - val_acc: 0.7050 - val_f1_m: 0.3099 - val_precision_m: 0.2003 - val_recall_m: 0.6940\n",
            "Epoch 600/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5869 - acc: 0.7011 - f1_m: 0.6918 - precision_m: 0.7021 - recall_m: 0.6824 - val_loss: 0.6003 - val_acc: 0.7039 - val_f1_m: 0.3091 - val_precision_m: 0.1996 - val_recall_m: 0.6940\n",
            "Epoch 601/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5868 - acc: 0.7011 - f1_m: 0.7009 - precision_m: 0.7105 - recall_m: 0.6927 - val_loss: 0.6021 - val_acc: 0.7027 - val_f1_m: 0.3097 - val_precision_m: 0.1997 - val_recall_m: 0.6985\n",
            "Epoch 602/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5868 - acc: 0.7003 - f1_m: 0.7034 - precision_m: 0.7058 - recall_m: 0.7017 - val_loss: 0.6021 - val_acc: 0.7025 - val_f1_m: 0.3095 - val_precision_m: 0.1995 - val_recall_m: 0.6985\n",
            "Epoch 603/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5867 - acc: 0.7001 - f1_m: 0.6977 - precision_m: 0.7052 - recall_m: 0.6907 - val_loss: 0.5997 - val_acc: 0.7041 - val_f1_m: 0.3093 - val_precision_m: 0.1997 - val_recall_m: 0.6940\n",
            "Epoch 604/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5867 - acc: 0.7009 - f1_m: 0.6966 - precision_m: 0.7066 - recall_m: 0.6872 - val_loss: 0.5982 - val_acc: 0.7056 - val_f1_m: 0.3104 - val_precision_m: 0.2007 - val_recall_m: 0.6940\n",
            "Epoch 605/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5866 - acc: 0.7013 - f1_m: 0.6953 - precision_m: 0.7028 - recall_m: 0.6882 - val_loss: 0.5978 - val_acc: 0.7056 - val_f1_m: 0.3104 - val_precision_m: 0.2007 - val_recall_m: 0.6940\n",
            "Epoch 606/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5866 - acc: 0.7007 - f1_m: 0.6909 - precision_m: 0.6937 - recall_m: 0.6901 - val_loss: 0.5971 - val_acc: 0.7064 - val_f1_m: 0.3104 - val_precision_m: 0.2008 - val_recall_m: 0.6920\n",
            "Epoch 607/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5865 - acc: 0.7007 - f1_m: 0.6974 - precision_m: 0.7067 - recall_m: 0.6888 - val_loss: 0.5929 - val_acc: 0.7081 - val_f1_m: 0.3097 - val_precision_m: 0.2008 - val_recall_m: 0.6859\n",
            "Epoch 608/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5865 - acc: 0.7001 - f1_m: 0.6909 - precision_m: 0.7024 - recall_m: 0.6799 - val_loss: 0.5916 - val_acc: 0.7083 - val_f1_m: 0.3091 - val_precision_m: 0.2005 - val_recall_m: 0.6834\n",
            "Epoch 609/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5865 - acc: 0.7003 - f1_m: 0.6885 - precision_m: 0.6960 - recall_m: 0.6819 - val_loss: 0.5932 - val_acc: 0.7083 - val_f1_m: 0.3098 - val_precision_m: 0.2009 - val_recall_m: 0.6859\n",
            "Epoch 610/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5864 - acc: 0.7007 - f1_m: 0.7012 - precision_m: 0.7039 - recall_m: 0.7011 - val_loss: 0.5924 - val_acc: 0.7083 - val_f1_m: 0.3098 - val_precision_m: 0.2009 - val_recall_m: 0.6859\n",
            "Epoch 611/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5864 - acc: 0.7007 - f1_m: 0.7013 - precision_m: 0.7127 - recall_m: 0.6908 - val_loss: 0.5920 - val_acc: 0.7087 - val_f1_m: 0.3101 - val_precision_m: 0.2011 - val_recall_m: 0.6859\n",
            "Epoch 612/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5863 - acc: 0.7007 - f1_m: 0.6983 - precision_m: 0.7081 - recall_m: 0.6891 - val_loss: 0.5927 - val_acc: 0.7083 - val_f1_m: 0.3098 - val_precision_m: 0.2009 - val_recall_m: 0.6859\n",
            "Epoch 613/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5863 - acc: 0.7005 - f1_m: 0.6949 - precision_m: 0.6984 - recall_m: 0.6932 - val_loss: 0.5943 - val_acc: 0.7075 - val_f1_m: 0.3105 - val_precision_m: 0.2011 - val_recall_m: 0.6899\n",
            "Epoch 614/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5862 - acc: 0.7005 - f1_m: 0.6948 - precision_m: 0.7072 - recall_m: 0.6830 - val_loss: 0.5936 - val_acc: 0.7081 - val_f1_m: 0.3103 - val_precision_m: 0.2012 - val_recall_m: 0.6879\n",
            "Epoch 615/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5862 - acc: 0.7011 - f1_m: 0.7012 - precision_m: 0.7084 - recall_m: 0.6944 - val_loss: 0.5956 - val_acc: 0.7071 - val_f1_m: 0.3108 - val_precision_m: 0.2012 - val_recall_m: 0.6920\n",
            "Epoch 616/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5862 - acc: 0.7007 - f1_m: 0.6973 - precision_m: 0.7072 - recall_m: 0.6880 - val_loss: 0.5973 - val_acc: 0.7064 - val_f1_m: 0.3110 - val_precision_m: 0.2012 - val_recall_m: 0.6940\n",
            "Epoch 617/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5861 - acc: 0.7005 - f1_m: 0.7020 - precision_m: 0.7082 - recall_m: 0.6965 - val_loss: 0.5986 - val_acc: 0.7060 - val_f1_m: 0.3107 - val_precision_m: 0.2009 - val_recall_m: 0.6940\n",
            "Epoch 618/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5861 - acc: 0.7005 - f1_m: 0.7020 - precision_m: 0.7105 - recall_m: 0.6938 - val_loss: 0.5986 - val_acc: 0.7062 - val_f1_m: 0.3108 - val_precision_m: 0.2010 - val_recall_m: 0.6940\n",
            "Epoch 619/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5860 - acc: 0.7009 - f1_m: 0.6963 - precision_m: 0.7050 - recall_m: 0.6879 - val_loss: 0.5970 - val_acc: 0.7064 - val_f1_m: 0.3104 - val_precision_m: 0.2008 - val_recall_m: 0.6920\n",
            "Epoch 620/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5860 - acc: 0.7007 - f1_m: 0.6986 - precision_m: 0.7066 - recall_m: 0.6911 - val_loss: 0.5973 - val_acc: 0.7066 - val_f1_m: 0.3111 - val_precision_m: 0.2013 - val_recall_m: 0.6940\n",
            "Epoch 621/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5859 - acc: 0.7009 - f1_m: 0.6976 - precision_m: 0.7058 - recall_m: 0.6897 - val_loss: 0.5970 - val_acc: 0.7069 - val_f1_m: 0.3113 - val_precision_m: 0.2014 - val_recall_m: 0.6940\n",
            "Epoch 622/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5859 - acc: 0.7009 - f1_m: 0.7024 - precision_m: 0.7168 - recall_m: 0.6895 - val_loss: 0.5963 - val_acc: 0.7069 - val_f1_m: 0.3107 - val_precision_m: 0.2010 - val_recall_m: 0.6920\n",
            "Epoch 623/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5858 - acc: 0.7005 - f1_m: 0.6999 - precision_m: 0.7085 - recall_m: 0.6920 - val_loss: 0.5970 - val_acc: 0.7071 - val_f1_m: 0.3114 - val_precision_m: 0.2015 - val_recall_m: 0.6940\n",
            "Epoch 624/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5858 - acc: 0.7013 - f1_m: 0.7034 - precision_m: 0.7099 - recall_m: 0.6975 - val_loss: 0.5991 - val_acc: 0.7060 - val_f1_m: 0.3113 - val_precision_m: 0.2011 - val_recall_m: 0.6965\n",
            "Epoch 625/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5858 - acc: 0.7013 - f1_m: 0.6934 - precision_m: 0.7039 - recall_m: 0.6839 - val_loss: 0.5991 - val_acc: 0.7060 - val_f1_m: 0.3113 - val_precision_m: 0.2011 - val_recall_m: 0.6965\n",
            "Epoch 626/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5857 - acc: 0.7017 - f1_m: 0.7042 - precision_m: 0.7067 - recall_m: 0.7026 - val_loss: 0.6014 - val_acc: 0.7037 - val_f1_m: 0.3096 - val_precision_m: 0.1998 - val_recall_m: 0.6965\n",
            "Epoch 627/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5857 - acc: 0.7015 - f1_m: 0.6991 - precision_m: 0.7055 - recall_m: 0.6932 - val_loss: 0.6018 - val_acc: 0.7037 - val_f1_m: 0.3096 - val_precision_m: 0.1998 - val_recall_m: 0.6965\n",
            "Epoch 628/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5857 - acc: 0.7015 - f1_m: 0.6953 - precision_m: 0.6954 - recall_m: 0.6957 - val_loss: 0.6033 - val_acc: 0.7025 - val_f1_m: 0.3088 - val_precision_m: 0.1991 - val_recall_m: 0.6965\n",
            "Epoch 629/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5856 - acc: 0.7017 - f1_m: 0.6969 - precision_m: 0.7004 - recall_m: 0.6941 - val_loss: 0.6001 - val_acc: 0.7052 - val_f1_m: 0.3106 - val_precision_m: 0.2006 - val_recall_m: 0.6965\n",
            "Epoch 630/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5856 - acc: 0.7019 - f1_m: 0.6966 - precision_m: 0.7053 - recall_m: 0.6887 - val_loss: 0.5953 - val_acc: 0.7077 - val_f1_m: 0.3106 - val_precision_m: 0.2012 - val_recall_m: 0.6899\n",
            "Epoch 631/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5855 - acc: 0.7011 - f1_m: 0.6967 - precision_m: 0.7064 - recall_m: 0.6876 - val_loss: 0.5944 - val_acc: 0.7077 - val_f1_m: 0.3100 - val_precision_m: 0.2008 - val_recall_m: 0.6879\n",
            "Epoch 632/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5855 - acc: 0.7013 - f1_m: 0.6981 - precision_m: 0.7128 - recall_m: 0.6846 - val_loss: 0.5938 - val_acc: 0.7081 - val_f1_m: 0.3103 - val_precision_m: 0.2011 - val_recall_m: 0.6879\n",
            "Epoch 633/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5854 - acc: 0.7009 - f1_m: 0.6895 - precision_m: 0.6985 - recall_m: 0.6810 - val_loss: 0.5976 - val_acc: 0.7064 - val_f1_m: 0.3115 - val_precision_m: 0.2014 - val_recall_m: 0.6965\n",
            "Epoch 634/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5854 - acc: 0.7017 - f1_m: 0.6946 - precision_m: 0.7012 - recall_m: 0.6892 - val_loss: 0.5970 - val_acc: 0.7062 - val_f1_m: 0.3107 - val_precision_m: 0.2009 - val_recall_m: 0.6945\n",
            "Epoch 635/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5854 - acc: 0.7019 - f1_m: 0.7021 - precision_m: 0.7129 - recall_m: 0.6924 - val_loss: 0.5968 - val_acc: 0.7064 - val_f1_m: 0.3109 - val_precision_m: 0.2010 - val_recall_m: 0.6945\n",
            "Epoch 636/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5853 - acc: 0.7017 - f1_m: 0.7003 - precision_m: 0.7069 - recall_m: 0.6945 - val_loss: 0.5977 - val_acc: 0.7064 - val_f1_m: 0.3115 - val_precision_m: 0.2014 - val_recall_m: 0.6965\n",
            "Epoch 637/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5853 - acc: 0.7019 - f1_m: 0.6967 - precision_m: 0.7040 - recall_m: 0.6901 - val_loss: 0.5985 - val_acc: 0.7062 - val_f1_m: 0.3114 - val_precision_m: 0.2013 - val_recall_m: 0.6965\n",
            "Epoch 638/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5852 - acc: 0.7019 - f1_m: 0.6949 - precision_m: 0.7064 - recall_m: 0.6845 - val_loss: 0.5965 - val_acc: 0.7066 - val_f1_m: 0.3111 - val_precision_m: 0.2011 - val_recall_m: 0.6945\n",
            "Epoch 639/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5852 - acc: 0.7015 - f1_m: 0.6940 - precision_m: 0.7032 - recall_m: 0.6854 - val_loss: 0.5967 - val_acc: 0.7064 - val_f1_m: 0.3109 - val_precision_m: 0.2010 - val_recall_m: 0.6945\n",
            "Epoch 640/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5852 - acc: 0.7015 - f1_m: 0.6997 - precision_m: 0.7071 - recall_m: 0.6927 - val_loss: 0.5969 - val_acc: 0.7064 - val_f1_m: 0.3109 - val_precision_m: 0.2010 - val_recall_m: 0.6945\n",
            "Epoch 641/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5851 - acc: 0.7021 - f1_m: 0.6865 - precision_m: 0.6946 - recall_m: 0.6787 - val_loss: 0.5957 - val_acc: 0.7075 - val_f1_m: 0.3117 - val_precision_m: 0.2017 - val_recall_m: 0.6945\n",
            "Epoch 642/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5851 - acc: 0.7017 - f1_m: 0.6962 - precision_m: 0.7070 - recall_m: 0.6861 - val_loss: 0.5931 - val_acc: 0.7094 - val_f1_m: 0.3111 - val_precision_m: 0.2017 - val_recall_m: 0.6879\n",
            "Epoch 643/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5851 - acc: 0.7021 - f1_m: 0.6983 - precision_m: 0.7110 - recall_m: 0.6873 - val_loss: 0.5956 - val_acc: 0.7073 - val_f1_m: 0.3115 - val_precision_m: 0.2015 - val_recall_m: 0.6945\n",
            "Epoch 644/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5850 - acc: 0.7023 - f1_m: 0.6931 - precision_m: 0.6935 - recall_m: 0.6952 - val_loss: 0.5979 - val_acc: 0.7062 - val_f1_m: 0.3114 - val_precision_m: 0.2012 - val_recall_m: 0.6965\n",
            "Epoch 645/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5850 - acc: 0.7023 - f1_m: 0.6979 - precision_m: 0.7005 - recall_m: 0.6966 - val_loss: 0.5952 - val_acc: 0.7083 - val_f1_m: 0.3123 - val_precision_m: 0.2022 - val_recall_m: 0.6945\n",
            "Epoch 646/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5850 - acc: 0.7017 - f1_m: 0.6978 - precision_m: 0.7164 - recall_m: 0.6820 - val_loss: 0.5913 - val_acc: 0.7110 - val_f1_m: 0.3124 - val_precision_m: 0.2028 - val_recall_m: 0.6879\n",
            "Epoch 647/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5849 - acc: 0.7017 - f1_m: 0.7030 - precision_m: 0.7140 - recall_m: 0.6933 - val_loss: 0.5927 - val_acc: 0.7100 - val_f1_m: 0.3115 - val_precision_m: 0.2021 - val_recall_m: 0.6879\n",
            "Epoch 648/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5849 - acc: 0.7021 - f1_m: 0.6901 - precision_m: 0.7015 - recall_m: 0.6796 - val_loss: 0.5942 - val_acc: 0.7089 - val_f1_m: 0.3114 - val_precision_m: 0.2018 - val_recall_m: 0.6899\n",
            "Epoch 649/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5848 - acc: 0.7023 - f1_m: 0.6837 - precision_m: 0.6916 - recall_m: 0.6762 - val_loss: 0.5935 - val_acc: 0.7096 - val_f1_m: 0.3119 - val_precision_m: 0.2022 - val_recall_m: 0.6899\n",
            "Epoch 650/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5848 - acc: 0.7019 - f1_m: 0.6995 - precision_m: 0.7131 - recall_m: 0.6868 - val_loss: 0.5916 - val_acc: 0.7108 - val_f1_m: 0.3122 - val_precision_m: 0.2027 - val_recall_m: 0.6879\n",
            "Epoch 651/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5847 - acc: 0.7017 - f1_m: 0.6977 - precision_m: 0.7078 - recall_m: 0.6880 - val_loss: 0.5932 - val_acc: 0.7094 - val_f1_m: 0.3117 - val_precision_m: 0.2020 - val_recall_m: 0.6899\n",
            "Epoch 652/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5847 - acc: 0.7025 - f1_m: 0.6853 - precision_m: 0.6949 - recall_m: 0.6761 - val_loss: 0.5963 - val_acc: 0.7071 - val_f1_m: 0.3113 - val_precision_m: 0.2014 - val_recall_m: 0.6945\n",
            "Epoch 653/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5847 - acc: 0.7027 - f1_m: 0.6965 - precision_m: 0.7012 - recall_m: 0.6923 - val_loss: 0.5967 - val_acc: 0.7071 - val_f1_m: 0.3113 - val_precision_m: 0.2014 - val_recall_m: 0.6945\n",
            "Epoch 654/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5846 - acc: 0.7027 - f1_m: 0.7000 - precision_m: 0.7064 - recall_m: 0.6940 - val_loss: 0.5955 - val_acc: 0.7077 - val_f1_m: 0.3118 - val_precision_m: 0.2017 - val_recall_m: 0.6945\n",
            "Epoch 655/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5846 - acc: 0.7027 - f1_m: 0.6972 - precision_m: 0.7038 - recall_m: 0.6917 - val_loss: 0.5942 - val_acc: 0.7085 - val_f1_m: 0.3117 - val_precision_m: 0.2019 - val_recall_m: 0.6925\n",
            "Epoch 656/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5845 - acc: 0.7019 - f1_m: 0.6882 - precision_m: 0.6964 - recall_m: 0.6809 - val_loss: 0.5912 - val_acc: 0.7106 - val_f1_m: 0.3120 - val_precision_m: 0.2025 - val_recall_m: 0.6879\n",
            "Epoch 657/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5845 - acc: 0.7019 - f1_m: 0.6949 - precision_m: 0.7071 - recall_m: 0.6836 - val_loss: 0.5890 - val_acc: 0.7125 - val_f1_m: 0.3126 - val_precision_m: 0.2032 - val_recall_m: 0.6855\n",
            "Epoch 658/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5846 - acc: 0.7021 - f1_m: 0.6921 - precision_m: 0.6977 - recall_m: 0.6884 - val_loss: 0.5910 - val_acc: 0.7110 - val_f1_m: 0.3123 - val_precision_m: 0.2028 - val_recall_m: 0.6879\n",
            "Epoch 659/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5845 - acc: 0.7021 - f1_m: 0.6971 - precision_m: 0.7061 - recall_m: 0.6889 - val_loss: 0.5880 - val_acc: 0.7131 - val_f1_m: 0.3125 - val_precision_m: 0.2033 - val_recall_m: 0.6835\n",
            "Epoch 660/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5845 - acc: 0.7023 - f1_m: 0.6975 - precision_m: 0.7043 - recall_m: 0.6934 - val_loss: 0.5878 - val_acc: 0.7131 - val_f1_m: 0.3125 - val_precision_m: 0.2033 - val_recall_m: 0.6835\n",
            "Epoch 661/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5844 - acc: 0.7019 - f1_m: 0.6963 - precision_m: 0.7102 - recall_m: 0.6836 - val_loss: 0.5886 - val_acc: 0.7125 - val_f1_m: 0.3120 - val_precision_m: 0.2029 - val_recall_m: 0.6835\n",
            "Epoch 662/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5844 - acc: 0.7023 - f1_m: 0.6971 - precision_m: 0.7096 - recall_m: 0.6856 - val_loss: 0.5914 - val_acc: 0.7104 - val_f1_m: 0.3111 - val_precision_m: 0.2019 - val_recall_m: 0.6855\n",
            "Epoch 663/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5844 - acc: 0.7023 - f1_m: 0.6937 - precision_m: 0.6965 - recall_m: 0.6929 - val_loss: 0.5948 - val_acc: 0.7083 - val_f1_m: 0.3122 - val_precision_m: 0.2021 - val_recall_m: 0.6945\n",
            "Epoch 664/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5843 - acc: 0.7027 - f1_m: 0.6942 - precision_m: 0.6995 - recall_m: 0.6898 - val_loss: 0.5918 - val_acc: 0.7104 - val_f1_m: 0.3110 - val_precision_m: 0.2019 - val_recall_m: 0.6855\n",
            "Epoch 665/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5843 - acc: 0.7031 - f1_m: 0.6980 - precision_m: 0.7129 - recall_m: 0.6843 - val_loss: 0.5890 - val_acc: 0.7115 - val_f1_m: 0.3097 - val_precision_m: 0.2014 - val_recall_m: 0.6784\n",
            "Epoch 666/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5842 - acc: 0.7027 - f1_m: 0.7013 - precision_m: 0.7094 - recall_m: 0.6944 - val_loss: 0.5901 - val_acc: 0.7112 - val_f1_m: 0.3110 - val_precision_m: 0.2020 - val_recall_m: 0.6835\n",
            "Epoch 667/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5842 - acc: 0.7029 - f1_m: 0.6995 - precision_m: 0.7073 - recall_m: 0.6924 - val_loss: 0.5915 - val_acc: 0.7108 - val_f1_m: 0.3113 - val_precision_m: 0.2021 - val_recall_m: 0.6855\n",
            "Epoch 668/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5841 - acc: 0.7031 - f1_m: 0.6944 - precision_m: 0.7078 - recall_m: 0.6822 - val_loss: 0.5928 - val_acc: 0.7102 - val_f1_m: 0.3115 - val_precision_m: 0.2021 - val_recall_m: 0.6881\n",
            "Epoch 669/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5841 - acc: 0.7029 - f1_m: 0.6990 - precision_m: 0.7053 - recall_m: 0.6932 - val_loss: 0.5951 - val_acc: 0.7079 - val_f1_m: 0.3106 - val_precision_m: 0.2011 - val_recall_m: 0.6905\n",
            "Epoch 670/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5841 - acc: 0.7027 - f1_m: 0.7021 - precision_m: 0.7083 - recall_m: 0.6965 - val_loss: 0.5952 - val_acc: 0.7083 - val_f1_m: 0.3116 - val_precision_m: 0.2017 - val_recall_m: 0.6925\n",
            "Epoch 671/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5840 - acc: 0.7025 - f1_m: 0.6949 - precision_m: 0.7000 - recall_m: 0.6903 - val_loss: 0.5946 - val_acc: 0.7087 - val_f1_m: 0.3112 - val_precision_m: 0.2016 - val_recall_m: 0.6905\n",
            "Epoch 672/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5840 - acc: 0.7029 - f1_m: 0.6958 - precision_m: 0.7000 - recall_m: 0.6923 - val_loss: 0.5912 - val_acc: 0.7108 - val_f1_m: 0.3106 - val_precision_m: 0.2017 - val_recall_m: 0.6829\n",
            "Epoch 673/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5840 - acc: 0.7029 - f1_m: 0.6951 - precision_m: 0.7049 - recall_m: 0.6859 - val_loss: 0.5891 - val_acc: 0.7112 - val_f1_m: 0.3096 - val_precision_m: 0.2012 - val_recall_m: 0.6784\n",
            "Epoch 674/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5840 - acc: 0.7029 - f1_m: 0.6968 - precision_m: 0.7058 - recall_m: 0.6884 - val_loss: 0.5879 - val_acc: 0.7123 - val_f1_m: 0.3104 - val_precision_m: 0.2019 - val_recall_m: 0.6784\n",
            "Epoch 675/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5839 - acc: 0.7031 - f1_m: 0.6843 - precision_m: 0.7034 - recall_m: 0.6677 - val_loss: 0.5882 - val_acc: 0.7121 - val_f1_m: 0.3103 - val_precision_m: 0.2018 - val_recall_m: 0.6784\n",
            "Epoch 676/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5839 - acc: 0.7031 - f1_m: 0.6928 - precision_m: 0.7039 - recall_m: 0.6827 - val_loss: 0.5904 - val_acc: 0.7108 - val_f1_m: 0.3099 - val_precision_m: 0.2013 - val_recall_m: 0.6804\n",
            "Epoch 677/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5838 - acc: 0.7037 - f1_m: 0.7048 - precision_m: 0.7162 - recall_m: 0.6942 - val_loss: 0.5918 - val_acc: 0.7100 - val_f1_m: 0.3099 - val_precision_m: 0.2011 - val_recall_m: 0.6829\n",
            "Epoch 678/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5838 - acc: 0.7039 - f1_m: 0.7003 - precision_m: 0.7105 - recall_m: 0.6905 - val_loss: 0.5937 - val_acc: 0.7098 - val_f1_m: 0.3119 - val_precision_m: 0.2022 - val_recall_m: 0.6905\n",
            "Epoch 679/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5837 - acc: 0.7031 - f1_m: 0.6945 - precision_m: 0.7075 - recall_m: 0.6830 - val_loss: 0.5958 - val_acc: 0.7087 - val_f1_m: 0.3118 - val_precision_m: 0.2019 - val_recall_m: 0.6925\n",
            "Epoch 680/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5838 - acc: 0.7031 - f1_m: 0.7003 - precision_m: 0.7071 - recall_m: 0.6945 - val_loss: 0.5991 - val_acc: 0.7052 - val_f1_m: 0.3093 - val_precision_m: 0.1998 - val_recall_m: 0.6925\n",
            "Epoch 681/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5837 - acc: 0.7035 - f1_m: 0.7021 - precision_m: 0.7072 - recall_m: 0.6975 - val_loss: 0.5986 - val_acc: 0.7056 - val_f1_m: 0.3096 - val_precision_m: 0.2000 - val_recall_m: 0.6925\n",
            "Epoch 682/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5837 - acc: 0.7035 - f1_m: 0.7045 - precision_m: 0.7078 - recall_m: 0.7016 - val_loss: 0.5974 - val_acc: 0.7079 - val_f1_m: 0.3112 - val_precision_m: 0.2014 - val_recall_m: 0.6925\n",
            "Epoch 683/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5836 - acc: 0.7039 - f1_m: 0.6999 - precision_m: 0.7082 - recall_m: 0.6924 - val_loss: 0.5961 - val_acc: 0.7089 - val_f1_m: 0.3120 - val_precision_m: 0.2020 - val_recall_m: 0.6925\n",
            "Epoch 684/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5836 - acc: 0.7029 - f1_m: 0.7048 - precision_m: 0.7176 - recall_m: 0.6936 - val_loss: 0.5959 - val_acc: 0.7089 - val_f1_m: 0.3113 - val_precision_m: 0.2016 - val_recall_m: 0.6899\n",
            "Epoch 685/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5836 - acc: 0.7033 - f1_m: 0.7042 - precision_m: 0.7125 - recall_m: 0.6968 - val_loss: 0.5965 - val_acc: 0.7089 - val_f1_m: 0.3113 - val_precision_m: 0.2016 - val_recall_m: 0.6899\n",
            "Epoch 686/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5835 - acc: 0.7035 - f1_m: 0.7046 - precision_m: 0.7100 - recall_m: 0.6996 - val_loss: 0.5965 - val_acc: 0.7085 - val_f1_m: 0.3109 - val_precision_m: 0.2013 - val_recall_m: 0.6899\n",
            "Epoch 687/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5835 - acc: 0.7035 - f1_m: 0.7005 - precision_m: 0.7079 - recall_m: 0.6938 - val_loss: 0.5942 - val_acc: 0.7094 - val_f1_m: 0.3101 - val_precision_m: 0.2011 - val_recall_m: 0.6855\n",
            "Epoch 688/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5834 - acc: 0.7041 - f1_m: 0.7076 - precision_m: 0.7198 - recall_m: 0.6965 - val_loss: 0.5941 - val_acc: 0.7094 - val_f1_m: 0.3101 - val_precision_m: 0.2011 - val_recall_m: 0.6855\n",
            "Epoch 689/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5834 - acc: 0.7037 - f1_m: 0.7022 - precision_m: 0.7082 - recall_m: 0.6968 - val_loss: 0.5958 - val_acc: 0.7085 - val_f1_m: 0.3109 - val_precision_m: 0.2013 - val_recall_m: 0.6899\n",
            "Epoch 690/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5834 - acc: 0.7029 - f1_m: 0.7070 - precision_m: 0.7143 - recall_m: 0.7000 - val_loss: 0.5958 - val_acc: 0.7085 - val_f1_m: 0.3109 - val_precision_m: 0.2013 - val_recall_m: 0.6899\n",
            "Epoch 691/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5833 - acc: 0.7033 - f1_m: 0.7101 - precision_m: 0.7180 - recall_m: 0.7025 - val_loss: 0.5956 - val_acc: 0.7085 - val_f1_m: 0.3109 - val_precision_m: 0.2013 - val_recall_m: 0.6899\n",
            "Epoch 692/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5833 - acc: 0.7035 - f1_m: 0.7043 - precision_m: 0.7090 - recall_m: 0.7002 - val_loss: 0.5966 - val_acc: 0.7079 - val_f1_m: 0.3105 - val_precision_m: 0.2010 - val_recall_m: 0.6899\n",
            "Epoch 693/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5833 - acc: 0.7037 - f1_m: 0.6959 - precision_m: 0.7045 - recall_m: 0.6882 - val_loss: 0.5957 - val_acc: 0.7079 - val_f1_m: 0.3097 - val_precision_m: 0.2005 - val_recall_m: 0.6875\n",
            "Epoch 694/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5832 - acc: 0.7039 - f1_m: 0.6960 - precision_m: 0.7072 - recall_m: 0.6858 - val_loss: 0.5933 - val_acc: 0.7092 - val_f1_m: 0.3093 - val_precision_m: 0.2006 - val_recall_m: 0.6829\n",
            "Epoch 695/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5832 - acc: 0.7039 - f1_m: 0.7006 - precision_m: 0.7081 - recall_m: 0.6934 - val_loss: 0.5922 - val_acc: 0.7098 - val_f1_m: 0.3098 - val_precision_m: 0.2010 - val_recall_m: 0.6829\n",
            "Epoch 696/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.5832 - acc: 0.7031 - f1_m: 0.7027 - precision_m: 0.7124 - recall_m: 0.6938 - val_loss: 0.5900 - val_acc: 0.7110 - val_f1_m: 0.3101 - val_precision_m: 0.2014 - val_recall_m: 0.6810\n",
            "Epoch 697/1000\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.5831 - acc: 0.7037 - f1_m: 0.6970 - precision_m: 0.7081 - recall_m: 0.6868 - val_loss: 0.5901 - val_acc: 0.7108 - val_f1_m: 0.3099 - val_precision_m: 0.2013 - val_recall_m: 0.6810\n",
            "Epoch 698/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.5831 - acc: 0.7031 - f1_m: 0.6926 - precision_m: 0.7007 - recall_m: 0.6850 - val_loss: 0.5906 - val_acc: 0.7106 - val_f1_m: 0.3097 - val_precision_m: 0.2011 - val_recall_m: 0.6810\n",
            "Epoch 699/1000\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.5831 - acc: 0.7037 - f1_m: 0.7023 - precision_m: 0.7151 - recall_m: 0.6904 - val_loss: 0.5883 - val_acc: 0.7119 - val_f1_m: 0.3099 - val_precision_m: 0.2015 - val_recall_m: 0.6784\n",
            "Epoch 700/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5831 - acc: 0.7035 - f1_m: 0.6998 - precision_m: 0.7167 - recall_m: 0.6844 - val_loss: 0.5890 - val_acc: 0.7112 - val_f1_m: 0.3102 - val_precision_m: 0.2015 - val_recall_m: 0.6810\n",
            "Epoch 701/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5830 - acc: 0.7041 - f1_m: 0.6982 - precision_m: 0.7084 - recall_m: 0.6888 - val_loss: 0.5933 - val_acc: 0.7087 - val_f1_m: 0.3089 - val_precision_m: 0.2002 - val_recall_m: 0.6829\n",
            "Epoch 702/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5830 - acc: 0.7039 - f1_m: 0.6944 - precision_m: 0.7048 - recall_m: 0.6845 - val_loss: 0.5938 - val_acc: 0.7083 - val_f1_m: 0.3086 - val_precision_m: 0.2000 - val_recall_m: 0.6829\n",
            "Epoch 703/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5829 - acc: 0.7041 - f1_m: 0.6964 - precision_m: 0.7014 - recall_m: 0.6922 - val_loss: 0.5943 - val_acc: 0.7079 - val_f1_m: 0.3083 - val_precision_m: 0.1997 - val_recall_m: 0.6829\n",
            "Epoch 704/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5829 - acc: 0.7041 - f1_m: 0.7032 - precision_m: 0.7098 - recall_m: 0.6970 - val_loss: 0.5928 - val_acc: 0.7089 - val_f1_m: 0.3084 - val_precision_m: 0.2000 - val_recall_m: 0.6810\n",
            "Epoch 705/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5829 - acc: 0.7039 - f1_m: 0.7019 - precision_m: 0.7153 - recall_m: 0.6900 - val_loss: 0.5908 - val_acc: 0.7104 - val_f1_m: 0.3095 - val_precision_m: 0.2010 - val_recall_m: 0.6810\n",
            "Epoch 706/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5828 - acc: 0.7039 - f1_m: 0.7005 - precision_m: 0.7100 - recall_m: 0.6914 - val_loss: 0.5938 - val_acc: 0.7081 - val_f1_m: 0.3078 - val_precision_m: 0.1995 - val_recall_m: 0.6810\n",
            "Epoch 707/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5828 - acc: 0.7041 - f1_m: 0.7004 - precision_m: 0.7039 - recall_m: 0.6978 - val_loss: 0.5967 - val_acc: 0.7073 - val_f1_m: 0.3085 - val_precision_m: 0.1997 - val_recall_m: 0.6850\n",
            "Epoch 708/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.5828 - acc: 0.7045 - f1_m: 0.7070 - precision_m: 0.7113 - recall_m: 0.7032 - val_loss: 0.5955 - val_acc: 0.7075 - val_f1_m: 0.3080 - val_precision_m: 0.1995 - val_recall_m: 0.6829\n",
            "Epoch 709/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.5827 - acc: 0.7041 - f1_m: 0.6974 - precision_m: 0.7140 - recall_m: 0.6839 - val_loss: 0.5940 - val_acc: 0.7081 - val_f1_m: 0.3078 - val_precision_m: 0.1995 - val_recall_m: 0.6810\n",
            "Epoch 710/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.5827 - acc: 0.7045 - f1_m: 0.7003 - precision_m: 0.7048 - recall_m: 0.6966 - val_loss: 0.5946 - val_acc: 0.7077 - val_f1_m: 0.3075 - val_precision_m: 0.1992 - val_recall_m: 0.6810\n",
            "Epoch 711/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.5827 - acc: 0.7047 - f1_m: 0.6988 - precision_m: 0.7075 - recall_m: 0.6909 - val_loss: 0.5933 - val_acc: 0.7085 - val_f1_m: 0.3081 - val_precision_m: 0.1997 - val_recall_m: 0.6810\n",
            "Epoch 712/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5827 - acc: 0.7041 - f1_m: 0.7027 - precision_m: 0.7127 - recall_m: 0.6931 - val_loss: 0.5919 - val_acc: 0.7089 - val_f1_m: 0.3084 - val_precision_m: 0.2000 - val_recall_m: 0.6810\n",
            "Epoch 713/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5826 - acc: 0.7043 - f1_m: 0.7054 - precision_m: 0.7135 - recall_m: 0.6978 - val_loss: 0.5911 - val_acc: 0.7098 - val_f1_m: 0.3090 - val_precision_m: 0.2005 - val_recall_m: 0.6810\n",
            "Epoch 714/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5826 - acc: 0.7047 - f1_m: 0.6938 - precision_m: 0.7079 - recall_m: 0.6815 - val_loss: 0.5927 - val_acc: 0.7085 - val_f1_m: 0.3081 - val_precision_m: 0.1997 - val_recall_m: 0.6810\n",
            "Epoch 715/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5826 - acc: 0.7045 - f1_m: 0.7009 - precision_m: 0.7130 - recall_m: 0.6897 - val_loss: 0.5943 - val_acc: 0.7079 - val_f1_m: 0.3077 - val_precision_m: 0.1994 - val_recall_m: 0.6810\n",
            "Epoch 716/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5825 - acc: 0.7049 - f1_m: 0.6982 - precision_m: 0.7034 - recall_m: 0.6934 - val_loss: 0.5979 - val_acc: 0.7054 - val_f1_m: 0.3078 - val_precision_m: 0.1989 - val_recall_m: 0.6873\n",
            "Epoch 717/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5825 - acc: 0.7049 - f1_m: 0.7000 - precision_m: 0.7046 - recall_m: 0.6957 - val_loss: 0.5975 - val_acc: 0.7054 - val_f1_m: 0.3071 - val_precision_m: 0.1985 - val_recall_m: 0.6853\n",
            "Epoch 718/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5825 - acc: 0.7055 - f1_m: 0.7036 - precision_m: 0.7057 - recall_m: 0.7025 - val_loss: 0.5948 - val_acc: 0.7075 - val_f1_m: 0.3080 - val_precision_m: 0.1995 - val_recall_m: 0.6833\n",
            "Epoch 719/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5824 - acc: 0.7049 - f1_m: 0.7042 - precision_m: 0.7097 - recall_m: 0.6990 - val_loss: 0.5930 - val_acc: 0.7085 - val_f1_m: 0.3088 - val_precision_m: 0.2001 - val_recall_m: 0.6833\n",
            "Epoch 720/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5824 - acc: 0.7049 - f1_m: 0.7009 - precision_m: 0.7129 - recall_m: 0.6898 - val_loss: 0.5914 - val_acc: 0.7104 - val_f1_m: 0.3095 - val_precision_m: 0.2009 - val_recall_m: 0.6810\n",
            "Epoch 721/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5824 - acc: 0.7047 - f1_m: 0.7008 - precision_m: 0.7141 - recall_m: 0.6889 - val_loss: 0.5910 - val_acc: 0.7106 - val_f1_m: 0.3096 - val_precision_m: 0.2010 - val_recall_m: 0.6810\n",
            "Epoch 722/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5823 - acc: 0.7049 - f1_m: 0.7040 - precision_m: 0.7147 - recall_m: 0.6937 - val_loss: 0.5928 - val_acc: 0.7087 - val_f1_m: 0.3089 - val_precision_m: 0.2002 - val_recall_m: 0.6833\n",
            "Epoch 723/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5823 - acc: 0.7049 - f1_m: 0.7030 - precision_m: 0.7155 - recall_m: 0.6918 - val_loss: 0.5934 - val_acc: 0.7087 - val_f1_m: 0.3089 - val_precision_m: 0.2002 - val_recall_m: 0.6833\n",
            "Epoch 724/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5823 - acc: 0.7051 - f1_m: 0.7040 - precision_m: 0.7102 - recall_m: 0.6981 - val_loss: 0.5951 - val_acc: 0.7069 - val_f1_m: 0.3075 - val_precision_m: 0.1990 - val_recall_m: 0.6833\n",
            "Epoch 725/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5823 - acc: 0.7049 - f1_m: 0.6990 - precision_m: 0.7094 - recall_m: 0.6896 - val_loss: 0.5945 - val_acc: 0.7073 - val_f1_m: 0.3079 - val_precision_m: 0.1993 - val_recall_m: 0.6833\n",
            "Epoch 726/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5822 - acc: 0.7051 - f1_m: 0.7007 - precision_m: 0.7124 - recall_m: 0.6902 - val_loss: 0.5939 - val_acc: 0.7083 - val_f1_m: 0.3086 - val_precision_m: 0.2000 - val_recall_m: 0.6833\n",
            "Epoch 727/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5822 - acc: 0.7051 - f1_m: 0.6996 - precision_m: 0.7077 - recall_m: 0.6919 - val_loss: 0.5957 - val_acc: 0.7066 - val_f1_m: 0.3074 - val_precision_m: 0.1989 - val_recall_m: 0.6833\n",
            "Epoch 728/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5822 - acc: 0.7055 - f1_m: 0.7036 - precision_m: 0.7141 - recall_m: 0.6946 - val_loss: 0.5949 - val_acc: 0.7071 - val_f1_m: 0.3077 - val_precision_m: 0.1992 - val_recall_m: 0.6833\n",
            "Epoch 729/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5821 - acc: 0.7047 - f1_m: 0.7084 - precision_m: 0.7178 - recall_m: 0.7002 - val_loss: 0.5945 - val_acc: 0.7075 - val_f1_m: 0.3080 - val_precision_m: 0.1994 - val_recall_m: 0.6833\n",
            "Epoch 730/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5821 - acc: 0.7049 - f1_m: 0.7068 - precision_m: 0.7162 - recall_m: 0.6982 - val_loss: 0.5968 - val_acc: 0.7054 - val_f1_m: 0.3071 - val_precision_m: 0.1985 - val_recall_m: 0.6853\n",
            "Epoch 731/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5821 - acc: 0.7055 - f1_m: 0.7070 - precision_m: 0.7143 - recall_m: 0.7001 - val_loss: 0.5981 - val_acc: 0.7050 - val_f1_m: 0.3075 - val_precision_m: 0.1987 - val_recall_m: 0.6873\n",
            "Epoch 732/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5821 - acc: 0.7059 - f1_m: 0.7057 - precision_m: 0.7078 - recall_m: 0.7046 - val_loss: 0.5995 - val_acc: 0.7033 - val_f1_m: 0.3071 - val_precision_m: 0.1982 - val_recall_m: 0.6897\n",
            "Epoch 733/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5821 - acc: 0.7061 - f1_m: 0.6947 - precision_m: 0.7017 - recall_m: 0.6883 - val_loss: 0.5984 - val_acc: 0.7048 - val_f1_m: 0.3081 - val_precision_m: 0.1990 - val_recall_m: 0.6897\n",
            "Epoch 734/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5820 - acc: 0.7061 - f1_m: 0.7056 - precision_m: 0.7099 - recall_m: 0.7015 - val_loss: 0.5984 - val_acc: 0.7048 - val_f1_m: 0.3081 - val_precision_m: 0.1990 - val_recall_m: 0.6897\n",
            "Epoch 735/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5820 - acc: 0.7059 - f1_m: 0.7088 - precision_m: 0.7120 - recall_m: 0.7062 - val_loss: 0.5958 - val_acc: 0.7062 - val_f1_m: 0.3071 - val_precision_m: 0.1987 - val_recall_m: 0.6833\n",
            "Epoch 736/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5819 - acc: 0.7049 - f1_m: 0.7012 - precision_m: 0.7120 - recall_m: 0.6913 - val_loss: 0.5926 - val_acc: 0.7089 - val_f1_m: 0.3084 - val_precision_m: 0.1999 - val_recall_m: 0.6813\n",
            "Epoch 737/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5819 - acc: 0.7045 - f1_m: 0.7027 - precision_m: 0.7102 - recall_m: 0.6956 - val_loss: 0.5916 - val_acc: 0.7104 - val_f1_m: 0.3094 - val_precision_m: 0.2008 - val_recall_m: 0.6813\n",
            "Epoch 738/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5819 - acc: 0.7047 - f1_m: 0.7007 - precision_m: 0.7214 - recall_m: 0.6845 - val_loss: 0.5918 - val_acc: 0.7102 - val_f1_m: 0.3093 - val_precision_m: 0.2007 - val_recall_m: 0.6813\n",
            "Epoch 739/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5818 - acc: 0.7047 - f1_m: 0.7032 - precision_m: 0.7157 - recall_m: 0.6919 - val_loss: 0.5965 - val_acc: 0.7060 - val_f1_m: 0.3069 - val_precision_m: 0.1985 - val_recall_m: 0.6833\n",
            "Epoch 740/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5818 - acc: 0.7067 - f1_m: 0.7036 - precision_m: 0.7046 - recall_m: 0.7029 - val_loss: 0.6003 - val_acc: 0.7029 - val_f1_m: 0.3082 - val_precision_m: 0.1987 - val_recall_m: 0.6941\n",
            "Epoch 741/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5818 - acc: 0.7057 - f1_m: 0.7084 - precision_m: 0.7129 - recall_m: 0.7042 - val_loss: 0.5977 - val_acc: 0.7050 - val_f1_m: 0.3083 - val_precision_m: 0.1992 - val_recall_m: 0.6897\n",
            "Epoch 742/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5818 - acc: 0.7057 - f1_m: 0.7057 - precision_m: 0.7102 - recall_m: 0.7017 - val_loss: 0.5965 - val_acc: 0.7060 - val_f1_m: 0.3084 - val_precision_m: 0.1993 - val_recall_m: 0.6877\n",
            "Epoch 743/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5817 - acc: 0.7059 - f1_m: 0.7053 - precision_m: 0.7120 - recall_m: 0.6989 - val_loss: 0.5944 - val_acc: 0.7069 - val_f1_m: 0.3068 - val_precision_m: 0.1986 - val_recall_m: 0.6813\n",
            "Epoch 744/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5817 - acc: 0.7057 - f1_m: 0.7104 - precision_m: 0.7157 - recall_m: 0.7053 - val_loss: 0.5929 - val_acc: 0.7092 - val_f1_m: 0.3085 - val_precision_m: 0.2000 - val_recall_m: 0.6813\n",
            "Epoch 745/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5817 - acc: 0.7051 - f1_m: 0.7045 - precision_m: 0.7102 - recall_m: 0.6992 - val_loss: 0.5915 - val_acc: 0.7106 - val_f1_m: 0.3096 - val_precision_m: 0.2010 - val_recall_m: 0.6813\n",
            "Epoch 746/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5816 - acc: 0.7045 - f1_m: 0.6980 - precision_m: 0.7051 - recall_m: 0.6914 - val_loss: 0.5905 - val_acc: 0.7115 - val_f1_m: 0.3102 - val_precision_m: 0.2015 - val_recall_m: 0.6813\n",
            "Epoch 747/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5816 - acc: 0.7047 - f1_m: 0.7019 - precision_m: 0.7065 - recall_m: 0.6980 - val_loss: 0.5909 - val_acc: 0.7110 - val_f1_m: 0.3099 - val_precision_m: 0.2012 - val_recall_m: 0.6813\n",
            "Epoch 748/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5816 - acc: 0.7047 - f1_m: 0.7043 - precision_m: 0.7162 - recall_m: 0.6937 - val_loss: 0.5913 - val_acc: 0.7106 - val_f1_m: 0.3096 - val_precision_m: 0.2010 - val_recall_m: 0.6813\n",
            "Epoch 749/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5815 - acc: 0.7053 - f1_m: 0.6989 - precision_m: 0.7011 - recall_m: 0.6986 - val_loss: 0.5933 - val_acc: 0.7077 - val_f1_m: 0.3075 - val_precision_m: 0.1991 - val_recall_m: 0.6813\n",
            "Epoch 750/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5815 - acc: 0.7053 - f1_m: 0.7059 - precision_m: 0.7120 - recall_m: 0.7001 - val_loss: 0.5919 - val_acc: 0.7102 - val_f1_m: 0.3093 - val_precision_m: 0.2007 - val_recall_m: 0.6813\n",
            "Epoch 751/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5815 - acc: 0.7051 - f1_m: 0.7047 - precision_m: 0.7134 - recall_m: 0.6965 - val_loss: 0.5909 - val_acc: 0.7110 - val_f1_m: 0.3099 - val_precision_m: 0.2012 - val_recall_m: 0.6813\n",
            "Epoch 752/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5815 - acc: 0.7049 - f1_m: 0.6982 - precision_m: 0.7056 - recall_m: 0.6915 - val_loss: 0.5916 - val_acc: 0.7106 - val_f1_m: 0.3096 - val_precision_m: 0.2010 - val_recall_m: 0.6813\n",
            "Epoch 753/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5815 - acc: 0.7049 - f1_m: 0.7013 - precision_m: 0.7105 - recall_m: 0.6931 - val_loss: 0.5899 - val_acc: 0.7115 - val_f1_m: 0.3102 - val_precision_m: 0.2014 - val_recall_m: 0.6813\n",
            "Epoch 754/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5814 - acc: 0.7045 - f1_m: 0.7020 - precision_m: 0.7059 - recall_m: 0.6992 - val_loss: 0.5911 - val_acc: 0.7106 - val_f1_m: 0.3096 - val_precision_m: 0.2010 - val_recall_m: 0.6813\n",
            "Epoch 755/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5814 - acc: 0.7047 - f1_m: 0.6973 - precision_m: 0.7052 - recall_m: 0.6904 - val_loss: 0.5887 - val_acc: 0.7121 - val_f1_m: 0.3107 - val_precision_m: 0.2018 - val_recall_m: 0.6813\n",
            "Epoch 756/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5814 - acc: 0.7049 - f1_m: 0.7006 - precision_m: 0.7086 - recall_m: 0.6932 - val_loss: 0.5891 - val_acc: 0.7121 - val_f1_m: 0.3107 - val_precision_m: 0.2018 - val_recall_m: 0.6813\n",
            "Epoch 757/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5813 - acc: 0.7049 - f1_m: 0.6957 - precision_m: 0.7014 - recall_m: 0.6907 - val_loss: 0.5900 - val_acc: 0.7110 - val_f1_m: 0.3099 - val_precision_m: 0.2012 - val_recall_m: 0.6813\n",
            "Epoch 758/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5813 - acc: 0.7043 - f1_m: 0.7001 - precision_m: 0.7116 - recall_m: 0.6895 - val_loss: 0.5879 - val_acc: 0.7129 - val_f1_m: 0.3107 - val_precision_m: 0.2020 - val_recall_m: 0.6793\n",
            "Epoch 759/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5813 - acc: 0.7049 - f1_m: 0.7037 - precision_m: 0.7159 - recall_m: 0.6931 - val_loss: 0.5919 - val_acc: 0.7096 - val_f1_m: 0.3089 - val_precision_m: 0.2003 - val_recall_m: 0.6813\n",
            "Epoch 760/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5812 - acc: 0.7055 - f1_m: 0.7034 - precision_m: 0.7124 - recall_m: 0.6952 - val_loss: 0.5941 - val_acc: 0.7073 - val_f1_m: 0.3086 - val_precision_m: 0.1998 - val_recall_m: 0.6857\n",
            "Epoch 761/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5812 - acc: 0.7057 - f1_m: 0.7076 - precision_m: 0.7130 - recall_m: 0.7030 - val_loss: 0.5941 - val_acc: 0.7071 - val_f1_m: 0.3085 - val_precision_m: 0.1997 - val_recall_m: 0.6857\n",
            "Epoch 762/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5812 - acc: 0.7057 - f1_m: 0.7093 - precision_m: 0.7167 - recall_m: 0.7022 - val_loss: 0.5941 - val_acc: 0.7073 - val_f1_m: 0.3087 - val_precision_m: 0.1998 - val_recall_m: 0.6857\n",
            "Epoch 763/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5812 - acc: 0.7059 - f1_m: 0.6957 - precision_m: 0.7050 - recall_m: 0.6874 - val_loss: 0.5957 - val_acc: 0.7056 - val_f1_m: 0.3089 - val_precision_m: 0.1996 - val_recall_m: 0.6906\n",
            "Epoch 764/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5811 - acc: 0.7063 - f1_m: 0.7084 - precision_m: 0.7107 - recall_m: 0.7065 - val_loss: 0.5964 - val_acc: 0.7052 - val_f1_m: 0.3093 - val_precision_m: 0.1997 - val_recall_m: 0.6926\n",
            "Epoch 765/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5811 - acc: 0.7061 - f1_m: 0.7018 - precision_m: 0.7030 - recall_m: 0.7016 - val_loss: 0.5949 - val_acc: 0.7062 - val_f1_m: 0.3094 - val_precision_m: 0.1999 - val_recall_m: 0.6906\n",
            "Epoch 766/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5811 - acc: 0.7065 - f1_m: 0.6979 - precision_m: 0.7050 - recall_m: 0.6912 - val_loss: 0.5906 - val_acc: 0.7100 - val_f1_m: 0.3086 - val_precision_m: 0.2003 - val_recall_m: 0.6793\n",
            "Epoch 767/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5810 - acc: 0.7053 - f1_m: 0.7058 - precision_m: 0.7138 - recall_m: 0.6985 - val_loss: 0.5898 - val_acc: 0.7104 - val_f1_m: 0.3088 - val_precision_m: 0.2005 - val_recall_m: 0.6793\n",
            "Epoch 768/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5810 - acc: 0.7055 - f1_m: 0.7014 - precision_m: 0.7180 - recall_m: 0.6868 - val_loss: 0.5891 - val_acc: 0.7112 - val_f1_m: 0.3095 - val_precision_m: 0.2010 - val_recall_m: 0.6793\n",
            "Epoch 769/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5810 - acc: 0.7059 - f1_m: 0.7090 - precision_m: 0.7129 - recall_m: 0.7060 - val_loss: 0.5930 - val_acc: 0.7081 - val_f1_m: 0.3100 - val_precision_m: 0.2007 - val_recall_m: 0.6882\n",
            "Epoch 770/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5810 - acc: 0.7063 - f1_m: 0.7069 - precision_m: 0.7140 - recall_m: 0.7005 - val_loss: 0.5922 - val_acc: 0.7087 - val_f1_m: 0.3097 - val_precision_m: 0.2007 - val_recall_m: 0.6863\n",
            "Epoch 771/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5809 - acc: 0.7065 - f1_m: 0.7016 - precision_m: 0.7020 - recall_m: 0.7031 - val_loss: 0.5915 - val_acc: 0.7094 - val_f1_m: 0.3102 - val_precision_m: 0.2010 - val_recall_m: 0.6863\n",
            "Epoch 772/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5809 - acc: 0.7057 - f1_m: 0.7066 - precision_m: 0.7148 - recall_m: 0.6993 - val_loss: 0.5875 - val_acc: 0.7129 - val_f1_m: 0.3107 - val_precision_m: 0.2020 - val_recall_m: 0.6793\n",
            "Epoch 773/1000\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.5809 - acc: 0.7057 - f1_m: 0.7010 - precision_m: 0.7149 - recall_m: 0.6884 - val_loss: 0.5855 - val_acc: 0.7135 - val_f1_m: 0.3106 - val_precision_m: 0.2021 - val_recall_m: 0.6773\n",
            "Epoch 774/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5809 - acc: 0.7053 - f1_m: 0.6965 - precision_m: 0.7083 - recall_m: 0.6851 - val_loss: 0.5865 - val_acc: 0.7133 - val_f1_m: 0.3110 - val_precision_m: 0.2023 - val_recall_m: 0.6793\n",
            "Epoch 775/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5808 - acc: 0.7051 - f1_m: 0.7007 - precision_m: 0.7058 - recall_m: 0.6967 - val_loss: 0.5881 - val_acc: 0.7125 - val_f1_m: 0.3104 - val_precision_m: 0.2018 - val_recall_m: 0.6793\n",
            "Epoch 776/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5808 - acc: 0.7053 - f1_m: 0.6915 - precision_m: 0.7040 - recall_m: 0.6797 - val_loss: 0.5880 - val_acc: 0.7127 - val_f1_m: 0.3105 - val_precision_m: 0.2019 - val_recall_m: 0.6793\n",
            "Epoch 777/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5808 - acc: 0.7053 - f1_m: 0.7005 - precision_m: 0.7121 - recall_m: 0.6897 - val_loss: 0.5898 - val_acc: 0.7108 - val_f1_m: 0.3107 - val_precision_m: 0.2016 - val_recall_m: 0.6843\n",
            "Epoch 778/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5807 - acc: 0.7059 - f1_m: 0.7116 - precision_m: 0.7192 - recall_m: 0.7042 - val_loss: 0.5911 - val_acc: 0.7089 - val_f1_m: 0.3093 - val_precision_m: 0.2005 - val_recall_m: 0.6843\n",
            "Epoch 779/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5808 - acc: 0.7059 - f1_m: 0.6981 - precision_m: 0.7035 - recall_m: 0.6932 - val_loss: 0.5944 - val_acc: 0.7064 - val_f1_m: 0.3095 - val_precision_m: 0.2001 - val_recall_m: 0.6906\n",
            "Epoch 780/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5807 - acc: 0.7061 - f1_m: 0.7032 - precision_m: 0.7110 - recall_m: 0.6963 - val_loss: 0.5942 - val_acc: 0.7069 - val_f1_m: 0.3098 - val_precision_m: 0.2003 - val_recall_m: 0.6906\n",
            "Epoch 781/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5807 - acc: 0.7061 - f1_m: 0.7022 - precision_m: 0.7048 - recall_m: 0.7004 - val_loss: 0.5928 - val_acc: 0.7083 - val_f1_m: 0.3109 - val_precision_m: 0.2013 - val_recall_m: 0.6906\n",
            "Epoch 782/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5807 - acc: 0.7061 - f1_m: 0.7086 - precision_m: 0.7249 - recall_m: 0.6950 - val_loss: 0.5894 - val_acc: 0.7106 - val_f1_m: 0.3106 - val_precision_m: 0.2015 - val_recall_m: 0.6843\n",
            "Epoch 783/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5806 - acc: 0.7065 - f1_m: 0.7043 - precision_m: 0.7082 - recall_m: 0.7012 - val_loss: 0.5927 - val_acc: 0.7083 - val_f1_m: 0.3109 - val_precision_m: 0.2013 - val_recall_m: 0.6906\n",
            "Epoch 784/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5806 - acc: 0.7061 - f1_m: 0.6911 - precision_m: 0.7033 - recall_m: 0.6804 - val_loss: 0.5924 - val_acc: 0.7085 - val_f1_m: 0.3104 - val_precision_m: 0.2010 - val_recall_m: 0.6886\n",
            "Epoch 785/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5806 - acc: 0.7059 - f1_m: 0.7032 - precision_m: 0.7092 - recall_m: 0.6974 - val_loss: 0.5937 - val_acc: 0.7069 - val_f1_m: 0.3098 - val_precision_m: 0.2003 - val_recall_m: 0.6906\n",
            "Epoch 786/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5806 - acc: 0.7061 - f1_m: 0.6991 - precision_m: 0.7126 - recall_m: 0.6879 - val_loss: 0.5928 - val_acc: 0.7083 - val_f1_m: 0.3103 - val_precision_m: 0.2009 - val_recall_m: 0.6886\n",
            "Epoch 787/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5805 - acc: 0.7061 - f1_m: 0.7083 - precision_m: 0.7118 - recall_m: 0.7055 - val_loss: 0.5949 - val_acc: 0.7060 - val_f1_m: 0.3092 - val_precision_m: 0.1998 - val_recall_m: 0.6906\n",
            "Epoch 788/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5805 - acc: 0.7061 - f1_m: 0.7025 - precision_m: 0.7062 - recall_m: 0.6994 - val_loss: 0.5937 - val_acc: 0.7069 - val_f1_m: 0.3098 - val_precision_m: 0.2003 - val_recall_m: 0.6906\n",
            "Epoch 789/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5805 - acc: 0.7059 - f1_m: 0.7053 - precision_m: 0.7103 - recall_m: 0.7010 - val_loss: 0.5920 - val_acc: 0.7087 - val_f1_m: 0.3106 - val_precision_m: 0.2012 - val_recall_m: 0.6886\n",
            "Epoch 790/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5805 - acc: 0.7059 - f1_m: 0.7041 - precision_m: 0.7116 - recall_m: 0.6970 - val_loss: 0.5904 - val_acc: 0.7096 - val_f1_m: 0.3105 - val_precision_m: 0.2013 - val_recall_m: 0.6867\n",
            "Epoch 791/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5804 - acc: 0.7057 - f1_m: 0.7083 - precision_m: 0.7164 - recall_m: 0.7007 - val_loss: 0.5929 - val_acc: 0.7079 - val_f1_m: 0.3100 - val_precision_m: 0.2006 - val_recall_m: 0.6886\n",
            "Epoch 792/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5804 - acc: 0.7059 - f1_m: 0.7038 - precision_m: 0.7124 - recall_m: 0.6958 - val_loss: 0.5948 - val_acc: 0.7062 - val_f1_m: 0.3100 - val_precision_m: 0.2003 - val_recall_m: 0.6926\n",
            "Epoch 793/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5804 - acc: 0.7063 - f1_m: 0.7020 - precision_m: 0.7072 - recall_m: 0.6971 - val_loss: 0.5957 - val_acc: 0.7054 - val_f1_m: 0.3094 - val_precision_m: 0.1998 - val_recall_m: 0.6926\n",
            "Epoch 794/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5804 - acc: 0.7063 - f1_m: 0.7024 - precision_m: 0.7110 - recall_m: 0.6947 - val_loss: 0.5939 - val_acc: 0.7062 - val_f1_m: 0.3088 - val_precision_m: 0.1996 - val_recall_m: 0.6886\n",
            "Epoch 795/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5803 - acc: 0.7063 - f1_m: 0.6975 - precision_m: 0.6994 - recall_m: 0.6964 - val_loss: 0.5911 - val_acc: 0.7096 - val_f1_m: 0.3106 - val_precision_m: 0.2013 - val_recall_m: 0.6866\n",
            "Epoch 796/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5803 - acc: 0.7065 - f1_m: 0.7043 - precision_m: 0.7180 - recall_m: 0.6922 - val_loss: 0.5879 - val_acc: 0.7117 - val_f1_m: 0.3107 - val_precision_m: 0.2018 - val_recall_m: 0.6823\n",
            "Epoch 797/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5803 - acc: 0.7067 - f1_m: 0.7047 - precision_m: 0.7098 - recall_m: 0.7009 - val_loss: 0.5878 - val_acc: 0.7121 - val_f1_m: 0.3110 - val_precision_m: 0.2021 - val_recall_m: 0.6823\n",
            "Epoch 798/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5802 - acc: 0.7065 - f1_m: 0.7044 - precision_m: 0.7178 - recall_m: 0.6925 - val_loss: 0.5879 - val_acc: 0.7119 - val_f1_m: 0.3109 - val_precision_m: 0.2020 - val_recall_m: 0.6823\n",
            "Epoch 799/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5802 - acc: 0.7063 - f1_m: 0.7033 - precision_m: 0.7119 - recall_m: 0.6952 - val_loss: 0.5905 - val_acc: 0.7100 - val_f1_m: 0.3109 - val_precision_m: 0.2016 - val_recall_m: 0.6866\n",
            "Epoch 800/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5802 - acc: 0.7073 - f1_m: 0.7078 - precision_m: 0.7141 - recall_m: 0.7020 - val_loss: 0.5924 - val_acc: 0.7083 - val_f1_m: 0.3103 - val_precision_m: 0.2009 - val_recall_m: 0.6886\n",
            "Epoch 801/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5802 - acc: 0.7067 - f1_m: 0.6991 - precision_m: 0.7040 - recall_m: 0.6946 - val_loss: 0.5934 - val_acc: 0.7073 - val_f1_m: 0.3095 - val_precision_m: 0.2002 - val_recall_m: 0.6886\n",
            "Epoch 802/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5801 - acc: 0.7067 - f1_m: 0.7089 - precision_m: 0.7158 - recall_m: 0.7028 - val_loss: 0.5930 - val_acc: 0.7079 - val_f1_m: 0.3100 - val_precision_m: 0.2006 - val_recall_m: 0.6886\n",
            "Epoch 803/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5801 - acc: 0.7065 - f1_m: 0.7049 - precision_m: 0.7101 - recall_m: 0.7003 - val_loss: 0.5940 - val_acc: 0.7062 - val_f1_m: 0.3088 - val_precision_m: 0.1996 - val_recall_m: 0.6886\n",
            "Epoch 804/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5801 - acc: 0.7063 - f1_m: 0.7031 - precision_m: 0.7122 - recall_m: 0.6947 - val_loss: 0.5940 - val_acc: 0.7062 - val_f1_m: 0.3088 - val_precision_m: 0.1996 - val_recall_m: 0.6886\n",
            "Epoch 805/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5801 - acc: 0.7063 - f1_m: 0.6973 - precision_m: 0.6974 - recall_m: 0.6990 - val_loss: 0.5931 - val_acc: 0.7075 - val_f1_m: 0.3097 - val_precision_m: 0.2004 - val_recall_m: 0.6886\n",
            "Epoch 806/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5800 - acc: 0.7069 - f1_m: 0.7030 - precision_m: 0.7104 - recall_m: 0.6964 - val_loss: 0.5892 - val_acc: 0.7108 - val_f1_m: 0.3109 - val_precision_m: 0.2018 - val_recall_m: 0.6847\n",
            "Epoch 807/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5800 - acc: 0.7069 - f1_m: 0.6978 - precision_m: 0.7093 - recall_m: 0.6874 - val_loss: 0.5869 - val_acc: 0.7127 - val_f1_m: 0.3123 - val_precision_m: 0.2029 - val_recall_m: 0.6847\n",
            "Epoch 808/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5800 - acc: 0.7065 - f1_m: 0.7060 - precision_m: 0.7194 - recall_m: 0.6936 - val_loss: 0.5874 - val_acc: 0.7125 - val_f1_m: 0.3121 - val_precision_m: 0.2028 - val_recall_m: 0.6847\n",
            "Epoch 809/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5800 - acc: 0.7067 - f1_m: 0.7027 - precision_m: 0.7135 - recall_m: 0.6925 - val_loss: 0.5893 - val_acc: 0.7106 - val_f1_m: 0.3107 - val_precision_m: 0.2016 - val_recall_m: 0.6847\n",
            "Epoch 810/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5799 - acc: 0.7069 - f1_m: 0.7079 - precision_m: 0.7180 - recall_m: 0.6985 - val_loss: 0.5910 - val_acc: 0.7096 - val_f1_m: 0.3106 - val_precision_m: 0.2013 - val_recall_m: 0.6866\n",
            "Epoch 811/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5799 - acc: 0.7071 - f1_m: 0.6956 - precision_m: 0.7044 - recall_m: 0.6877 - val_loss: 0.5934 - val_acc: 0.7069 - val_f1_m: 0.3086 - val_precision_m: 0.1996 - val_recall_m: 0.6866\n",
            "Epoch 812/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5799 - acc: 0.7067 - f1_m: 0.7016 - precision_m: 0.7111 - recall_m: 0.6930 - val_loss: 0.5944 - val_acc: 0.7058 - val_f1_m: 0.3085 - val_precision_m: 0.1994 - val_recall_m: 0.6886\n",
            "Epoch 813/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5799 - acc: 0.7063 - f1_m: 0.7013 - precision_m: 0.7098 - recall_m: 0.6939 - val_loss: 0.5925 - val_acc: 0.7081 - val_f1_m: 0.3095 - val_precision_m: 0.2004 - val_recall_m: 0.6866\n",
            "Epoch 814/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5798 - acc: 0.7069 - f1_m: 0.7019 - precision_m: 0.7086 - recall_m: 0.6955 - val_loss: 0.5915 - val_acc: 0.7085 - val_f1_m: 0.3098 - val_precision_m: 0.2006 - val_recall_m: 0.6866\n",
            "Epoch 815/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5799 - acc: 0.7071 - f1_m: 0.7068 - precision_m: 0.7113 - recall_m: 0.7036 - val_loss: 0.5925 - val_acc: 0.7079 - val_f1_m: 0.3094 - val_precision_m: 0.2003 - val_recall_m: 0.6866\n",
            "Epoch 816/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5798 - acc: 0.7075 - f1_m: 0.7086 - precision_m: 0.7143 - recall_m: 0.7033 - val_loss: 0.5898 - val_acc: 0.7102 - val_f1_m: 0.3111 - val_precision_m: 0.2017 - val_recall_m: 0.6866\n",
            "Epoch 817/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5798 - acc: 0.7071 - f1_m: 0.7036 - precision_m: 0.7087 - recall_m: 0.6992 - val_loss: 0.5883 - val_acc: 0.7112 - val_f1_m: 0.3112 - val_precision_m: 0.2021 - val_recall_m: 0.6847\n",
            "Epoch 818/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5798 - acc: 0.7065 - f1_m: 0.6997 - precision_m: 0.7065 - recall_m: 0.6938 - val_loss: 0.5860 - val_acc: 0.7133 - val_f1_m: 0.3127 - val_precision_m: 0.2033 - val_recall_m: 0.6847\n",
            "Epoch 819/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5797 - acc: 0.7065 - f1_m: 0.7062 - precision_m: 0.7174 - recall_m: 0.6957 - val_loss: 0.5850 - val_acc: 0.7140 - val_f1_m: 0.3131 - val_precision_m: 0.2036 - val_recall_m: 0.6847\n",
            "Epoch 820/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5797 - acc: 0.7065 - f1_m: 0.7091 - precision_m: 0.7195 - recall_m: 0.6995 - val_loss: 0.5860 - val_acc: 0.7135 - val_f1_m: 0.3129 - val_precision_m: 0.2034 - val_recall_m: 0.6847\n",
            "Epoch 821/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5797 - acc: 0.7065 - f1_m: 0.7008 - precision_m: 0.7070 - recall_m: 0.6960 - val_loss: 0.5871 - val_acc: 0.7125 - val_f1_m: 0.3122 - val_precision_m: 0.2028 - val_recall_m: 0.6847\n",
            "Epoch 822/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5797 - acc: 0.7065 - f1_m: 0.6942 - precision_m: 0.7031 - recall_m: 0.6860 - val_loss: 0.5871 - val_acc: 0.7125 - val_f1_m: 0.3122 - val_precision_m: 0.2028 - val_recall_m: 0.6847\n",
            "Epoch 823/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5796 - acc: 0.7067 - f1_m: 0.6966 - precision_m: 0.7005 - recall_m: 0.6942 - val_loss: 0.5882 - val_acc: 0.7108 - val_f1_m: 0.3109 - val_precision_m: 0.2017 - val_recall_m: 0.6847\n",
            "Epoch 824/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5796 - acc: 0.7071 - f1_m: 0.6996 - precision_m: 0.7108 - recall_m: 0.6891 - val_loss: 0.5866 - val_acc: 0.7131 - val_f1_m: 0.3126 - val_precision_m: 0.2032 - val_recall_m: 0.6847\n",
            "Epoch 825/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5796 - acc: 0.7063 - f1_m: 0.7084 - precision_m: 0.7160 - recall_m: 0.7015 - val_loss: 0.5871 - val_acc: 0.7127 - val_f1_m: 0.3123 - val_precision_m: 0.2029 - val_recall_m: 0.6847\n",
            "Epoch 826/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5796 - acc: 0.7059 - f1_m: 0.7079 - precision_m: 0.7137 - recall_m: 0.7027 - val_loss: 0.5883 - val_acc: 0.7106 - val_f1_m: 0.3107 - val_precision_m: 0.2016 - val_recall_m: 0.6847\n",
            "Epoch 827/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5796 - acc: 0.7067 - f1_m: 0.6967 - precision_m: 0.7001 - recall_m: 0.6945 - val_loss: 0.5890 - val_acc: 0.7108 - val_f1_m: 0.3116 - val_precision_m: 0.2021 - val_recall_m: 0.6866\n",
            "Epoch 828/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5795 - acc: 0.7067 - f1_m: 0.7034 - precision_m: 0.7129 - recall_m: 0.6944 - val_loss: 0.5853 - val_acc: 0.7140 - val_f1_m: 0.3132 - val_precision_m: 0.2037 - val_recall_m: 0.6847\n",
            "Epoch 829/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.5795 - acc: 0.7059 - f1_m: 0.7038 - precision_m: 0.7205 - recall_m: 0.6891 - val_loss: 0.5842 - val_acc: 0.7150 - val_f1_m: 0.3139 - val_precision_m: 0.2043 - val_recall_m: 0.6847\n",
            "Epoch 830/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.5795 - acc: 0.7063 - f1_m: 0.7021 - precision_m: 0.7084 - recall_m: 0.6967 - val_loss: 0.5882 - val_acc: 0.7112 - val_f1_m: 0.3119 - val_precision_m: 0.2024 - val_recall_m: 0.6866\n",
            "Epoch 831/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.5794 - acc: 0.7059 - f1_m: 0.6988 - precision_m: 0.7070 - recall_m: 0.6909 - val_loss: 0.5891 - val_acc: 0.7104 - val_f1_m: 0.3112 - val_precision_m: 0.2018 - val_recall_m: 0.6866\n",
            "Epoch 832/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.5794 - acc: 0.7059 - f1_m: 0.6964 - precision_m: 0.7046 - recall_m: 0.6886 - val_loss: 0.5892 - val_acc: 0.7104 - val_f1_m: 0.3112 - val_precision_m: 0.2018 - val_recall_m: 0.6866\n",
            "Epoch 833/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5794 - acc: 0.7059 - f1_m: 0.7073 - precision_m: 0.7154 - recall_m: 0.6998 - val_loss: 0.5895 - val_acc: 0.7104 - val_f1_m: 0.3112 - val_precision_m: 0.2018 - val_recall_m: 0.6866\n",
            "Epoch 834/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5794 - acc: 0.7055 - f1_m: 0.6957 - precision_m: 0.7041 - recall_m: 0.6879 - val_loss: 0.5888 - val_acc: 0.7106 - val_f1_m: 0.3114 - val_precision_m: 0.2019 - val_recall_m: 0.6866\n",
            "Epoch 835/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5793 - acc: 0.7063 - f1_m: 0.7075 - precision_m: 0.7180 - recall_m: 0.6979 - val_loss: 0.5881 - val_acc: 0.7112 - val_f1_m: 0.3119 - val_precision_m: 0.2024 - val_recall_m: 0.6866\n",
            "Epoch 836/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5793 - acc: 0.7059 - f1_m: 0.7055 - precision_m: 0.7168 - recall_m: 0.6952 - val_loss: 0.5902 - val_acc: 0.7094 - val_f1_m: 0.3104 - val_precision_m: 0.2012 - val_recall_m: 0.6866\n",
            "Epoch 837/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5793 - acc: 0.7063 - f1_m: 0.7075 - precision_m: 0.7151 - recall_m: 0.7003 - val_loss: 0.5920 - val_acc: 0.7083 - val_f1_m: 0.3097 - val_precision_m: 0.2005 - val_recall_m: 0.6866\n",
            "Epoch 838/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5793 - acc: 0.7069 - f1_m: 0.7095 - precision_m: 0.7150 - recall_m: 0.7046 - val_loss: 0.5939 - val_acc: 0.7060 - val_f1_m: 0.3086 - val_precision_m: 0.1995 - val_recall_m: 0.6886\n",
            "Epoch 839/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5793 - acc: 0.7069 - f1_m: 0.7066 - precision_m: 0.7069 - recall_m: 0.7087 - val_loss: 0.5922 - val_acc: 0.7079 - val_f1_m: 0.3094 - val_precision_m: 0.2003 - val_recall_m: 0.6866\n",
            "Epoch 840/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5793 - acc: 0.7061 - f1_m: 0.6980 - precision_m: 0.7084 - recall_m: 0.6887 - val_loss: 0.5892 - val_acc: 0.7098 - val_f1_m: 0.3107 - val_precision_m: 0.2014 - val_recall_m: 0.6866\n",
            "Epoch 841/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5792 - acc: 0.7057 - f1_m: 0.7028 - precision_m: 0.7129 - recall_m: 0.6932 - val_loss: 0.5887 - val_acc: 0.7102 - val_f1_m: 0.3111 - val_precision_m: 0.2017 - val_recall_m: 0.6866\n",
            "Epoch 842/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5792 - acc: 0.7057 - f1_m: 0.7048 - precision_m: 0.7150 - recall_m: 0.6950 - val_loss: 0.5888 - val_acc: 0.7104 - val_f1_m: 0.3112 - val_precision_m: 0.2018 - val_recall_m: 0.6866\n",
            "Epoch 843/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5792 - acc: 0.7057 - f1_m: 0.7032 - precision_m: 0.7145 - recall_m: 0.6927 - val_loss: 0.5914 - val_acc: 0.7085 - val_f1_m: 0.3099 - val_precision_m: 0.2007 - val_recall_m: 0.6866\n",
            "Epoch 844/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5791 - acc: 0.7063 - f1_m: 0.7029 - precision_m: 0.7103 - recall_m: 0.6956 - val_loss: 0.5927 - val_acc: 0.7073 - val_f1_m: 0.3089 - val_precision_m: 0.1999 - val_recall_m: 0.6866\n",
            "Epoch 845/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5791 - acc: 0.7067 - f1_m: 0.7108 - precision_m: 0.7167 - recall_m: 0.7055 - val_loss: 0.5933 - val_acc: 0.7066 - val_f1_m: 0.3091 - val_precision_m: 0.1999 - val_recall_m: 0.6886\n",
            "Epoch 846/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5791 - acc: 0.7063 - f1_m: 0.6999 - precision_m: 0.7051 - recall_m: 0.6948 - val_loss: 0.5925 - val_acc: 0.7075 - val_f1_m: 0.3091 - val_precision_m: 0.2000 - val_recall_m: 0.6866\n",
            "Epoch 847/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5791 - acc: 0.7063 - f1_m: 0.7054 - precision_m: 0.7113 - recall_m: 0.7001 - val_loss: 0.5920 - val_acc: 0.7083 - val_f1_m: 0.3097 - val_precision_m: 0.2005 - val_recall_m: 0.6866\n",
            "Epoch 848/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5790 - acc: 0.7059 - f1_m: 0.7048 - precision_m: 0.7156 - recall_m: 0.6951 - val_loss: 0.5902 - val_acc: 0.7094 - val_f1_m: 0.3105 - val_precision_m: 0.2012 - val_recall_m: 0.6866\n",
            "Epoch 849/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5790 - acc: 0.7055 - f1_m: 0.6949 - precision_m: 0.7046 - recall_m: 0.6863 - val_loss: 0.5884 - val_acc: 0.7104 - val_f1_m: 0.3112 - val_precision_m: 0.2018 - val_recall_m: 0.6866\n",
            "Epoch 850/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5790 - acc: 0.7057 - f1_m: 0.7016 - precision_m: 0.7092 - recall_m: 0.6944 - val_loss: 0.5901 - val_acc: 0.7096 - val_f1_m: 0.3106 - val_precision_m: 0.2013 - val_recall_m: 0.6866\n",
            "Epoch 851/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5790 - acc: 0.7055 - f1_m: 0.7004 - precision_m: 0.7100 - recall_m: 0.6916 - val_loss: 0.5898 - val_acc: 0.7096 - val_f1_m: 0.3106 - val_precision_m: 0.2013 - val_recall_m: 0.6866\n",
            "Epoch 852/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5790 - acc: 0.7055 - f1_m: 0.6974 - precision_m: 0.7174 - recall_m: 0.6821 - val_loss: 0.5909 - val_acc: 0.7089 - val_f1_m: 0.3102 - val_precision_m: 0.2009 - val_recall_m: 0.6866\n",
            "Epoch 853/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5790 - acc: 0.7057 - f1_m: 0.7036 - precision_m: 0.7152 - recall_m: 0.6936 - val_loss: 0.5962 - val_acc: 0.7041 - val_f1_m: 0.3086 - val_precision_m: 0.1991 - val_recall_m: 0.6929\n",
            "Epoch 854/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5790 - acc: 0.7071 - f1_m: 0.7045 - precision_m: 0.7067 - recall_m: 0.7031 - val_loss: 0.5969 - val_acc: 0.7039 - val_f1_m: 0.3084 - val_precision_m: 0.1990 - val_recall_m: 0.6929\n",
            "Epoch 855/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.5789 - acc: 0.7063 - f1_m: 0.6984 - precision_m: 0.7085 - recall_m: 0.6899 - val_loss: 0.5944 - val_acc: 0.7056 - val_f1_m: 0.3090 - val_precision_m: 0.1996 - val_recall_m: 0.6906\n",
            "Epoch 856/1000\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.5789 - acc: 0.7059 - f1_m: 0.7083 - precision_m: 0.7113 - recall_m: 0.7053 - val_loss: 0.5949 - val_acc: 0.7050 - val_f1_m: 0.3085 - val_precision_m: 0.1992 - val_recall_m: 0.6906\n",
            "Epoch 857/1000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.5789 - acc: 0.7061 - f1_m: 0.7117 - precision_m: 0.7137 - recall_m: 0.7100 - val_loss: 0.5939 - val_acc: 0.7060 - val_f1_m: 0.3093 - val_precision_m: 0.1999 - val_recall_m: 0.6906\n",
            "Epoch 858/1000\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.5788 - acc: 0.7063 - f1_m: 0.7070 - precision_m: 0.7128 - recall_m: 0.7015 - val_loss: 0.5928 - val_acc: 0.7081 - val_f1_m: 0.3109 - val_precision_m: 0.2012 - val_recall_m: 0.6906\n",
            "Epoch 859/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5788 - acc: 0.7055 - f1_m: 0.7091 - precision_m: 0.7191 - recall_m: 0.7001 - val_loss: 0.5917 - val_acc: 0.7081 - val_f1_m: 0.3102 - val_precision_m: 0.2008 - val_recall_m: 0.6886\n",
            "Epoch 860/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5788 - acc: 0.7053 - f1_m: 0.6924 - precision_m: 0.6981 - recall_m: 0.6871 - val_loss: 0.5937 - val_acc: 0.7062 - val_f1_m: 0.3095 - val_precision_m: 0.2000 - val_recall_m: 0.6906\n",
            "Epoch 861/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5788 - acc: 0.7053 - f1_m: 0.7063 - precision_m: 0.7091 - recall_m: 0.7048 - val_loss: 0.5907 - val_acc: 0.7087 - val_f1_m: 0.3100 - val_precision_m: 0.2008 - val_recall_m: 0.6866\n",
            "Epoch 862/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5787 - acc: 0.7055 - f1_m: 0.7062 - precision_m: 0.7161 - recall_m: 0.6969 - val_loss: 0.5887 - val_acc: 0.7102 - val_f1_m: 0.3111 - val_precision_m: 0.2017 - val_recall_m: 0.6866\n",
            "Epoch 863/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5787 - acc: 0.7055 - f1_m: 0.7048 - precision_m: 0.7179 - recall_m: 0.6929 - val_loss: 0.5886 - val_acc: 0.7100 - val_f1_m: 0.3109 - val_precision_m: 0.2015 - val_recall_m: 0.6866\n",
            "Epoch 864/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5787 - acc: 0.7053 - f1_m: 0.6997 - precision_m: 0.7080 - recall_m: 0.6920 - val_loss: 0.5921 - val_acc: 0.7081 - val_f1_m: 0.3109 - val_precision_m: 0.2012 - val_recall_m: 0.6906\n",
            "Epoch 865/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5787 - acc: 0.7051 - f1_m: 0.7036 - precision_m: 0.7118 - recall_m: 0.6962 - val_loss: 0.5935 - val_acc: 0.7066 - val_f1_m: 0.3104 - val_precision_m: 0.2006 - val_recall_m: 0.6929\n",
            "Epoch 866/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5787 - acc: 0.7059 - f1_m: 0.7062 - precision_m: 0.7083 - recall_m: 0.7044 - val_loss: 0.5941 - val_acc: 0.7064 - val_f1_m: 0.3102 - val_precision_m: 0.2004 - val_recall_m: 0.6929\n",
            "Epoch 867/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5786 - acc: 0.7061 - f1_m: 0.7066 - precision_m: 0.7057 - recall_m: 0.7095 - val_loss: 0.5928 - val_acc: 0.7079 - val_f1_m: 0.3107 - val_precision_m: 0.2010 - val_recall_m: 0.6906\n",
            "Epoch 868/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5786 - acc: 0.7059 - f1_m: 0.7079 - precision_m: 0.7112 - recall_m: 0.7050 - val_loss: 0.5901 - val_acc: 0.7089 - val_f1_m: 0.3102 - val_precision_m: 0.2009 - val_recall_m: 0.6866\n",
            "Epoch 869/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5786 - acc: 0.7059 - f1_m: 0.7027 - precision_m: 0.7112 - recall_m: 0.6945 - val_loss: 0.5871 - val_acc: 0.7117 - val_f1_m: 0.3121 - val_precision_m: 0.2026 - val_recall_m: 0.6866\n",
            "Epoch 870/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5786 - acc: 0.7057 - f1_m: 0.7073 - precision_m: 0.7130 - recall_m: 0.7020 - val_loss: 0.5877 - val_acc: 0.7112 - val_f1_m: 0.3119 - val_precision_m: 0.2023 - val_recall_m: 0.6866\n",
            "Epoch 871/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5785 - acc: 0.7057 - f1_m: 0.7001 - precision_m: 0.7099 - recall_m: 0.6910 - val_loss: 0.5881 - val_acc: 0.7106 - val_f1_m: 0.3114 - val_precision_m: 0.2019 - val_recall_m: 0.6866\n",
            "Epoch 872/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5785 - acc: 0.7059 - f1_m: 0.6996 - precision_m: 0.7090 - recall_m: 0.6908 - val_loss: 0.5873 - val_acc: 0.7112 - val_f1_m: 0.3119 - val_precision_m: 0.2023 - val_recall_m: 0.6866\n",
            "Epoch 873/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5785 - acc: 0.7057 - f1_m: 0.7027 - precision_m: 0.7097 - recall_m: 0.6960 - val_loss: 0.5886 - val_acc: 0.7104 - val_f1_m: 0.3113 - val_precision_m: 0.2018 - val_recall_m: 0.6866\n",
            "Epoch 874/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5785 - acc: 0.7057 - f1_m: 0.7018 - precision_m: 0.7168 - recall_m: 0.6886 - val_loss: 0.5884 - val_acc: 0.7102 - val_f1_m: 0.3111 - val_precision_m: 0.2017 - val_recall_m: 0.6866\n",
            "Epoch 875/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5785 - acc: 0.7059 - f1_m: 0.6994 - precision_m: 0.7051 - recall_m: 0.6944 - val_loss: 0.5896 - val_acc: 0.7092 - val_f1_m: 0.3103 - val_precision_m: 0.2010 - val_recall_m: 0.6866\n",
            "Epoch 876/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5784 - acc: 0.7061 - f1_m: 0.7012 - precision_m: 0.7114 - recall_m: 0.6918 - val_loss: 0.5879 - val_acc: 0.7106 - val_f1_m: 0.3114 - val_precision_m: 0.2020 - val_recall_m: 0.6866\n",
            "Epoch 877/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5784 - acc: 0.7057 - f1_m: 0.6994 - precision_m: 0.7106 - recall_m: 0.6889 - val_loss: 0.5885 - val_acc: 0.7100 - val_f1_m: 0.3109 - val_precision_m: 0.2016 - val_recall_m: 0.6866\n",
            "Epoch 878/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5784 - acc: 0.7059 - f1_m: 0.7032 - precision_m: 0.7128 - recall_m: 0.6942 - val_loss: 0.5883 - val_acc: 0.7100 - val_f1_m: 0.3109 - val_precision_m: 0.2016 - val_recall_m: 0.6866\n",
            "Epoch 879/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5784 - acc: 0.7057 - f1_m: 0.6972 - precision_m: 0.7090 - recall_m: 0.6863 - val_loss: 0.5881 - val_acc: 0.7102 - val_f1_m: 0.3111 - val_precision_m: 0.2017 - val_recall_m: 0.6866\n",
            "Epoch 880/1000\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.5783 - acc: 0.7059 - f1_m: 0.7061 - precision_m: 0.7181 - recall_m: 0.6950 - val_loss: 0.5904 - val_acc: 0.7094 - val_f1_m: 0.3111 - val_precision_m: 0.2015 - val_recall_m: 0.6886\n",
            "Epoch 881/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5783 - acc: 0.7049 - f1_m: 0.7067 - precision_m: 0.7118 - recall_m: 0.7020 - val_loss: 0.5941 - val_acc: 0.7073 - val_f1_m: 0.3109 - val_precision_m: 0.2009 - val_recall_m: 0.6929\n",
            "Epoch 882/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5783 - acc: 0.7057 - f1_m: 0.7101 - precision_m: 0.7188 - recall_m: 0.7023 - val_loss: 0.5951 - val_acc: 0.7064 - val_f1_m: 0.3102 - val_precision_m: 0.2004 - val_recall_m: 0.6929\n",
            "Epoch 883/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5783 - acc: 0.7069 - f1_m: 0.7028 - precision_m: 0.7036 - recall_m: 0.7026 - val_loss: 0.5972 - val_acc: 0.7041 - val_f1_m: 0.3087 - val_precision_m: 0.1992 - val_recall_m: 0.6929\n",
            "Epoch 884/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5783 - acc: 0.7065 - f1_m: 0.6967 - precision_m: 0.7031 - recall_m: 0.6914 - val_loss: 0.5948 - val_acc: 0.7069 - val_f1_m: 0.3106 - val_precision_m: 0.2007 - val_recall_m: 0.6929\n",
            "Epoch 885/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5782 - acc: 0.7055 - f1_m: 0.6997 - precision_m: 0.7049 - recall_m: 0.6953 - val_loss: 0.5915 - val_acc: 0.7092 - val_f1_m: 0.3123 - val_precision_m: 0.2022 - val_recall_m: 0.6929\n",
            "Epoch 886/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5782 - acc: 0.7049 - f1_m: 0.6985 - precision_m: 0.7063 - recall_m: 0.6912 - val_loss: 0.5884 - val_acc: 0.7098 - val_f1_m: 0.3108 - val_precision_m: 0.2014 - val_recall_m: 0.6866\n",
            "Epoch 887/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5782 - acc: 0.7065 - f1_m: 0.6970 - precision_m: 0.7048 - recall_m: 0.6901 - val_loss: 0.5855 - val_acc: 0.7125 - val_f1_m: 0.3121 - val_precision_m: 0.2027 - val_recall_m: 0.6846\n",
            "Epoch 888/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5782 - acc: 0.7065 - f1_m: 0.7035 - precision_m: 0.7222 - recall_m: 0.6874 - val_loss: 0.5850 - val_acc: 0.7127 - val_f1_m: 0.3122 - val_precision_m: 0.2029 - val_recall_m: 0.6846\n",
            "Epoch 889/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5782 - acc: 0.7067 - f1_m: 0.7028 - precision_m: 0.7133 - recall_m: 0.6928 - val_loss: 0.5878 - val_acc: 0.7108 - val_f1_m: 0.3116 - val_precision_m: 0.2021 - val_recall_m: 0.6866\n",
            "Epoch 890/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5781 - acc: 0.7061 - f1_m: 0.7011 - precision_m: 0.7118 - recall_m: 0.6912 - val_loss: 0.5889 - val_acc: 0.7098 - val_f1_m: 0.3115 - val_precision_m: 0.2019 - val_recall_m: 0.6886\n",
            "Epoch 891/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5781 - acc: 0.7061 - f1_m: 0.7061 - precision_m: 0.7135 - recall_m: 0.6992 - val_loss: 0.5916 - val_acc: 0.7096 - val_f1_m: 0.3126 - val_precision_m: 0.2024 - val_recall_m: 0.6929\n",
            "Epoch 892/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5781 - acc: 0.7057 - f1_m: 0.7003 - precision_m: 0.7064 - recall_m: 0.6947 - val_loss: 0.5945 - val_acc: 0.7069 - val_f1_m: 0.3106 - val_precision_m: 0.2007 - val_recall_m: 0.6929\n",
            "Epoch 893/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5781 - acc: 0.7057 - f1_m: 0.7036 - precision_m: 0.7088 - recall_m: 0.6986 - val_loss: 0.5961 - val_acc: 0.7054 - val_f1_m: 0.3095 - val_precision_m: 0.1999 - val_recall_m: 0.6929\n",
            "Epoch 894/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5781 - acc: 0.7063 - f1_m: 0.7098 - precision_m: 0.7153 - recall_m: 0.7049 - val_loss: 0.5949 - val_acc: 0.7066 - val_f1_m: 0.3104 - val_precision_m: 0.2006 - val_recall_m: 0.6929\n",
            "Epoch 895/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5781 - acc: 0.7059 - f1_m: 0.7017 - precision_m: 0.7033 - recall_m: 0.7009 - val_loss: 0.5933 - val_acc: 0.7085 - val_f1_m: 0.3118 - val_precision_m: 0.2017 - val_recall_m: 0.6929\n",
            "Epoch 896/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5780 - acc: 0.7061 - f1_m: 0.6997 - precision_m: 0.7105 - recall_m: 0.6901 - val_loss: 0.5904 - val_acc: 0.7094 - val_f1_m: 0.3118 - val_precision_m: 0.2019 - val_recall_m: 0.6909\n",
            "Epoch 897/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5780 - acc: 0.7059 - f1_m: 0.6961 - precision_m: 0.7066 - recall_m: 0.6863 - val_loss: 0.5891 - val_acc: 0.7104 - val_f1_m: 0.3112 - val_precision_m: 0.2019 - val_recall_m: 0.6866\n",
            "Epoch 898/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5780 - acc: 0.7057 - f1_m: 0.6918 - precision_m: 0.6972 - recall_m: 0.6869 - val_loss: 0.5900 - val_acc: 0.7096 - val_f1_m: 0.3119 - val_precision_m: 0.2020 - val_recall_m: 0.6909\n",
            "Epoch 899/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5780 - acc: 0.7059 - f1_m: 0.7019 - precision_m: 0.7143 - recall_m: 0.6907 - val_loss: 0.5881 - val_acc: 0.7110 - val_f1_m: 0.3117 - val_precision_m: 0.2022 - val_recall_m: 0.6866\n",
            "Epoch 900/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5779 - acc: 0.7065 - f1_m: 0.7037 - precision_m: 0.7195 - recall_m: 0.6900 - val_loss: 0.5888 - val_acc: 0.7110 - val_f1_m: 0.3117 - val_precision_m: 0.2022 - val_recall_m: 0.6866\n",
            "Epoch 901/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5779 - acc: 0.7063 - f1_m: 0.7063 - precision_m: 0.7125 - recall_m: 0.7004 - val_loss: 0.5908 - val_acc: 0.7098 - val_f1_m: 0.3127 - val_precision_m: 0.2025 - val_recall_m: 0.6929\n",
            "Epoch 902/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5779 - acc: 0.7057 - f1_m: 0.6970 - precision_m: 0.7064 - recall_m: 0.6883 - val_loss: 0.5886 - val_acc: 0.7112 - val_f1_m: 0.3125 - val_precision_m: 0.2027 - val_recall_m: 0.6889\n",
            "Epoch 903/1000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5779 - acc: 0.7059 - f1_m: 0.7101 - precision_m: 0.7134 - recall_m: 0.7081 - val_loss: 0.5894 - val_acc: 0.7104 - val_f1_m: 0.3119 - val_precision_m: 0.2022 - val_recall_m: 0.6889\n",
            "Epoch 904/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5778 - acc: 0.7059 - f1_m: 0.6986 - precision_m: 0.7070 - recall_m: 0.6906 - val_loss: 0.5881 - val_acc: 0.7112 - val_f1_m: 0.3119 - val_precision_m: 0.2024 - val_recall_m: 0.6866\n",
            "Epoch 905/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5778 - acc: 0.7065 - f1_m: 0.7037 - precision_m: 0.7165 - recall_m: 0.6920 - val_loss: 0.5878 - val_acc: 0.7115 - val_f1_m: 0.3120 - val_precision_m: 0.2025 - val_recall_m: 0.6866\n",
            "Epoch 906/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5778 - acc: 0.7063 - f1_m: 0.6982 - precision_m: 0.7020 - recall_m: 0.6958 - val_loss: 0.5878 - val_acc: 0.7117 - val_f1_m: 0.3122 - val_precision_m: 0.2027 - val_recall_m: 0.6866\n",
            "Epoch 907/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5778 - acc: 0.7071 - f1_m: 0.7057 - precision_m: 0.7167 - recall_m: 0.6954 - val_loss: 0.5855 - val_acc: 0.7123 - val_f1_m: 0.3119 - val_precision_m: 0.2026 - val_recall_m: 0.6846\n",
            "Epoch 908/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5778 - acc: 0.7067 - f1_m: 0.6898 - precision_m: 0.6992 - recall_m: 0.6812 - val_loss: 0.5873 - val_acc: 0.7117 - val_f1_m: 0.3122 - val_precision_m: 0.2027 - val_recall_m: 0.6866\n",
            "Epoch 909/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5777 - acc: 0.7069 - f1_m: 0.7037 - precision_m: 0.7140 - recall_m: 0.6940 - val_loss: 0.5859 - val_acc: 0.7119 - val_f1_m: 0.3123 - val_precision_m: 0.2028 - val_recall_m: 0.6866\n",
            "Epoch 910/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5777 - acc: 0.7063 - f1_m: 0.7058 - precision_m: 0.7159 - recall_m: 0.6965 - val_loss: 0.5859 - val_acc: 0.7117 - val_f1_m: 0.3122 - val_precision_m: 0.2027 - val_recall_m: 0.6866\n",
            "Epoch 911/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5777 - acc: 0.7065 - f1_m: 0.6966 - precision_m: 0.7046 - recall_m: 0.6890 - val_loss: 0.5865 - val_acc: 0.7117 - val_f1_m: 0.3122 - val_precision_m: 0.2027 - val_recall_m: 0.6866\n",
            "Epoch 912/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5777 - acc: 0.7069 - f1_m: 0.6998 - precision_m: 0.7063 - recall_m: 0.6945 - val_loss: 0.5840 - val_acc: 0.7135 - val_f1_m: 0.3129 - val_precision_m: 0.2034 - val_recall_m: 0.6846\n",
            "Epoch 913/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5777 - acc: 0.7077 - f1_m: 0.7026 - precision_m: 0.7101 - recall_m: 0.6964 - val_loss: 0.5824 - val_acc: 0.7142 - val_f1_m: 0.3133 - val_precision_m: 0.2037 - val_recall_m: 0.6846\n",
            "Epoch 914/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5777 - acc: 0.7079 - f1_m: 0.7087 - precision_m: 0.7209 - recall_m: 0.6972 - val_loss: 0.5827 - val_acc: 0.7142 - val_f1_m: 0.3133 - val_precision_m: 0.2037 - val_recall_m: 0.6846\n",
            "Epoch 915/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5776 - acc: 0.7079 - f1_m: 0.6994 - precision_m: 0.7125 - recall_m: 0.6870 - val_loss: 0.5839 - val_acc: 0.7129 - val_f1_m: 0.3124 - val_precision_m: 0.2030 - val_recall_m: 0.6846\n",
            "Epoch 916/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5776 - acc: 0.7079 - f1_m: 0.7089 - precision_m: 0.7217 - recall_m: 0.6970 - val_loss: 0.5851 - val_acc: 0.7131 - val_f1_m: 0.3132 - val_precision_m: 0.2035 - val_recall_m: 0.6866\n",
            "Epoch 917/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5776 - acc: 0.7061 - f1_m: 0.6963 - precision_m: 0.7033 - recall_m: 0.6900 - val_loss: 0.5880 - val_acc: 0.7112 - val_f1_m: 0.3125 - val_precision_m: 0.2028 - val_recall_m: 0.6889\n",
            "Epoch 918/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5776 - acc: 0.7061 - f1_m: 0.7008 - precision_m: 0.7108 - recall_m: 0.6915 - val_loss: 0.5892 - val_acc: 0.7108 - val_f1_m: 0.3123 - val_precision_m: 0.2025 - val_recall_m: 0.6889\n",
            "Epoch 919/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5775 - acc: 0.7063 - f1_m: 0.7026 - precision_m: 0.7163 - recall_m: 0.6906 - val_loss: 0.5892 - val_acc: 0.7108 - val_f1_m: 0.3129 - val_precision_m: 0.2029 - val_recall_m: 0.6909\n",
            "Epoch 920/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5775 - acc: 0.7061 - f1_m: 0.6983 - precision_m: 0.7031 - recall_m: 0.6941 - val_loss: 0.5903 - val_acc: 0.7096 - val_f1_m: 0.3120 - val_precision_m: 0.2021 - val_recall_m: 0.6909\n",
            "Epoch 921/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5775 - acc: 0.7063 - f1_m: 0.7061 - precision_m: 0.7202 - recall_m: 0.6936 - val_loss: 0.5899 - val_acc: 0.7098 - val_f1_m: 0.3121 - val_precision_m: 0.2022 - val_recall_m: 0.6909\n",
            "Epoch 922/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5775 - acc: 0.7061 - f1_m: 0.7099 - precision_m: 0.7129 - recall_m: 0.7080 - val_loss: 0.5921 - val_acc: 0.7092 - val_f1_m: 0.3123 - val_precision_m: 0.2022 - val_recall_m: 0.6929\n",
            "Epoch 923/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5775 - acc: 0.7063 - f1_m: 0.7024 - precision_m: 0.7059 - recall_m: 0.6997 - val_loss: 0.5910 - val_acc: 0.7096 - val_f1_m: 0.3126 - val_precision_m: 0.2024 - val_recall_m: 0.6929\n",
            "Epoch 924/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5774 - acc: 0.7059 - f1_m: 0.7005 - precision_m: 0.7106 - recall_m: 0.6911 - val_loss: 0.5868 - val_acc: 0.7123 - val_f1_m: 0.3133 - val_precision_m: 0.2034 - val_recall_m: 0.6889\n",
            "Epoch 925/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5774 - acc: 0.7067 - f1_m: 0.7026 - precision_m: 0.7228 - recall_m: 0.6857 - val_loss: 0.5859 - val_acc: 0.7127 - val_f1_m: 0.3136 - val_precision_m: 0.2036 - val_recall_m: 0.6889\n",
            "Epoch 926/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5774 - acc: 0.7055 - f1_m: 0.6959 - precision_m: 0.7079 - recall_m: 0.6850 - val_loss: 0.5891 - val_acc: 0.7112 - val_f1_m: 0.3132 - val_precision_m: 0.2032 - val_recall_m: 0.6909\n",
            "Epoch 927/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5774 - acc: 0.7063 - f1_m: 0.7020 - precision_m: 0.7066 - recall_m: 0.6981 - val_loss: 0.5906 - val_acc: 0.7100 - val_f1_m: 0.3129 - val_precision_m: 0.2027 - val_recall_m: 0.6929\n",
            "Epoch 928/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5773 - acc: 0.7061 - f1_m: 0.7060 - precision_m: 0.7100 - recall_m: 0.7023 - val_loss: 0.5890 - val_acc: 0.7112 - val_f1_m: 0.3139 - val_precision_m: 0.2036 - val_recall_m: 0.6929\n",
            "Epoch 929/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5773 - acc: 0.7057 - f1_m: 0.7034 - precision_m: 0.7106 - recall_m: 0.6969 - val_loss: 0.5862 - val_acc: 0.7127 - val_f1_m: 0.3136 - val_precision_m: 0.2036 - val_recall_m: 0.6889\n",
            "Epoch 930/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5773 - acc: 0.7065 - f1_m: 0.7018 - precision_m: 0.7101 - recall_m: 0.6940 - val_loss: 0.5849 - val_acc: 0.7133 - val_f1_m: 0.3140 - val_precision_m: 0.2040 - val_recall_m: 0.6889\n",
            "Epoch 931/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5773 - acc: 0.7073 - f1_m: 0.7029 - precision_m: 0.7141 - recall_m: 0.6927 - val_loss: 0.5835 - val_acc: 0.7135 - val_f1_m: 0.3128 - val_precision_m: 0.2034 - val_recall_m: 0.6846\n",
            "Epoch 932/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5773 - acc: 0.7083 - f1_m: 0.7012 - precision_m: 0.7121 - recall_m: 0.6908 - val_loss: 0.5823 - val_acc: 0.7140 - val_f1_m: 0.3131 - val_precision_m: 0.2036 - val_recall_m: 0.6846\n",
            "Epoch 933/1000\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.5773 - acc: 0.7083 - f1_m: 0.7022 - precision_m: 0.7106 - recall_m: 0.6952 - val_loss: 0.5831 - val_acc: 0.7135 - val_f1_m: 0.3128 - val_precision_m: 0.2034 - val_recall_m: 0.6846\n",
            "Epoch 934/1000\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.5773 - acc: 0.7085 - f1_m: 0.7059 - precision_m: 0.7166 - recall_m: 0.6957 - val_loss: 0.5829 - val_acc: 0.7137 - val_f1_m: 0.3130 - val_precision_m: 0.2035 - val_recall_m: 0.6846\n",
            "Epoch 935/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5772 - acc: 0.7081 - f1_m: 0.7052 - precision_m: 0.7153 - recall_m: 0.6957 - val_loss: 0.5836 - val_acc: 0.7133 - val_f1_m: 0.3127 - val_precision_m: 0.2032 - val_recall_m: 0.6846\n",
            "Epoch 936/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5772 - acc: 0.7067 - f1_m: 0.7078 - precision_m: 0.7147 - recall_m: 0.7020 - val_loss: 0.5863 - val_acc: 0.7123 - val_f1_m: 0.3133 - val_precision_m: 0.2033 - val_recall_m: 0.6889\n",
            "Epoch 937/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5772 - acc: 0.7067 - f1_m: 0.6963 - precision_m: 0.7072 - recall_m: 0.6861 - val_loss: 0.5866 - val_acc: 0.7123 - val_f1_m: 0.3133 - val_precision_m: 0.2033 - val_recall_m: 0.6889\n",
            "Epoch 938/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5772 - acc: 0.7063 - f1_m: 0.7053 - precision_m: 0.7113 - recall_m: 0.7000 - val_loss: 0.5878 - val_acc: 0.7117 - val_f1_m: 0.3128 - val_precision_m: 0.2030 - val_recall_m: 0.6889\n",
            "Epoch 939/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5771 - acc: 0.7065 - f1_m: 0.7070 - precision_m: 0.7204 - recall_m: 0.6948 - val_loss: 0.5867 - val_acc: 0.7125 - val_f1_m: 0.3134 - val_precision_m: 0.2035 - val_recall_m: 0.6889\n",
            "Epoch 940/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5771 - acc: 0.7063 - f1_m: 0.7061 - precision_m: 0.7176 - recall_m: 0.6952 - val_loss: 0.5892 - val_acc: 0.7112 - val_f1_m: 0.3138 - val_precision_m: 0.2035 - val_recall_m: 0.6929\n",
            "Epoch 941/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5771 - acc: 0.7057 - f1_m: 0.7100 - precision_m: 0.7204 - recall_m: 0.7003 - val_loss: 0.5912 - val_acc: 0.7098 - val_f1_m: 0.3127 - val_precision_m: 0.2025 - val_recall_m: 0.6929\n",
            "Epoch 942/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5771 - acc: 0.7065 - f1_m: 0.7060 - precision_m: 0.7140 - recall_m: 0.6985 - val_loss: 0.5940 - val_acc: 0.7089 - val_f1_m: 0.3121 - val_precision_m: 0.2020 - val_recall_m: 0.6929\n",
            "Epoch 943/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5771 - acc: 0.7063 - f1_m: 0.7049 - precision_m: 0.7076 - recall_m: 0.7024 - val_loss: 0.5940 - val_acc: 0.7087 - val_f1_m: 0.3120 - val_precision_m: 0.2019 - val_recall_m: 0.6929\n",
            "Epoch 944/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5771 - acc: 0.7061 - f1_m: 0.7032 - precision_m: 0.7152 - recall_m: 0.6933 - val_loss: 0.5914 - val_acc: 0.7100 - val_f1_m: 0.3129 - val_precision_m: 0.2026 - val_recall_m: 0.6929\n",
            "Epoch 945/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5770 - acc: 0.7055 - f1_m: 0.7036 - precision_m: 0.7126 - recall_m: 0.6954 - val_loss: 0.5892 - val_acc: 0.7115 - val_f1_m: 0.3140 - val_precision_m: 0.2036 - val_recall_m: 0.6929\n",
            "Epoch 946/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5770 - acc: 0.7057 - f1_m: 0.6995 - precision_m: 0.7076 - recall_m: 0.6918 - val_loss: 0.5909 - val_acc: 0.7104 - val_f1_m: 0.3132 - val_precision_m: 0.2029 - val_recall_m: 0.6929\n",
            "Epoch 947/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5770 - acc: 0.7059 - f1_m: 0.6943 - precision_m: 0.6945 - recall_m: 0.6963 - val_loss: 0.5907 - val_acc: 0.7108 - val_f1_m: 0.3135 - val_precision_m: 0.2032 - val_recall_m: 0.6929\n",
            "Epoch 948/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5769 - acc: 0.7065 - f1_m: 0.7079 - precision_m: 0.7189 - recall_m: 0.6980 - val_loss: 0.5859 - val_acc: 0.7133 - val_f1_m: 0.3147 - val_precision_m: 0.2044 - val_recall_m: 0.6909\n",
            "Epoch 949/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5770 - acc: 0.7077 - f1_m: 0.7047 - precision_m: 0.7159 - recall_m: 0.6946 - val_loss: 0.5842 - val_acc: 0.7135 - val_f1_m: 0.3142 - val_precision_m: 0.2041 - val_recall_m: 0.6889\n",
            "Epoch 950/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5769 - acc: 0.7079 - f1_m: 0.7082 - precision_m: 0.7168 - recall_m: 0.7007 - val_loss: 0.5851 - val_acc: 0.7135 - val_f1_m: 0.3148 - val_precision_m: 0.2045 - val_recall_m: 0.6909\n",
            "Epoch 951/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5769 - acc: 0.7077 - f1_m: 0.6977 - precision_m: 0.7032 - recall_m: 0.6935 - val_loss: 0.5850 - val_acc: 0.7135 - val_f1_m: 0.3148 - val_precision_m: 0.2045 - val_recall_m: 0.6909\n",
            "Epoch 952/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5770 - acc: 0.7081 - f1_m: 0.7083 - precision_m: 0.7240 - recall_m: 0.6943 - val_loss: 0.5826 - val_acc: 0.7140 - val_f1_m: 0.3138 - val_precision_m: 0.2039 - val_recall_m: 0.6869\n",
            "Epoch 953/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5769 - acc: 0.7081 - f1_m: 0.6994 - precision_m: 0.7147 - recall_m: 0.6851 - val_loss: 0.5852 - val_acc: 0.7133 - val_f1_m: 0.3147 - val_precision_m: 0.2044 - val_recall_m: 0.6909\n",
            "Epoch 954/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5768 - acc: 0.7069 - f1_m: 0.7040 - precision_m: 0.7156 - recall_m: 0.6934 - val_loss: 0.5885 - val_acc: 0.7112 - val_f1_m: 0.3138 - val_precision_m: 0.2035 - val_recall_m: 0.6929\n",
            "Epoch 955/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5769 - acc: 0.7057 - f1_m: 0.6994 - precision_m: 0.7047 - recall_m: 0.6945 - val_loss: 0.5925 - val_acc: 0.7102 - val_f1_m: 0.3130 - val_precision_m: 0.2028 - val_recall_m: 0.6929\n",
            "Epoch 956/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5768 - acc: 0.7055 - f1_m: 0.6993 - precision_m: 0.7041 - recall_m: 0.6947 - val_loss: 0.5914 - val_acc: 0.7106 - val_f1_m: 0.3133 - val_precision_m: 0.2030 - val_recall_m: 0.6929\n",
            "Epoch 957/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5768 - acc: 0.7055 - f1_m: 0.7038 - precision_m: 0.7074 - recall_m: 0.7006 - val_loss: 0.5889 - val_acc: 0.7112 - val_f1_m: 0.3138 - val_precision_m: 0.2035 - val_recall_m: 0.6929\n",
            "Epoch 958/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5768 - acc: 0.7063 - f1_m: 0.6986 - precision_m: 0.7070 - recall_m: 0.6907 - val_loss: 0.5859 - val_acc: 0.7127 - val_f1_m: 0.3143 - val_precision_m: 0.2040 - val_recall_m: 0.6909\n",
            "Epoch 959/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5768 - acc: 0.7075 - f1_m: 0.7009 - precision_m: 0.7145 - recall_m: 0.6882 - val_loss: 0.5844 - val_acc: 0.7135 - val_f1_m: 0.3148 - val_precision_m: 0.2045 - val_recall_m: 0.6909\n",
            "Epoch 960/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5767 - acc: 0.7077 - f1_m: 0.7061 - precision_m: 0.7158 - recall_m: 0.6969 - val_loss: 0.5857 - val_acc: 0.7127 - val_f1_m: 0.3143 - val_precision_m: 0.2040 - val_recall_m: 0.6909\n",
            "Epoch 961/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5767 - acc: 0.7071 - f1_m: 0.7038 - precision_m: 0.7114 - recall_m: 0.6967 - val_loss: 0.5879 - val_acc: 0.7115 - val_f1_m: 0.3133 - val_precision_m: 0.2032 - val_recall_m: 0.6909\n",
            "Epoch 962/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5767 - acc: 0.7063 - f1_m: 0.7028 - precision_m: 0.7153 - recall_m: 0.6914 - val_loss: 0.5881 - val_acc: 0.7115 - val_f1_m: 0.3133 - val_precision_m: 0.2032 - val_recall_m: 0.6909\n",
            "Epoch 963/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5767 - acc: 0.7063 - f1_m: 0.7048 - precision_m: 0.7140 - recall_m: 0.6967 - val_loss: 0.5891 - val_acc: 0.7117 - val_f1_m: 0.3141 - val_precision_m: 0.2037 - val_recall_m: 0.6929\n",
            "Epoch 964/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5766 - acc: 0.7063 - f1_m: 0.6967 - precision_m: 0.7052 - recall_m: 0.6888 - val_loss: 0.5895 - val_acc: 0.7112 - val_f1_m: 0.3138 - val_precision_m: 0.2035 - val_recall_m: 0.6929\n",
            "Epoch 965/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5767 - acc: 0.7067 - f1_m: 0.6914 - precision_m: 0.6989 - recall_m: 0.6845 - val_loss: 0.5882 - val_acc: 0.7115 - val_f1_m: 0.3133 - val_precision_m: 0.2032 - val_recall_m: 0.6909\n",
            "Epoch 966/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5766 - acc: 0.7067 - f1_m: 0.7062 - precision_m: 0.7167 - recall_m: 0.6966 - val_loss: 0.5865 - val_acc: 0.7121 - val_f1_m: 0.3138 - val_precision_m: 0.2036 - val_recall_m: 0.6909\n",
            "Epoch 967/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5766 - acc: 0.7067 - f1_m: 0.7052 - precision_m: 0.7194 - recall_m: 0.6923 - val_loss: 0.5870 - val_acc: 0.7121 - val_f1_m: 0.3138 - val_precision_m: 0.2036 - val_recall_m: 0.6909\n",
            "Epoch 968/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5766 - acc: 0.7061 - f1_m: 0.7047 - precision_m: 0.7129 - recall_m: 0.6968 - val_loss: 0.5897 - val_acc: 0.7108 - val_f1_m: 0.3135 - val_precision_m: 0.2032 - val_recall_m: 0.6929\n",
            "Epoch 969/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5766 - acc: 0.7065 - f1_m: 0.7068 - precision_m: 0.7127 - recall_m: 0.7015 - val_loss: 0.5901 - val_acc: 0.7108 - val_f1_m: 0.3135 - val_precision_m: 0.2032 - val_recall_m: 0.6929\n",
            "Epoch 970/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5765 - acc: 0.7069 - f1_m: 0.6999 - precision_m: 0.7120 - recall_m: 0.6893 - val_loss: 0.5894 - val_acc: 0.7115 - val_f1_m: 0.3140 - val_precision_m: 0.2036 - val_recall_m: 0.6929\n",
            "Epoch 971/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5765 - acc: 0.7067 - f1_m: 0.7032 - precision_m: 0.7149 - recall_m: 0.6926 - val_loss: 0.5876 - val_acc: 0.7119 - val_f1_m: 0.3136 - val_precision_m: 0.2035 - val_recall_m: 0.6909\n",
            "Epoch 972/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5765 - acc: 0.7073 - f1_m: 0.7030 - precision_m: 0.7135 - recall_m: 0.6933 - val_loss: 0.5901 - val_acc: 0.7110 - val_f1_m: 0.3136 - val_precision_m: 0.2033 - val_recall_m: 0.6929\n",
            "Epoch 973/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5765 - acc: 0.7061 - f1_m: 0.7027 - precision_m: 0.7041 - recall_m: 0.7022 - val_loss: 0.5913 - val_acc: 0.7104 - val_f1_m: 0.3132 - val_precision_m: 0.2029 - val_recall_m: 0.6929\n",
            "Epoch 974/1000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5765 - acc: 0.7065 - f1_m: 0.7055 - precision_m: 0.7106 - recall_m: 0.7011 - val_loss: 0.5887 - val_acc: 0.7121 - val_f1_m: 0.3144 - val_precision_m: 0.2040 - val_recall_m: 0.6929\n",
            "Epoch 975/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5764 - acc: 0.7071 - f1_m: 0.6999 - precision_m: 0.7143 - recall_m: 0.6872 - val_loss: 0.5869 - val_acc: 0.7123 - val_f1_m: 0.3139 - val_precision_m: 0.2037 - val_recall_m: 0.6909\n",
            "Epoch 976/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5764 - acc: 0.7073 - f1_m: 0.7064 - precision_m: 0.7151 - recall_m: 0.6982 - val_loss: 0.5878 - val_acc: 0.7119 - val_f1_m: 0.3136 - val_precision_m: 0.2035 - val_recall_m: 0.6909\n",
            "Epoch 977/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5764 - acc: 0.7067 - f1_m: 0.7092 - precision_m: 0.7166 - recall_m: 0.7021 - val_loss: 0.5887 - val_acc: 0.7119 - val_f1_m: 0.3143 - val_precision_m: 0.2038 - val_recall_m: 0.6929\n",
            "Epoch 978/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5764 - acc: 0.7067 - f1_m: 0.7102 - precision_m: 0.7134 - recall_m: 0.7077 - val_loss: 0.5901 - val_acc: 0.7110 - val_f1_m: 0.3136 - val_precision_m: 0.2033 - val_recall_m: 0.6929\n",
            "Epoch 979/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5764 - acc: 0.7059 - f1_m: 0.7052 - precision_m: 0.7082 - recall_m: 0.7030 - val_loss: 0.5894 - val_acc: 0.7117 - val_f1_m: 0.3141 - val_precision_m: 0.2037 - val_recall_m: 0.6929\n",
            "Epoch 980/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5763 - acc: 0.7063 - f1_m: 0.7084 - precision_m: 0.7188 - recall_m: 0.6989 - val_loss: 0.5886 - val_acc: 0.7121 - val_f1_m: 0.3144 - val_precision_m: 0.2040 - val_recall_m: 0.6929\n",
            "Epoch 981/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5763 - acc: 0.7067 - f1_m: 0.7034 - precision_m: 0.7119 - recall_m: 0.6953 - val_loss: 0.5907 - val_acc: 0.7110 - val_f1_m: 0.3136 - val_precision_m: 0.2033 - val_recall_m: 0.6929\n",
            "Epoch 982/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5763 - acc: 0.7061 - f1_m: 0.7025 - precision_m: 0.7121 - recall_m: 0.6939 - val_loss: 0.5913 - val_acc: 0.7104 - val_f1_m: 0.3132 - val_precision_m: 0.2029 - val_recall_m: 0.6929\n",
            "Epoch 983/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5763 - acc: 0.7063 - f1_m: 0.7033 - precision_m: 0.7095 - recall_m: 0.6978 - val_loss: 0.5913 - val_acc: 0.7108 - val_f1_m: 0.3135 - val_precision_m: 0.2031 - val_recall_m: 0.6929\n",
            "Epoch 984/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5763 - acc: 0.7061 - f1_m: 0.7061 - precision_m: 0.7122 - recall_m: 0.7010 - val_loss: 0.5904 - val_acc: 0.7112 - val_f1_m: 0.3138 - val_precision_m: 0.2034 - val_recall_m: 0.6929\n",
            "Epoch 985/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5763 - acc: 0.7065 - f1_m: 0.7068 - precision_m: 0.7128 - recall_m: 0.7011 - val_loss: 0.5900 - val_acc: 0.7115 - val_f1_m: 0.3139 - val_precision_m: 0.2035 - val_recall_m: 0.6929\n",
            "Epoch 986/1000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5762 - acc: 0.7065 - f1_m: 0.7034 - precision_m: 0.7129 - recall_m: 0.6949 - val_loss: 0.5890 - val_acc: 0.7117 - val_f1_m: 0.3141 - val_precision_m: 0.2037 - val_recall_m: 0.6929\n",
            "Epoch 987/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5762 - acc: 0.7065 - f1_m: 0.7015 - precision_m: 0.7125 - recall_m: 0.6915 - val_loss: 0.5880 - val_acc: 0.7123 - val_f1_m: 0.3139 - val_precision_m: 0.2037 - val_recall_m: 0.6909\n",
            "Epoch 988/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5762 - acc: 0.7069 - f1_m: 0.6940 - precision_m: 0.7004 - recall_m: 0.6882 - val_loss: 0.5888 - val_acc: 0.7117 - val_f1_m: 0.3141 - val_precision_m: 0.2037 - val_recall_m: 0.6929\n",
            "Epoch 989/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5762 - acc: 0.7071 - f1_m: 0.6987 - precision_m: 0.7050 - recall_m: 0.6930 - val_loss: 0.5870 - val_acc: 0.7125 - val_f1_m: 0.3141 - val_precision_m: 0.2039 - val_recall_m: 0.6909\n",
            "Epoch 990/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5761 - acc: 0.7077 - f1_m: 0.7024 - precision_m: 0.7138 - recall_m: 0.6916 - val_loss: 0.5845 - val_acc: 0.7127 - val_f1_m: 0.3142 - val_precision_m: 0.2040 - val_recall_m: 0.6909\n",
            "Epoch 991/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5762 - acc: 0.7085 - f1_m: 0.6996 - precision_m: 0.7159 - recall_m: 0.6851 - val_loss: 0.5830 - val_acc: 0.7140 - val_f1_m: 0.3145 - val_precision_m: 0.2043 - val_recall_m: 0.6889\n",
            "Epoch 992/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5761 - acc: 0.7087 - f1_m: 0.7049 - precision_m: 0.7106 - recall_m: 0.7009 - val_loss: 0.5841 - val_acc: 0.7135 - val_f1_m: 0.3148 - val_precision_m: 0.2045 - val_recall_m: 0.6909\n",
            "Epoch 993/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5761 - acc: 0.7091 - f1_m: 0.7051 - precision_m: 0.7231 - recall_m: 0.6892 - val_loss: 0.5815 - val_acc: 0.7144 - val_f1_m: 0.3148 - val_precision_m: 0.2047 - val_recall_m: 0.6889\n",
            "Epoch 994/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5761 - acc: 0.7091 - f1_m: 0.7038 - precision_m: 0.7207 - recall_m: 0.6885 - val_loss: 0.5851 - val_acc: 0.7125 - val_f1_m: 0.3141 - val_precision_m: 0.2039 - val_recall_m: 0.6909\n",
            "Epoch 995/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5761 - acc: 0.7073 - f1_m: 0.7023 - precision_m: 0.7069 - recall_m: 0.6985 - val_loss: 0.5904 - val_acc: 0.7115 - val_f1_m: 0.3139 - val_precision_m: 0.2035 - val_recall_m: 0.6929\n",
            "Epoch 996/1000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.5761 - acc: 0.7065 - f1_m: 0.7073 - precision_m: 0.7102 - recall_m: 0.7051 - val_loss: 0.5903 - val_acc: 0.7115 - val_f1_m: 0.3139 - val_precision_m: 0.2035 - val_recall_m: 0.6929\n",
            "Epoch 997/1000\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.5760 - acc: 0.7067 - f1_m: 0.7044 - precision_m: 0.7094 - recall_m: 0.6996 - val_loss: 0.5899 - val_acc: 0.7115 - val_f1_m: 0.3139 - val_precision_m: 0.2035 - val_recall_m: 0.6929\n",
            "Epoch 998/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5760 - acc: 0.7069 - f1_m: 0.7093 - precision_m: 0.7205 - recall_m: 0.6996 - val_loss: 0.5897 - val_acc: 0.7115 - val_f1_m: 0.3139 - val_precision_m: 0.2035 - val_recall_m: 0.6929\n",
            "Epoch 999/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5760 - acc: 0.7067 - f1_m: 0.7034 - precision_m: 0.7116 - recall_m: 0.6956 - val_loss: 0.5907 - val_acc: 0.7110 - val_f1_m: 0.3136 - val_precision_m: 0.2032 - val_recall_m: 0.6929\n",
            "Epoch 1000/1000\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.5760 - acc: 0.7063 - f1_m: 0.7094 - precision_m: 0.7088 - recall_m: 0.7115 - val_loss: 0.5918 - val_acc: 0.7102 - val_f1_m: 0.3130 - val_precision_m: 0.2028 - val_recall_m: 0.6929\n",
            "loss=nan  accuracy=0.692  F1-score=nan  Precision=nan  Recall=nan\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f67075f4f687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# plot learning curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1_m'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall_m'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'precision_m'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CVD Basic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utilities.py\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(history, measures)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \"\"\"\n\u001b[1;32m    191\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpanels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = utilities.process_features(df, 'CVD', QuantileTransformer(output_distribution='uniform'), one_hot=True)\n",
        "X_train, y_train= utilities.resample_data(X_train, y_train, 'under')\n",
        "    \n",
        "# evaluate model with a given number of nodes\n",
        "history, result = mlp_model( X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation='gelu',opt=Adam, lr=0.000001)\n",
        "\n",
        "# summarize final test set accuracy\n",
        "print('loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (result[0], result[1], result[2], result[3], result[4]))\n",
        "\n",
        "# plot learning curves\n",
        "utilities.plot_history(history, ['acc', 'f1_m', 'recall_m' ,'precision_m'])\n",
        "plt.suptitle('CVD Basic')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['recall_m']"
      ],
      "metadata": {
        "id": "7BBRjgEtmIPp",
        "outputId": "0eae6dc1-6edd-40d0-a550-e79b3ca3b443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7BBRjgEtmIPp",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7527537941932678,\n",
              " 0.7433106303215027,\n",
              " 0.7566922903060913,\n",
              " 0.7461205720901489,\n",
              " 0.7307217121124268,\n",
              " 0.7319322228431702,\n",
              " 0.7163892984390259,\n",
              " 0.732787549495697,\n",
              " 0.7291476726531982,\n",
              " 0.7332759499549866,\n",
              " 0.7397046685218811,\n",
              " 0.7410196661949158,\n",
              " 0.7422518134117126,\n",
              " 0.7254469394683838,\n",
              " 0.7318738102912903,\n",
              " 0.7452773451805115,\n",
              " 0.7436651587486267,\n",
              " 0.7283495664596558,\n",
              " 0.7212789058685303,\n",
              " 0.7116029262542725,\n",
              " 0.7151219844818115,\n",
              " 0.7170182466506958,\n",
              " 0.720961332321167,\n",
              " 0.7168580293655396,\n",
              " 0.7044721245765686,\n",
              " 0.6899634599685669,\n",
              " 0.6897028684616089,\n",
              " 0.6914255619049072,\n",
              " 0.6983641386032104,\n",
              " 0.7091034650802612,\n",
              " 0.7023743987083435,\n",
              " 0.6956177949905396,\n",
              " 0.7038167119026184,\n",
              " 0.6921106576919556,\n",
              " 0.6864302754402161,\n",
              " 0.6815353631973267,\n",
              " 0.681868851184845,\n",
              " 0.6854514479637146,\n",
              " 0.6833369135856628,\n",
              " 0.6793941259384155,\n",
              " 0.6880921721458435,\n",
              " 0.6858218312263489,\n",
              " 0.6814174056053162,\n",
              " 0.673966109752655,\n",
              " 0.6764265298843384,\n",
              " 0.6738480925559998,\n",
              " 0.676987886428833,\n",
              " 0.6795435547828674,\n",
              " 0.6780948042869568,\n",
              " 0.6782015562057495,\n",
              " 0.6768122911453247,\n",
              " 0.6801227927207947,\n",
              " 0.6680079102516174,\n",
              " 0.6556441783905029,\n",
              " 0.6548702716827393,\n",
              " 0.6590375304222107,\n",
              " 0.6539071798324585,\n",
              " 0.6653532385826111,\n",
              " 0.6616697907447815,\n",
              " 0.6580994129180908,\n",
              " 0.6525599956512451,\n",
              " 0.6562108993530273,\n",
              " 0.6555353999137878,\n",
              " 0.65761798620224,\n",
              " 0.6628720760345459,\n",
              " 0.6509934663772583,\n",
              " 0.6531649231910706,\n",
              " 0.6457967758178711,\n",
              " 0.6526583433151245,\n",
              " 0.6526486277580261,\n",
              " 0.6494616270065308,\n",
              " 0.6453055739402771,\n",
              " 0.6501783728599548,\n",
              " 0.6575488448143005,\n",
              " 0.6560856699943542,\n",
              " 0.6533991098403931,\n",
              " 0.660965621471405,\n",
              " 0.6564261317253113,\n",
              " 0.6529977321624756,\n",
              " 0.6538079977035522,\n",
              " 0.6546878814697266,\n",
              " 0.6481387615203857,\n",
              " 0.6506770253181458,\n",
              " 0.6537556052207947,\n",
              " 0.6556756496429443,\n",
              " 0.6542890071868896,\n",
              " 0.656139075756073,\n",
              " 0.6556769013404846,\n",
              " 0.6559422612190247,\n",
              " 0.6550959348678589,\n",
              " 0.6493256688117981,\n",
              " 0.6513136625289917,\n",
              " 0.6497563719749451,\n",
              " 0.648743212223053,\n",
              " 0.652851402759552,\n",
              " 0.6546263098716736,\n",
              " 0.6486352682113647,\n",
              " 0.6470655798912048,\n",
              " 0.6499338746070862,\n",
              " 0.6569300889968872,\n",
              " 0.6531378626823425,\n",
              " 0.6531153321266174,\n",
              " 0.6576869487762451,\n",
              " 0.6532354950904846,\n",
              " 0.6512063145637512,\n",
              " 0.6529062986373901,\n",
              " 0.6539885401725769,\n",
              " 0.6529789566993713,\n",
              " 0.6508832573890686,\n",
              " 0.6550686359405518,\n",
              " 0.6557150483131409,\n",
              " 0.6511682271957397,\n",
              " 0.650738000869751,\n",
              " 0.6516926288604736,\n",
              " 0.6554747223854065,\n",
              " 0.6541171669960022,\n",
              " 0.6603307723999023,\n",
              " 0.6595755815505981,\n",
              " 0.6523621082305908,\n",
              " 0.6546487212181091,\n",
              " 0.6547906398773193,\n",
              " 0.6511499881744385,\n",
              " 0.6474460959434509,\n",
              " 0.6495321989059448,\n",
              " 0.6549990177154541,\n",
              " 0.6523371338844299,\n",
              " 0.652362585067749,\n",
              " 0.6556044220924377,\n",
              " 0.6561025381088257,\n",
              " 0.6533574461936951,\n",
              " 0.6560242176055908,\n",
              " 0.652867317199707,\n",
              " 0.6524046659469604,\n",
              " 0.6556853652000427,\n",
              " 0.6586059331893921,\n",
              " 0.6466187834739685,\n",
              " 0.658247709274292,\n",
              " 0.6560021638870239,\n",
              " 0.6548662185668945,\n",
              " 0.6555763483047485,\n",
              " 0.6565386652946472,\n",
              " 0.663285493850708,\n",
              " 0.6681875586509705,\n",
              " 0.6594860553741455,\n",
              " 0.6596167087554932,\n",
              " 0.6602760553359985,\n",
              " 0.6606053709983826,\n",
              " 0.6600722670555115,\n",
              " 0.6622375845909119,\n",
              " 0.6600125432014465,\n",
              " 0.6613327860832214,\n",
              " 0.661343514919281,\n",
              " 0.6595357656478882,\n",
              " 0.6622374653816223,\n",
              " 0.6564298868179321,\n",
              " 0.6519909501075745,\n",
              " 0.6568760275840759,\n",
              " 0.6633604764938354,\n",
              " 0.6562087535858154,\n",
              " 0.659142792224884,\n",
              " 0.6549373269081116,\n",
              " 0.6575765013694763,\n",
              " 0.6624674201011658,\n",
              " 0.6600629091262817,\n",
              " 0.6629912257194519,\n",
              " 0.6639338135719299,\n",
              " 0.6638075113296509,\n",
              " 0.6591593027114868,\n",
              " 0.6619175672531128,\n",
              " 0.6651411056518555,\n",
              " 0.6633711457252502,\n",
              " 0.6621800661087036,\n",
              " 0.6565102934837341,\n",
              " 0.6628021597862244,\n",
              " 0.6618074178695679,\n",
              " 0.6643584966659546,\n",
              " 0.6601662039756775,\n",
              " 0.6607490181922913,\n",
              " 0.6624410152435303,\n",
              " 0.6665388941764832,\n",
              " 0.6669896245002747,\n",
              " 0.6620670557022095,\n",
              " 0.655811607837677,\n",
              " 0.6662956476211548,\n",
              " 0.6698184609413147,\n",
              " 0.665867269039154,\n",
              " 0.6680673956871033,\n",
              " 0.6684945821762085,\n",
              " 0.6659936308860779,\n",
              " 0.6672242879867554,\n",
              " 0.6713536977767944,\n",
              " 0.6705998182296753,\n",
              " 0.6751972436904907,\n",
              " 0.6686664819717407,\n",
              " 0.670873761177063,\n",
              " 0.6707674860954285,\n",
              " 0.672420084476471,\n",
              " 0.670160174369812,\n",
              " 0.6750520467758179,\n",
              " 0.672803521156311,\n",
              " 0.6720495223999023,\n",
              " 0.672226071357727,\n",
              " 0.6705838441848755,\n",
              " 0.670036256313324,\n",
              " 0.6719105243682861,\n",
              " 0.6719738245010376,\n",
              " 0.6701940894126892,\n",
              " 0.6696024537086487,\n",
              " 0.6724821925163269,\n",
              " 0.6755829453468323,\n",
              " 0.6789610385894775,\n",
              " 0.6768863201141357,\n",
              " 0.6723899245262146,\n",
              " 0.6767700910568237,\n",
              " 0.6742481589317322,\n",
              " 0.6727129220962524,\n",
              " 0.6761271357536316,\n",
              " 0.6743824481964111,\n",
              " 0.677130401134491,\n",
              " 0.6765662431716919,\n",
              " 0.6761443614959717,\n",
              " 0.6757460236549377,\n",
              " 0.6756903529167175,\n",
              " 0.669796347618103,\n",
              " 0.6735230684280396,\n",
              " 0.6781481504440308,\n",
              " 0.6729539632797241,\n",
              " 0.6765177249908447,\n",
              " 0.6790787577629089,\n",
              " 0.6751327514648438,\n",
              " 0.6710296273231506,\n",
              " 0.6731756925582886,\n",
              " 0.6728455424308777,\n",
              " 0.6811408400535583,\n",
              " 0.6789156794548035,\n",
              " 0.6778411865234375,\n",
              " 0.6710951328277588,\n",
              " 0.6743606925010681,\n",
              " 0.6846663355827332,\n",
              " 0.6760806441307068,\n",
              " 0.6755958199501038,\n",
              " 0.675381600856781,\n",
              " 0.6821072101593018,\n",
              " 0.6801037192344666,\n",
              " 0.674462080001831,\n",
              " 0.6761963367462158,\n",
              " 0.6757237315177917,\n",
              " 0.6831986904144287,\n",
              " 0.6849749088287354,\n",
              " 0.6790210008621216,\n",
              " 0.6779698729515076,\n",
              " 0.6727256774902344,\n",
              " 0.6814610362052917,\n",
              " 0.6796900629997253,\n",
              " 0.6780639886856079,\n",
              " 0.6779499650001526,\n",
              " 0.6816867589950562,\n",
              " 0.6806824207305908,\n",
              " 0.6746398210525513,\n",
              " 0.6740933656692505,\n",
              " 0.6774058938026428,\n",
              " 0.6792153716087341,\n",
              " 0.6709809899330139,\n",
              " 0.6719269156455994,\n",
              " 0.6777763962745667,\n",
              " 0.6745849251747131,\n",
              " 0.6761806011199951,\n",
              " 0.6790006160736084,\n",
              " 0.6820997595787048,\n",
              " 0.6759589910507202,\n",
              " 0.6779407262802124,\n",
              " 0.6800408959388733,\n",
              " 0.6785604953765869,\n",
              " 0.6741319894790649,\n",
              " 0.6769415140151978,\n",
              " 0.6796306371688843,\n",
              " 0.6767734289169312,\n",
              " 0.6781208515167236,\n",
              " 0.6777368187904358,\n",
              " 0.6818123459815979,\n",
              " 0.6822065114974976,\n",
              " 0.6756950616836548,\n",
              " 0.6769307255744934,\n",
              " 0.6756260991096497,\n",
              " 0.6834989190101624,\n",
              " 0.6791925430297852,\n",
              " 0.6794757843017578,\n",
              " 0.6774262189865112,\n",
              " 0.676345705986023,\n",
              " 0.6792958378791809,\n",
              " 0.683455765247345,\n",
              " 0.6813263297080994,\n",
              " 0.6806671619415283,\n",
              " 0.6846402287483215,\n",
              " 0.6845425963401794,\n",
              " 0.6809847950935364,\n",
              " 0.6765331625938416,\n",
              " 0.6791414022445679,\n",
              " 0.675665557384491,\n",
              " 0.6800363063812256]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "656f0e9e",
      "metadata": {
        "id": "656f0e9e"
      },
      "outputs": [],
      "source": [
        "# Test numerical transformers\n",
        "save_history = pd.DataFrame()\n",
        "for param in num_transformers:\n",
        "    \n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = utilities.process_features(df, 'outcome_arrhythmia', param, one_hot=True)\n",
        "    X_train, y_train= utilities.resample_data(X_train, y_train, 'under')\n",
        "    \n",
        "    # evaluate model with a given number of nodes\n",
        "    history, result = mlp_model( X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation='tanh',opt=SGD, lr=0.000001)\n",
        "    save_history['loss_'+str(n_nodes)]=history.history[\"loss\"]\n",
        "    save_history['acc_'+str(n_nodes)]=history.history[\"acc\"]\n",
        "    save_history['f1'+str(n_nodes)]=history.history[\"f1_m\"]\n",
        "    save_history['recall'+str(n_nodes)]=history.history[\"recall_m\"]\n",
        "\n",
        "\n",
        "    # summarize final test set accuracy\n",
        "    print('loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (result[0], result[1], result[2], result[3], result[4]))\n",
        "    \n",
        "    # plot learning curves\n",
        "    utilities.plot_history(history)\n",
        "    plt.suptitle(str(param))\n",
        "\n",
        "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "404a7317",
      "metadata": {
        "id": "404a7317"
      },
      "outputs": [],
      "source": [
        "# Test sample methods\n",
        "save_history = pd.DataFrame()\n",
        "for param in sample_methods:\n",
        "    \n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = utilities.process_features(df, 'outcome_arrhythmia')\n",
        "    X_train, y_train= utilities.resample_data(X_train, y_train, param)\n",
        "    \n",
        "    # evaluate model with a given number of nodes\n",
        "    history, result = mlp_model(X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch,opt=SGD, lr=0.000001)\n",
        "    save_history['loss_'+str(n_nodes)]=history.history[\"loss\"]\n",
        "    save_history['acc_'+str(n_nodes)]=history.history[\"acc\"]\n",
        "    save_history['f1'+str(n_nodes)]=history.history[\"f1_m\"]\n",
        "    save_history['recall'+str(n_nodes)]=history.history[\"recall_m\"]\n",
        "\n",
        "\n",
        "    # summarize final test set accuracy\n",
        "    print('nodes=%d  loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (n_nodes, result[0], result[1], result[2], result[3], result[4]))\n",
        "    \n",
        "    # plot learning curves\n",
        "    utilities.plot_history(history)\n",
        "    plt.suptitle(str(param))\n",
        "\n",
        "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f84752a4",
      "metadata": {
        "id": "f84752a4"
      },
      "outputs": [],
      "source": [
        "# Test activations\n",
        "activations = ['tanh']\n",
        "save_history = pd.DataFrame()\n",
        "for param in activations:\n",
        "    \n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = utilities.process_features(df, 'outcome_arrhythmia')\n",
        "    X_train, y_train= utilities.resample_data(X_train, y_train, 'under')\n",
        "    \n",
        "    # evaluate model with a given number of nodes\n",
        "    history, result = mlp_model(X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation=param,opt=SGD, lr=0.0001) #lr = 0.0002\n",
        "    save_history['loss_']=history.history[\"loss\"]\n",
        "    save_history['acc_']=history.history[\"acc\"]\n",
        "    save_history['f1']=history.history[\"f1_m\"]\n",
        "    save_history['recall']=history.history[\"recall_m\"]\n",
        "\n",
        "\n",
        "    # summarize final test set accuracy\n",
        "    print('nodes=%d  loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (n_nodes, result[0], result[1], result[2], result[3], result[4]))\n",
        "    \n",
        "    # plot learning curves\n",
        "    utilities.plot_history(history)\n",
        "    plt.suptitle(str(param))\n",
        "\n",
        "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "580a1880",
      "metadata": {
        "id": "580a1880"
      },
      "outputs": [],
      "source": [
        "# Test optimizers\n",
        "\n",
        "optimizers =[Adam]\n",
        "save_history = pd.DataFrame()\n",
        "for param in optimizers:\n",
        "    \n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = utilities.process_features(df, 'outcome_arrhythmia')\n",
        "    X_train, y_train= utilities.resample_data(X_train, y_train, 'under')\n",
        "    \n",
        "    # evaluate model with a given number of nodes\n",
        "    history, result = mlp_model(X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation='tanh',opt=param, lr=0.000002)\n",
        "    save_history['loss_']=history.history[\"loss\"]\n",
        "    save_history['acc_']=history.history[\"acc\"]\n",
        "    save_history['f1']=history.history[\"f1_m\"]\n",
        "    save_history['recall']=history.history[\"recall_m\"]\n",
        "\n",
        "\n",
        "    # summarize final test set accuracy\n",
        "    print('loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (result[0], result[1], result[2], result[3], result[4]))\n",
        "    \n",
        "    # plot learning curves\n",
        "    utilities.plot_history(history)\n",
        "    plt.suptitle(str(param))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i5FnEICHArGz",
      "metadata": {
        "id": "i5FnEICHArGz"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m-XAdsqrw8HZ",
      "metadata": {
        "id": "m-XAdsqrw8HZ"
      },
      "source": [
        "#### Learning Rate Schedulers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zNwMETydw7Ay",
      "metadata": {
        "id": "zNwMETydw7Ay"
      },
      "outputs": [],
      "source": [
        "# learning rate schedule\n",
        "def step_decay(epoch):\n",
        "    initial_lrate = 0.1\n",
        "    drop = 0.5\n",
        "    epochs_drop = 10.0\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    return lrate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dAaElnGDpvzg",
      "metadata": {
        "id": "dAaElnGDpvzg"
      },
      "outputs": [],
      "source": [
        "# Test opt opt params\n",
        "\n",
        "learning_rates = [1e-3, 1e-4, 1e-6, some_changing_thing()]\n",
        "beta1, beta2 = [1,2,3,4], [1,2,3,4]\n",
        "save_history = pd.DataFrame()\n",
        "for param in optimizers:\n",
        "    \n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = process_features(df, 'outcome_arrhythmia', QuantileTransformer(output_distribution='uniform'), one_hot=True)\n",
        "    X_train, y_train= resample_data(X_train, y_train, 'under')\n",
        "    \n",
        "    # evaluate model with a given number of nodes\n",
        "    history, result = basic_model(n_nodes, X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation='relu',opt=param, lr=0.000001)\n",
        "    save_history['loss_'+str(n_nodes)]=history.history[\"loss\"]\n",
        "    save_history['acc_'+str(n_nodes)]=history.history[\"acc\"]\n",
        "    save_history['f1'+str(n_nodes)]=history.history[\"f1_m\"]\n",
        "    save_history['recall'+str(n_nodes)]=history.history[\"recall_m\"]\n",
        "\n",
        "\n",
        "    # summarize final test set accuracy\n",
        "    print('nodes=%d  loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (n_nodes, result[0], result[1], result[2], result[3], result[4]))\n",
        "    \n",
        "    # plot learning curves\n",
        "    plot_history(history)\n",
        "    plt.suptitle(str(param))\n",
        "\n",
        "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7132839",
      "metadata": {
        "id": "b7132839"
      },
      "source": [
        "### Build MLP Model with Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32f78ee8",
      "metadata": {
        "id": "32f78ee8"
      },
      "outputs": [],
      "source": [
        "def build_categorical_inputs(features):\n",
        "\n",
        "    initial_inputs = {}\n",
        "    cat_input_layers={}\n",
        "    \n",
        "    train_test_cat_features = pd.concat([X_train[categorical_cols], X_test[categorical_cols]])\n",
        "    \n",
        "    for feature in features:\n",
        "        no_of_unique_cats  = train_test_cat_features[feature].nunique()\n",
        "        embedding_size = int(min(np.ceil((no_of_unique_cats)/2), 50))\n",
        "        categories  = no_of_unique_cats + 1\n",
        "\n",
        "        initial_inputs[feature] = Input(shape=(1,))\n",
        "        embedding_layer = Embedding(categories, \n",
        "                                    embedding_size,\n",
        "                                    embeddings_regularizer=regularizers.l2(0.01),\n",
        "                                    input_length=1)(initial_inputs[feature])\n",
        "        cat_input_layers[feature] = Reshape(target_shape=(embedding_size,))(embedding_layer)\n",
        "\n",
        "    return initial_inputs, cat_input_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58a231b6",
      "metadata": {
        "id": "58a231b6"
      },
      "outputs": [],
      "source": [
        "def build_model( X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch):\n",
        "    \n",
        "    models = []\n",
        "    for categorical_var in categorical_cols :\n",
        "        model = Sequential()\n",
        "        no_of_unique_cat  = X_train[categorical_var].nunique()\n",
        "        embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
        "        embedding_size = int(embedding_size)\n",
        "        vocab  = no_of_unique_cat+1\n",
        "        model.add( Embedding(vocab ,embedding_size, input_length = 1 ))\n",
        "        model.add(Reshape(target_shape=(embedding_size,)))\n",
        "        models.append( model )\n",
        "        \n",
        "    model_rest = Sequential()\n",
        "    model_rest.add(Dense(16, input_dim= X_train[numerical_cols+continuous_cols].shape[1]))\n",
        "    models.append(model_rest)\n",
        "\n",
        "    full_model = Sequential()\n",
        "    full_model.add(Concatenate(models))\n",
        "    full_model.add(Dense(1000))\n",
        "    full_model.add(Activation('relu'))\n",
        "    full_model.add(Dense(400))\n",
        "    full_model.add(Activation('relu'))\n",
        "    full_model.add(Dense(1))\n",
        "    full_model.add(Activation('sigmoid'))\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=Adam(learning_rate=0.000001),\n",
        "        metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "    # fit model on train set\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=batch,\n",
        "        epochs=epochs,\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        validation_data=(X_val, y_val),\n",
        "    )\n",
        "    score = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return history, score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7df20d86",
      "metadata": {
        "id": "7df20d86"
      },
      "outputs": [],
      "source": [
        "def build_model( X_train, X_val, X_test ,y_train, y_val, y_test, epochs, batch):\n",
        "    \n",
        "    # define model\n",
        "    model = Sequential()\n",
        "    for col in categorical_cols:\n",
        "        no_of_unique_cat  = X_train[col].nunique()\n",
        "        embedding_size = min(np.ceil((no_of_unique_cat)/2), 50)\n",
        "        embedding_size = int(embedding_size)\n",
        "        vocab  = no_of_unique_cat+1\n",
        "        model.add(Embedding(input_dim=no_of_unique_cat, output_dim=embedding_size, input_shape=(X_train.shape[1],)))\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(50, activation=tf.keras.activations.gelu ))\n",
        "    model.add(Dense(1, activation=tf.nn.sigmoid))\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=Adam(learning_rate=0.000001),\n",
        "        metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "    # fit model on train set\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=batch,\n",
        "        epochs=epochs,\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        validation_data=(X_val, y_val),\n",
        "    )\n",
        "    score = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return history, score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7504bd9e",
      "metadata": {
        "id": "7504bd9e"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = process_features(df, 'outcome_arrhythmia', QuantileTransformer(output_distribution='uniform'), one_hot=False)\n",
        "X_train, y_train= resample_data(X_train, y_train, 'under')\n",
        "model=build_model(X_train, X_val, X_test ,y_train, y_val, y_test, 400, 600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fac49e1",
      "metadata": {
        "id": "1fac49e1"
      },
      "outputs": [],
      "source": [
        "initial_inputs, input_layers = build_categorical_inputs(categorical_cols)\n",
        "\n",
        "no_of_num_features = len(X_train.columns) - len(categorical_cols)\n",
        "\n",
        "initial_inputs['numerical_features'] = Input(shape=(no_of_num_features,))\n",
        "input_layers['numerical_features'] = initial_inputs['numerical_features']\n",
        "\n",
        "inputs = Concatenate(axis=-1)([layer for layer in input_layers.values()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40ccdade",
      "metadata": {
        "id": "40ccdade"
      },
      "outputs": [],
      "source": [
        "models = []\n",
        "\n",
        "model_rest = Sequential()\n",
        "model_rest.add(Dense(100, input_dim= len(numerical_cols+continuous_cols) ))\n",
        "models.append(model_rest)\n",
        "\n",
        "for categorical_var in categorical_cols :\n",
        "     \n",
        "    model = Sequential()\n",
        "    no_of_unique_cat  = X_train[categorical_var].nunique()\n",
        "    \n",
        "    # jeremy howard rule\n",
        "    embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
        "    embedding_size = int(embedding_size)\n",
        "    vocab  = no_of_unique_cat+1\n",
        "    model.add( Embedding(vocab ,embedding_size, input_length = 1 ))\n",
        "    model.add(Reshape(target_shape=(embedding_size,)))\n",
        "    models.append( model )\n",
        "\n",
        "\n",
        "    full_model = Sequential()\n",
        "    full_model.add(Concatenate(models))\n",
        "    full_model.add(Dense(1000))\n",
        "    full_model.add(Activation('relu'))\n",
        "    full_model.add(Dense(400))\n",
        "    full_model.add(Activation('relu'))\n",
        "    full_model.add(Dense(200))\n",
        "    full_model.add(Activation('sigmoid'))\n",
        "    full_model.add(Dense(1))\n",
        "    full_model.add(Activation('sigmoid'))\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.000001)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['acc',f1_m,precision_m, recall_m])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "987f57a0",
      "metadata": {
        "id": "987f57a0"
      },
      "outputs": [],
      "source": [
        "batch=1000\n",
        "epochs=100\n",
        "# fit model on train set\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=batch,\n",
        "    epochs=epochs,\n",
        "#     shuffle=True,\n",
        "    verbose=1,\n",
        "    validation_data=(X_val, y_val),\n",
        ")\n",
        "score = model.evaluate(X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a0276b8",
      "metadata": {
        "id": "6a0276b8"
      },
      "source": [
        "### K-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "436b62e0",
      "metadata": {
        "id": "436b62e0"
      },
      "outputs": [],
      "source": [
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((input_train, input_test), axis=0)\n",
        "targets = np.concatenate((target_train, target_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "    # Define the model architecture\n",
        "    full_model = Sequential()\n",
        "    full_model.add(Concatenate(models))\n",
        "    full_model.add(Dense(1000))\n",
        "    full_model.add(Activation('relu'))\n",
        "    full_model.add(Dense(400))\n",
        "    full_model.add(Activation('relu'))\n",
        "    full_model.add(Dense(200))\n",
        "    full_model.add(Activation('sigmoid'))\n",
        "    full_model.add(Dense(1))\n",
        "    full_model.add(Activation('sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=loss_function,\n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    # Generate a print\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "    # Fit data to model\n",
        "    history = model.fit(inputs[train], targets[train],\n",
        "              batch_size=batch_size,\n",
        "              epochs=no_epochs,\n",
        "              verbose=verbosity)\n",
        "\n",
        "    # Generate generalization metrics\n",
        "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "779c9624",
      "metadata": {
        "id": "779c9624"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00dd4df5",
      "metadata": {
        "id": "00dd4df5"
      },
      "outputs": [],
      "source": [
        "Model.save(\n",
        "    saved_models/'model_'+str(num)+'.h5',\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format=None,\n",
        "    signatures=None,\n",
        "    options=None,\n",
        "    save_traces=True,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "name": "02-basic_model.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}