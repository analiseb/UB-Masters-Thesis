{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0f0353",
   "metadata": {
    "id": "9d0f0353"
   },
   "outputs": [],
   "source": [
    "# Importing core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import pprint\n",
    "import joblib\n",
    "import global_variables as gv\n",
    "import utilities\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Data transformation pipelines\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import QuantileTransformer, RobustScaler, StandardScaler,MinMaxScaler\n",
    "\n",
    "# Graphics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88b1262",
   "metadata": {
    "id": "d88b1262"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, PReLU\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers  import Adam, Adagrad, SGD\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440b3c88",
   "metadata": {
    "id": "440b3c88"
   },
   "outputs": [],
   "source": [
    "# Importing from Scikit-Learn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "\n",
    "from keras.layers import Input, Embedding, Reshape, GlobalAveragePooling1D\n",
    "from keras.layers import Flatten, concatenate, Concatenate, Lambda, Dropout, SpatialDropout1D\n",
    "from keras.layers import Activation, LeakyReLU\n",
    "from keras.models import Model, load_model\n",
    "from keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55b3cd",
   "metadata": {
    "id": "ed55b3cd",
    "outputId": "ff1a7971-259a-4ca7-ddb8-2863b3343ef7"
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce03cbb9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "ce03cbb9",
    "outputId": "a7a94335-a7bd-4c45-9f4d-587720233d66",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>30850-0.0</th>\n",
       "      <th>30780-0.0</th>\n",
       "      <th>30690-0.0</th>\n",
       "      <th>30790-0.0</th>\n",
       "      <th>23101-0.0</th>\n",
       "      <th>23099-0.0</th>\n",
       "      <th>48-0.0</th>\n",
       "      <th>23100-0.0</th>\n",
       "      <th>30710-0.0</th>\n",
       "      <th>30760-0.0</th>\n",
       "      <th>30640-0.0</th>\n",
       "      <th>30750-0.0</th>\n",
       "      <th>49-0.0</th>\n",
       "      <th>30770-0.0</th>\n",
       "      <th>30740-0.0</th>\n",
       "      <th>30630-0.0</th>\n",
       "      <th>30870-0.0</th>\n",
       "      <th>21001-0.0</th>\n",
       "      <th>1488-0.0</th>\n",
       "      <th>4079-0.0</th>\n",
       "      <th>1299-0.0</th>\n",
       "      <th>21003-0.0</th>\n",
       "      <th>1160-0.0</th>\n",
       "      <th>1438-0.0</th>\n",
       "      <th>4080-0.0</th>\n",
       "      <th>1458-0.0</th>\n",
       "      <th>1528-0.0</th>\n",
       "      <th>1319-0.0</th>\n",
       "      <th>845-0.0</th>\n",
       "      <th>1289-0.0</th>\n",
       "      <th>1309-0.0</th>\n",
       "      <th>1418-0.0</th>\n",
       "      <th>1329-0.0</th>\n",
       "      <th>1220-0.0</th>\n",
       "      <th>1428-0.0</th>\n",
       "      <th>1249-0.0</th>\n",
       "      <th>1349-0.0</th>\n",
       "      <th>1369-0.0</th>\n",
       "      <th>20117-0.0</th>\n",
       "      <th>2100-0.0</th>\n",
       "      <th>2654-0.0</th>\n",
       "      <th>1339-0.0</th>\n",
       "      <th>21000-0.0</th>\n",
       "      <th>2050-0.0</th>\n",
       "      <th>1408-0.0</th>\n",
       "      <th>1200-0.0</th>\n",
       "      <th>1538-0.0</th>\n",
       "      <th>31-0.0</th>\n",
       "      <th>6138-0.0</th>\n",
       "      <th>1359-0.0</th>\n",
       "      <th>1389-0.0</th>\n",
       "      <th>1478-0.0</th>\n",
       "      <th>2090-0.0</th>\n",
       "      <th>1508-0.0</th>\n",
       "      <th>1379-0.0</th>\n",
       "      <th>6142-0.0</th>\n",
       "      <th>1468-0.0</th>\n",
       "      <th>1548-0.0</th>\n",
       "      <th>1239-0.0</th>\n",
       "      <th>1448-0.0</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>outcome_cardiomyopathies</th>\n",
       "      <th>outcome_ischemic_heart_disease</th>\n",
       "      <th>outcome_heart_failure</th>\n",
       "      <th>outcome_myocardial_infarction</th>\n",
       "      <th>outcome_peripheral_vascular_disease</th>\n",
       "      <th>outcome_cardiac_arrest</th>\n",
       "      <th>outcome_cerebral_infarction</th>\n",
       "      <th>outcome_arrhythmia</th>\n",
       "      <th>multi-labels</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50800</td>\n",
       "      <td>3.88800</td>\n",
       "      <td>6.47700</td>\n",
       "      <td>65.1984</td>\n",
       "      <td>45.2</td>\n",
       "      <td>35.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.70600</td>\n",
       "      <td>1.21100</td>\n",
       "      <td>35.065</td>\n",
       "      <td>102.0</td>\n",
       "      <td>26.339</td>\n",
       "      <td>5.62200</td>\n",
       "      <td>1.59300</td>\n",
       "      <td>0.97700</td>\n",
       "      <td>24.5790</td>\n",
       "      <td>6.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3.73</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.52</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>54</td>\n",
       "      <td>Female</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.08800</td>\n",
       "      <td>3.52000</td>\n",
       "      <td>5.51200</td>\n",
       "      <td>15.4000</td>\n",
       "      <td>74.6</td>\n",
       "      <td>36.5</td>\n",
       "      <td>120.0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1.17300</td>\n",
       "      <td>1.01900</td>\n",
       "      <td>40.900</td>\n",
       "      <td>113.0</td>\n",
       "      <td>10.701</td>\n",
       "      <td>5.05200</td>\n",
       "      <td>1.39000</td>\n",
       "      <td>2.35800</td>\n",
       "      <td>35.0861</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>65</td>\n",
       "      <td>Male</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.73364</td>\n",
       "      <td>4.10892</td>\n",
       "      <td>6.47949</td>\n",
       "      <td>50.8588</td>\n",
       "      <td>71.7</td>\n",
       "      <td>29.7</td>\n",
       "      <td>112.0</td>\n",
       "      <td>30.3</td>\n",
       "      <td>3.88</td>\n",
       "      <td>1.58546</td>\n",
       "      <td>1.22432</td>\n",
       "      <td>84.100</td>\n",
       "      <td>107.0</td>\n",
       "      <td>18.763</td>\n",
       "      <td>13.71763</td>\n",
       "      <td>1.74423</td>\n",
       "      <td>2.78764</td>\n",
       "      <td>30.7934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 1, 1]</td>\n",
       "      <td>55</td>\n",
       "      <td>Male</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.78800</td>\n",
       "      <td>2.88700</td>\n",
       "      <td>5.56500</td>\n",
       "      <td>56.5183</td>\n",
       "      <td>40.2</td>\n",
       "      <td>29.8</td>\n",
       "      <td>67.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.11500</td>\n",
       "      <td>0.81000</td>\n",
       "      <td>36.400</td>\n",
       "      <td>91.0</td>\n",
       "      <td>31.672</td>\n",
       "      <td>4.82700</td>\n",
       "      <td>1.89100</td>\n",
       "      <td>1.15700</td>\n",
       "      <td>20.7577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>49</td>\n",
       "      <td>Female</td>\n",
       "      <td>Irish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75600</td>\n",
       "      <td>2.67000</td>\n",
       "      <td>4.68000</td>\n",
       "      <td>4.7700</td>\n",
       "      <td>46.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.49300</td>\n",
       "      <td>0.73300</td>\n",
       "      <td>34.200</td>\n",
       "      <td>105.0</td>\n",
       "      <td>42.209</td>\n",
       "      <td>5.06300</td>\n",
       "      <td>1.86900</td>\n",
       "      <td>1.67700</td>\n",
       "      <td>25.9766</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>61</td>\n",
       "      <td>Female</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   30850-0.0  30780-0.0  30690-0.0  30790-0.0  23101-0.0  23099-0.0  48-0.0  \\\n",
       "0    0.50800    3.88800    6.47700    65.1984       45.2       35.6    74.0   \n",
       "1   13.08800    3.52000    5.51200    15.4000       74.6       36.5   120.0   \n",
       "2    9.73364    4.10892    6.47949    50.8588       71.7       29.7   112.0   \n",
       "3    1.78800    2.88700    5.56500    56.5183       40.2       29.8    67.0   \n",
       "4    0.75600    2.67000    4.68000     4.7700       46.5       30.1    85.0   \n",
       "\n",
       "   23100-0.0  30710-0.0  30760-0.0  30640-0.0  30750-0.0  49-0.0  30770-0.0  \\\n",
       "0       25.0       0.34    1.70600    1.21100     35.065   102.0     26.339   \n",
       "1       42.9       3.94    1.17300    1.01900     40.900   113.0     10.701   \n",
       "2       30.3       3.88    1.58546    1.22432     84.100   107.0     18.763   \n",
       "3       17.0       0.87    2.11500    0.81000     36.400    91.0     31.672   \n",
       "4       20.0       0.18    1.49300    0.73300     34.200   105.0     42.209   \n",
       "\n",
       "   30740-0.0  30630-0.0  30870-0.0  21001-0.0  1488-0.0  4079-0.0  1299-0.0  \\\n",
       "0    5.62200    1.59300    0.97700    24.5790       6.0      77.0      10.0   \n",
       "1    5.05200    1.39000    2.35800    35.0861       2.0      91.0       2.0   \n",
       "2   13.71763    1.74423    2.78764    30.7934       0.0      99.0       2.0   \n",
       "3    4.82700    1.89100    1.15700    20.7577       0.0      71.0       5.0   \n",
       "4    5.06300    1.86900    1.67700    25.9766       7.0      73.0       4.0   \n",
       "\n",
       "   21003-0.0  1160-0.0  1438-0.0  4080-0.0  1458-0.0  1528-0.0  1319-0.0  \\\n",
       "0       54.0       7.0      10.0     110.0      3.73       2.0       0.0   \n",
       "1       65.0       9.0      12.0     166.0      7.00       2.4       0.0   \n",
       "2       55.0       7.0      10.0     135.0      7.00       2.0       0.0   \n",
       "3       49.0       8.0      14.0     116.0      5.00       3.0       1.0   \n",
       "4       61.0       7.0       2.0     113.0      7.00       4.0       2.0   \n",
       "\n",
       "   845-0.0  1289-0.0  1309-0.0  1418-0.0  1329-0.0  1220-0.0  1428-0.0  \\\n",
       "0    23.52       6.0       2.0         3         2         0         0   \n",
       "1    16.00       2.0       1.0         2         2         0         1   \n",
       "2    21.00       3.0       1.0         2         1         0         0   \n",
       "3    18.00       5.0       1.0         2         2         0         0   \n",
       "4    16.00       3.0       3.0         3         2         1         1   \n",
       "\n",
       "   1249-0.0  1349-0.0  1369-0.0  20117-0.0  2100-0.0  2654-0.0  1339-0.0  \\\n",
       "0         1         1         1          2         1         6         2   \n",
       "1         1         4         2          2         0         7         2   \n",
       "2         1         2         1          2         0         7         2   \n",
       "3         4         1         2          2         0         7         2   \n",
       "4         4         1         1          2         0         7         3   \n",
       "\n",
       "   21000-0.0  2050-0.0  1408-0.0  1200-0.0  1538-0.0  31-0.0  6138-0.0  \\\n",
       "0          0         2         1         3         2       0         1   \n",
       "1          0         1         3         2         0       1         3   \n",
       "2          0         1         2         2         1       1         3   \n",
       "3          2         1         2         1         2       0         6   \n",
       "4          0         1         3         1         0       0         3   \n",
       "\n",
       "   1359-0.0  1389-0.0  1478-0.0  2090-0.0  1508-0.0  1379-0.0  6142-0.0  \\\n",
       "0         2         1         1         1         3         1         1   \n",
       "1         3         1         1         0         2         2         1   \n",
       "2         3         2         1         0         2         2         1   \n",
       "3         2         2         1         0         2         2         1   \n",
       "4         3         1         2         0         1         1         1   \n",
       "\n",
       "   1468-0.0  1548-0.0  1239-0.0  1448-0.0  hypertension  \\\n",
       "0         3         2         0         3             0   \n",
       "1         5         2         0         1             1   \n",
       "2         4         2         0         3             1   \n",
       "3         3         2         0         3             0   \n",
       "4         4         2         0         3             1   \n",
       "\n",
       "   outcome_cardiomyopathies  outcome_ischemic_heart_disease  \\\n",
       "0                         0                               0   \n",
       "1                         0                               1   \n",
       "2                         0                               1   \n",
       "3                         0                               0   \n",
       "4                         0                               0   \n",
       "\n",
       "   outcome_heart_failure  outcome_myocardial_infarction  \\\n",
       "0                      0                              0   \n",
       "1                      0                              1   \n",
       "2                      0                              0   \n",
       "3                      0                              0   \n",
       "4                      0                              1   \n",
       "\n",
       "   outcome_peripheral_vascular_disease  outcome_cardiac_arrest  \\\n",
       "0                                    0                       0   \n",
       "1                                    0                       0   \n",
       "2                                    0                       1   \n",
       "3                                    0                       0   \n",
       "4                                    0                       0   \n",
       "\n",
       "   outcome_cerebral_infarction  outcome_arrhythmia              multi-labels  \\\n",
       "0                            0                   1  [0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "1                            0                   0  [1, 0, 1, 0, 0, 0, 0, 0]   \n",
       "2                            1                   1  [0, 0, 1, 0, 0, 1, 1, 1]   \n",
       "3                            0                   1  [0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "4                            0                   0  [1, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "   age  gender     race  \n",
       "0   54  Female  British  \n",
       "1   65    Male  British  \n",
       "2   55    Male  British  \n",
       "3   49  Female    Irish  \n",
       "4   61  Female  British  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(gv.data_link)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a94f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==1.2.0\n",
      "aif360==0.4.0\n",
      "aiohttp==3.8.1\n",
      "aiosignal==1.2.0\n",
      "alabaster==0.7.12\n",
      "altair==4.2.0rc1\n",
      "anaconda-client==1.7.2\n",
      "anaconda-navigator==1.9.12\n",
      "anaconda-project==0.8.3\n",
      "antlr4-python3-runtime==4.9.3\n",
      "anyio==3.5.0\n",
      "aplus==0.11.0\n",
      "argh==0.26.2\n",
      "argon2-cffi==21.3.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "asgiref==3.5.0\n",
      "asn1crypto==1.3.0\n",
      "astroid @ file:///C:/ci/astroid_1592487315634/work\n",
      "astropy==5.0.3\n",
      "astunparse==1.6.3\n",
      "async-timeout==4.0.2\n",
      "atomicwrites==1.4.0\n",
      "attrs==21.2.0\n",
      "autograd==1.3\n",
      "autopep8 @ file:///tmp/build/80754af9/autopep8_1592412889138/work\n",
      "Babel==2.8.0\n",
      "backcall==0.2.0\n",
      "backports.functools-lru-cache==1.6.1\n",
      "backports.shutil-get-terminal-size==1.0.0\n",
      "backports.tempfile==1.0\n",
      "backports.weakref==1.0.post1\n",
      "bcrypt==3.1.7\n",
      "beautifulsoup4==4.10.0\n",
      "bitarray @ file:///C:/ci/bitarray_1594751093906/work\n",
      "bkcharts==0.2\n",
      "blake3==0.3.1\n",
      "bleach==4.1.0\n",
      "bokeh @ file:///C:/ci/bokeh_1593178781838/work\n",
      "Boruta==0.3\n",
      "boto==2.49.0\n",
      "Bottleneck==1.3.2\n",
      "bqplot==0.12.33\n",
      "brotlipy==0.7.0\n",
      "cachetools==5.0.0\n",
      "category-encoders==2.2.2\n",
      "certifi==2021.10.8\n",
      "cffi==1.15.0\n",
      "chardet==3.0.4\n",
      "charset-normalizer==2.0.7\n",
      "click==8.0.4\n",
      "cloudpickle==2.0.0\n",
      "clyent==1.2.2\n",
      "colorama==0.4.4\n",
      "commonmark==0.9.1\n",
      "comtypes==1.1.7\n",
      "conda==4.13.0\n",
      "conda-build==3.18.11\n",
      "conda-package-handling==1.7.0\n",
      "conda-verify==3.4.2\n",
      "configparser==5.0.2\n",
      "contextlib2==0.6.0.post1\n",
      "cryptography==2.9.2\n",
      "cvxpy==1.1.7\n",
      "cycler==0.11.0\n",
      "Cython @ file:///C:/ci/cython_1594829190914/work\n",
      "cytoolz==0.10.1\n",
      "dask==2022.3.0\n",
      "debugpy==1.5.1\n",
      "decorator==5.1.0\n",
      "defusedxml==0.7.1\n",
      "diff-match-patch @ file:///tmp/build/80754af9/diff-match-patch_1594828741838/work\n",
      "distributed @ file:///C:/ci/distributed_1594742844291/work\n",
      "distro==1.6.0\n",
      "Django==3.1.2\n",
      "dnspython==2.0.0\n",
      "docutils==0.16\n",
      "ecos==2.0.7.post1\n",
      "einops==0.3.0\n",
      "eli5==0.11.0\n",
      "entrypoints==0.3\n",
      "et-xmlfile==1.0.1\n",
      "fairlearn==0.7.0\n",
      "fastapi==0.75.0\n",
      "fastcache==1.1.0\n",
      "filelock==3.6.0\n",
      "findspark==1.4.2\n",
      "flake8==3.8.3\n",
      "Flask==1.1.2\n",
      "Flask-Script==2.0.6\n",
      "flatbuffers==1.12\n",
      "frozendict==2.3.0\n",
      "frozenlist==1.3.0\n",
      "fsspec==2022.2.0\n",
      "future==0.18.2\n",
      "gamma-facet==1.2.2\n",
      "gamma-pytools==1.2.5\n",
      "gast==0.4.0\n",
      "gevent @ file:///C:/ci/gevent_1593005471151/work\n",
      "glob2==0.7\n",
      "gmpy2==2.0.8\n",
      "google-auth==2.9.1\n",
      "google-auth-oauthlib==0.4.6\n",
      "google-pasta==0.2.0\n",
      "graphviz==0.16\n",
      "greenlet==1.1.2\n",
      "grpcio==1.47.0\n",
      "h11==0.13.0\n",
      "h5py==3.6.0\n",
      "hda==0.2.2\n",
      "HeapDict==1.0.1\n",
      "helpdev==0.7.1\n",
      "html5lib @ file:///tmp/build/80754af9/html5lib_1593446221756/work\n",
      "htmlmin==0.1.12\n",
      "httptools==0.4.0\n",
      "idna==3.3\n",
      "ImageHash==4.2.1\n",
      "imageio==2.21.0\n",
      "imagesize==1.2.0\n",
      "imbalanced-learn==0.9.0\n",
      "imblearn==0.0\n",
      "importlib-metadata==4.12.0\n",
      "intervaltree @ file:///tmp/build/80754af9/intervaltree_1594361675072/work\n",
      "ipydatawidgets==4.2.0\n",
      "ipykernel==6.5.1\n",
      "ipyleaflet==0.15.0\n",
      "ipympl==0.8.8\n",
      "ipython==7.29.0\n",
      "ipython-genutils==0.2.0\n",
      "ipyvolume==0.5.2\n",
      "ipyvue==1.7.0\n",
      "ipyvuetify==1.8.2\n",
      "ipywebrtc==0.6.0\n",
      "ipywidgets==7.7.0\n",
      "isort==4.3.21\n",
      "itsdangerous==1.1.0\n",
      "jdcal==1.4.1\n",
      "jedi==0.18.1\n",
      "Jinja2==3.0.2\n",
      "joblib==1.0.1\n",
      "json5==0.9.5\n",
      "jsonschema==3.2.0\n",
      "jupyter==1.0.0\n",
      "jupyter-client==7.1.0\n",
      "jupyter-console==6.1.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anali\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jupyter-core==4.9.1\n",
      "jupyterlab==2.1.5\n",
      "jupyterlab-pygments==0.1.2\n",
      "jupyterlab-server @ file:///tmp/build/80754af9/jupyterlab_server_1594164409481/work\n",
      "jupyterlab-widgets==1.1.0\n",
      "jupyterthemes==0.20.0\n",
      "keras==2.9.0\n",
      "Keras-Preprocessing==1.1.2\n",
      "keyring @ file:///C:/ci/keyring_1593109799227/work\n",
      "kiwisolver==1.3.2\n",
      "lazy-object-proxy==1.4.3\n",
      "lesscpy @ file:///home/conda/feedstock_root/build_artifacts/lesscpy_1626335962205/work\n",
      "libarchive-c==2.9\n",
      "libclang==14.0.1\n",
      "lightgbm==3.3.2\n",
      "lime==0.2.0.1\n",
      "llvmlite==0.38.0\n",
      "locket==0.2.1\n",
      "lxml @ file:///C:/ci/lxml_1594822774489/work\n",
      "Markdown==3.4.1\n",
      "MarkupSafe==2.0.1\n",
      "matplotlib==3.4.3\n",
      "matplotlib-inline==0.1.3\n",
      "mccabe==0.6.1\n",
      "mechanize==0.4.5\n",
      "memory-profiler==0.60.0\n",
      "menuinst==1.4.16\n",
      "missingno==0.5.0\n",
      "missingpy==0.2.0\n",
      "mistune==0.8.4\n",
      "mkl-fft==1.1.0\n",
      "mkl-random==1.1.1\n",
      "mkl-service==2.3.0\n",
      "mock==4.0.2\n",
      "more-itertools==8.4.0\n",
      "mpmath==1.1.0\n",
      "msgpack==1.0.0\n",
      "multidict==6.0.2\n",
      "multimethod==1.6\n",
      "multipledispatch==0.6.0\n",
      "mypy-extensions==0.4.3\n",
      "navigator-updater==0.2.1\n",
      "nbclient==0.5.13\n",
      "nbconvert==6.4.5\n",
      "nbformat==5.2.0\n",
      "nest-asyncio==1.5.1\n",
      "networkx==2.6.3\n",
      "nltk==3.7\n",
      "nose==1.3.7\n",
      "notebook==6.4.10\n",
      "numba==0.55.1\n",
      "numexpr==2.7.1\n",
      "numpy==1.21.2\n",
      "numpydoc @ file:///tmp/build/80754af9/numpydoc_1594166760263/work\n",
      "oauthlib==3.2.0\n",
      "olefile==0.46\n",
      "omegaconf==2.2.2\n",
      "openpyxl @ file:///tmp/build/80754af9/openpyxl_1594167385094/work\n",
      "opt-einsum==3.3.0\n",
      "osqp==0.6.1\n",
      "packaging==21.3\n",
      "pandas==1.1.5\n",
      "pandas-profiling==3.1.0\n",
      "pandasql==0.7.3\n",
      "pandocfilters==1.5.0\n",
      "paramiko==2.7.1\n",
      "parso==0.8.2\n",
      "partd==1.2.0\n",
      "path==13.1.0\n",
      "pathlib2==2.3.5\n",
      "pathtools==0.1.2\n",
      "patsy==0.5.2\n",
      "pep8==1.7.1\n",
      "pexpect==4.8.0\n",
      "pgmpy==0.1.18\n",
      "phik==0.12.0\n",
      "pickleshare==0.7.5\n",
      "Pillow==8.4.0\n",
      "pkginfo==1.5.0.1\n",
      "plotly==5.3.1\n",
      "plotly-express==0.4.1\n",
      "pluggy==0.13.1\n",
      "ply==3.11\n",
      "progressbar2==4.0.0\n",
      "prometheus-client==0.13.1\n",
      "prompt-toolkit==3.0.22\n",
      "protobuf==3.19.4\n",
      "psutil==5.9.1\n",
      "ptyprocess==0.6.0\n",
      "py @ file:///tmp/build/80754af9/py_1593446248552/work\n",
      "py4j==0.10.9\n",
      "pyarrow==7.0.0\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycodestyle==2.6.0\n",
      "pycosat==0.6.3\n",
      "pycparser==2.21\n",
      "pycurl==7.43.0.5\n",
      "pydantic==1.8.2\n",
      "pyDeprecate==0.3.0\n",
      "pydocstyle @ file:///tmp/build/80754af9/pydocstyle_1592848020240/work\n",
      "pydot==1.4.2\n",
      "pyerfa==2.0.0.1\n",
      "pyflakes==2.2.0\n",
      "Pygments==2.10.0\n",
      "pylint @ file:///C:/ci/pylint_1592482039483/work\n",
      "pymongo==3.11.0\n",
      "PyNaCl @ file:///C:/ci/pynacl_1595000047588/work\n",
      "pyodbc===4.0.0-unsupported\n",
      "pyOpenSSL @ file:///tmp/build/80754af9/pyopenssl_1594392929924/work\n",
      "pyparsing==3.0.6\n",
      "PyQt5==5.12.3\n",
      "PyQt5-sip==12.8.1\n",
      "PyQtWebEngine==5.12.1\n",
      "pyreadline==2.1\n",
      "pyrsistent==0.18.0\n",
      "PySocks==1.7.1\n",
      "pyspark==3.0.1\n",
      "pytest==5.4.3\n",
      "python-dateutil==2.8.2\n",
      "python-dotenv==0.20.0\n",
      "python-jsonrpc-server @ file:///tmp/build/80754af9/python-jsonrpc-server_1594397536060/work\n",
      "python-language-server @ file:///C:/ci/python-language-server_1594162130238/work\n",
      "python-utils==3.1.0\n",
      "pythreejs==2.3.0\n",
      "pytorch-lightning==1.3.6\n",
      "pytorch-tabnet==3.0.0\n",
      "pytorch-tabular==0.7.0\n",
      "pytz==2021.3\n",
      "PyWavelets==1.2.0\n",
      "pywin32==302\n",
      "pywin32-ctypes==0.2.0\n",
      "pywinpty==2.0.5\n",
      "PyYAML==6.0\n",
      "pyzmq==22.3.0\n",
      "QDarkStyle==2.8.1\n",
      "QtAwesome==0.7.2\n",
      "qtconsole @ file:///tmp/build/80754af9/qtconsole_1592848611704/work\n",
      "QtPy==1.9.0\n",
      "regex==2022.3.2\n",
      "requests==2.26.0\n",
      "requests-oauthlib==1.3.1\n",
      "rich==12.0.1\n",
      "rope==0.17.0\n",
      "rsa==4.8\n",
      "Rtree==0.9.4\n",
      "ruamel_yaml==0.15.87\n",
      "scikeras==0.8.0\n",
      "scikit-image==0.19.3\n",
      "scikit-learn==1.0.2\n",
      "scikit-multilearn==0.2.0\n",
      "scikit-surprise==1.1.1\n",
      "scipy==1.5.4\n",
      "scs==2.1.2\n",
      "seaborn==0.11.2\n",
      "selenium==3.141.0\n",
      "Send2Trash==1.8.0\n",
      "shap==0.39.0\n",
      "simplegeneric==0.8.1\n",
      "singledispatch==3.4.0.3\n",
      "sip==4.19.13\n",
      "six==1.16.0\n",
      "sklearn==0.0\n",
      "sklearndf==1.2.3\n",
      "slicer==0.0.7\n",
      "sniffio==1.2.0\n",
      "snowballstemmer==2.0.0\n",
      "sortedcollections==1.2.1\n",
      "sortedcontainers==2.2.2\n",
      "soupsieve==2.3.1\n",
      "Sphinx @ file:///tmp/build/80754af9/sphinx_1594223420021/work\n",
      "sphinxcontrib-applehelp==1.0.2\n",
      "sphinxcontrib-devhelp==1.0.2\n",
      "sphinxcontrib-htmlhelp==1.0.3\n",
      "sphinxcontrib-jsmath==1.0.1\n",
      "sphinxcontrib-qthelp==1.0.3\n",
      "sphinxcontrib-serializinghtml==1.1.4\n",
      "sphinxcontrib-websupport @ file:///tmp/build/80754af9/sphinxcontrib-websupport_1593446360927/work\n",
      "spyder==4.1.5\n",
      "spyder-kernels==1.9.4\n",
      "SQLAlchemy==1.4.26\n",
      "sqlparse==0.4.1\n",
      "squarify==0.4.3\n",
      "starlette==0.17.1\n",
      "statsmodels==0.13.1\n",
      "sympy @ file:///C:/ci/sympy_1594234545115/work\n",
      "tables==3.6.1\n",
      "tabula==1.0.5\n",
      "tabula-py==2.3.0\n",
      "tabulate==0.8.9\n",
      "tangled-up-in-unicode==0.1.0\n",
      "tblib==1.6.0\n",
      "tempeh==0.1.12\n",
      "tenacity==8.0.1\n",
      "tensorboard==2.9.1\n",
      "tensorboard-data-server==0.6.1\n",
      "tensorboard-plugin-wit==1.8.1\n",
      "tensorflow==2.9.1\n",
      "tensorflow-addons==0.17.1\n",
      "tensorflow-estimator==2.9.0\n",
      "tensorflow-io-gcs-filesystem==0.26.0\n",
      "termcolor==1.1.0\n",
      "terminado==0.13.3\n",
      "testpath==0.6.0\n",
      "threadpoolctl==3.1.0\n",
      "tifffile==2022.8.3\n",
      "toml @ file:///tmp/build/80754af9/toml_1592853716807/work\n",
      "toolz==0.11.1\n",
      "torch==1.11.0\n",
      "torchmetrics==0.9.3\n",
      "tornado==6.1\n",
      "tqdm==4.62.3\n",
      "traitlets==5.1.1\n",
      "traittypes==0.2.1\n",
      "tweepy==3.9.0\n",
      "twython==3.8.2\n",
      "typeguard==2.13.3\n",
      "typing-inspect==0.7.1\n",
      "typing_extensions==4.0.0\n",
      "ujson==1.35\n",
      "unicodecsv==0.14.1\n",
      "union==0.1.10\n",
      "urllib3==1.26.7\n",
      "uvicorn==0.17.6\n",
      "vaex==4.8.0\n",
      "vaex-astro==0.9.0\n",
      "vaex-core==4.8.0\n",
      "vaex-hdf5==0.12.0\n",
      "vaex-jupyter==0.7.0\n",
      "vaex-ml==0.17.0\n",
      "vaex-server==0.8.1\n",
      "vaex-viz==0.5.1\n",
      "vega-datasets==0.9.0\n",
      "visions==0.7.4\n",
      "watchdog @ file:///C:/ci/watchdog_1593447437088/work\n",
      "watchgod==0.8.1\n",
      "wcwidth==0.2.5\n",
      "webencodings==0.5.1\n",
      "websockets==10.2\n",
      "Werkzeug==2.1.2\n",
      "widgetsnbextension==3.6.0\n",
      "win-inet-pton==1.1.0\n",
      "win-unicode-console==0.5\n",
      "wincertstore==0.2\n",
      "wrapt==1.14.1\n",
      "xarray==2022.3.0\n",
      "xgboost==1.6.1\n",
      "xlrd==1.2.0\n",
      "XlsxWriter==1.2.9\n",
      "xlwings==0.19.5\n",
      "xlwt==1.3.0\n",
      "xmltodict==0.12.0\n",
      "xyzservices==2022.3.0\n",
      "yapf @ file:///tmp/build/80754af9/yapf_1593528177422/work\n",
      "yarl==1.7.2\n",
      "zict==2.0.0\n",
      "zipp==3.8.1\n",
      "zope.event==4.4\n",
      "zope.interface==4.7.1\n"
     ]
    }
   ],
   "source": [
    "! pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f27ac1",
   "metadata": {
    "id": "79f27ac1"
   },
   "source": [
    "### Build MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd9d66d",
   "metadata": {
    "id": "1bd9d66d"
   },
   "outputs": [],
   "source": [
    "# METRICS = [\n",
    "#       keras.metrics.TruePositives(name='tp'),\n",
    "#       keras.metrics.FalsePositives(name='fp'),\n",
    "#       keras.metrics.TrueNegatives(name='tn'),\n",
    "#       keras.metrics.FalseNegatives(name='fn'), \n",
    "#       keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#       keras.metrics.Precision(name='precision'),\n",
    "#       keras.metrics.Recall(name='recall'),\n",
    "#       keras.metrics.AUC(name='auc'),\n",
    "#       keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617f83cd",
   "metadata": {
    "id": "617f83cd"
   },
   "source": [
    "#### optimize number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d5bf9b2",
   "metadata": {
    "id": "5d5bf9b2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_nodes(n_nodes, X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch):\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation=tf.keras.activations.gelu , input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(n_nodes, activation=tf.keras.activations.gelu ))\n",
    "    model.add(Dense(n_nodes, activation=tf.keras.activations.gelu ))\n",
    "    model.add(Dense(1, activation=tf.nn.sigmoid))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=0.000001),\n",
    "        metrics=['acc',utilities.f1_m,utilities.precision_m, utilities.recall_m])\n",
    "\n",
    "    # fit model on train set\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch,\n",
    "        epochs=epochs,\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val),\n",
    "    )\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return history, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bgpit_ZemX1V",
   "metadata": {
    "id": "bgpit_ZemX1V"
   },
   "outputs": [],
   "source": [
    "def evaluate_layers(n_layers, X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch):\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation=tf.keras.activations.gelu , input_shape=(X_train.shape[1],)))\n",
    "    for _ in range(1,n_layers):\n",
    "        model.add(Dense(50, activation=tf.keras.activations.gelu ))\n",
    "    model.add(Dense(1, activation=tf.nn.sigmoid))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=0.000001),\n",
    "        metrics=['acc',utilities.f1_m,utilities.precision_m, utilities.recall_m])\n",
    "\n",
    "    # fit model on train set\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch,\n",
    "        epochs=epochs,\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val),\n",
    "    )\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return history, score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6cc2f2",
   "metadata": {
    "id": "9b6cc2f2"
   },
   "source": [
    "#### test range of input nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9dae95",
   "metadata": {
    "id": "cf9dae95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "112/112 [==============================] - 6s 19ms/step - loss: 0.6965 - acc: 0.4980 - f1_m: 0.6397 - precision_m: 0.4984 - recall_m: 0.8942 - val_loss: 0.6936 - val_acc: 0.5160 - val_f1_m: 0.6580 - val_precision_m: 0.5241 - val_recall_m: 0.8849\n",
      "Epoch 2/400\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.6962 - acc: 0.4972 - f1_m: 0.6369 - precision_m: 0.4984 - recall_m: 0.8832 - val_loss: 0.6935 - val_acc: 0.5150 - val_f1_m: 0.6548 - val_precision_m: 0.5239 - val_recall_m: 0.8742\n",
      "Epoch 3/400\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.6961 - acc: 0.4974 - f1_m: 0.6341 - precision_m: 0.4988 - recall_m: 0.8715 - val_loss: 0.6935 - val_acc: 0.5142 - val_f1_m: 0.6514 - val_precision_m: 0.5237 - val_recall_m: 0.8625\n",
      "Epoch 4/400\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.6959 - acc: 0.4969 - f1_m: 0.6308 - precision_m: 0.4987 - recall_m: 0.8594 - val_loss: 0.6934 - val_acc: 0.5145 - val_f1_m: 0.6489 - val_precision_m: 0.5242 - val_recall_m: 0.8527\n",
      "Epoch 5/400\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.6957 - acc: 0.4972 - f1_m: 0.6275 - precision_m: 0.4984 - recall_m: 0.8485 - val_loss: 0.6934 - val_acc: 0.5120 - val_f1_m: 0.6442 - val_precision_m: 0.5230 - val_recall_m: 0.8394\n",
      "Epoch 6/400\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.6956 - acc: 0.4980 - f1_m: 0.6250 - precision_m: 0.4994 - recall_m: 0.8366 - val_loss: 0.6933 - val_acc: 0.5098 - val_f1_m: 0.6390 - val_precision_m: 0.5221 - val_recall_m: 0.8245\n",
      "Epoch 7/400\n",
      " 99/112 [=========================>....] - ETA: 0s - loss: 0.6956 - acc: 0.4981 - f1_m: 0.6205 - precision_m: 0.4978 - recall_m: 0.8250"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28908/283384018.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_nodes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# evaluate model with a given number of nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0msave_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0msave_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28908/220400949.py\u001b[0m in \u001b[0;36mevaluate_nodes\u001b[1;34m(n_nodes, X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# fit model on train set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     history = model.fit(\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_nodes = [10, 25, 50, 100, 150, 200]\n",
    "epochs = 400\n",
    "batch = 500\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = utilities.process_features(df, 'outcome_arrhythmia', QuantileTransformer(output_distribution='uniform'), one_hot=True)\n",
    "X_train, y_train= utilities.resample_data(X_train, y_train, 'under')\n",
    "\n",
    "save_history = pd.DataFrame()\n",
    "for n_nodes in num_nodes:\n",
    "    # evaluate model with a given number of nodes\n",
    "    history, result = evaluate_nodes(n_nodes, X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch)\n",
    "    save_history['loss_'+str(n_nodes)]=history.history[\"loss\"]\n",
    "    save_history['acc_'+str(n_nodes)]=history.history[\"acc\"]\n",
    "    save_history['f1'+str(n_nodes)]=history.history[\"f1_m\"]\n",
    "    save_history['recall'+str(n_nodes)]=history.history[\"recall_m\"]\n",
    "\n",
    "\n",
    "    # summarize final test set accuracy\n",
    "    print('nodes=%d  loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (n_nodes, result[0], result[1], result[2], result[3], result[4]))\n",
    "    \n",
    "    # plot learning curves\n",
    "    utilities.plot_history(history)\n",
    "    plt.suptitle('Number of Nodes: '+str(n_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kJOOk6B5ZxXS",
   "metadata": {
    "id": "kJOOk6B5ZxXS"
   },
   "outputs": [],
   "source": [
    "def plot_compare(data, metric):\n",
    "  labels = []\n",
    "  for i in range(data.shape[1]):\n",
    "    sns.lineplot(x=data.index, y=data.loc[:,data.columns[i-1]], data=data)\n",
    "    plt.title(metric+' for all num_nodes')\n",
    "    labels.append(str(data.columns[i-1]))\n",
    "  plt.legend(title=metric, loc='best', labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3HVZFtPQcE-B",
   "metadata": {
    "id": "3HVZFtPQcE-B"
   },
   "outputs": [],
   "source": [
    "plot_compare(save_history.loc[:,save_history.columns.to_list()[::4]], 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dQxjf1IXvO_C",
   "metadata": {
    "id": "dQxjf1IXvO_C"
   },
   "outputs": [],
   "source": [
    "plot_compare(save_history.loc[:,save_history.columns.to_list()[1::4]], 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zz0p182tzyHR",
   "metadata": {
    "id": "zz0p182tzyHR"
   },
   "outputs": [],
   "source": [
    "plot_compare(save_history.loc[:,save_history.columns.to_list()[2::4]], 'F1-Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XhRlCOvtzyRo",
   "metadata": {
    "id": "XhRlCOvtzyRo"
   },
   "outputs": [],
   "source": [
    "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XB4Rv9251GnD",
   "metadata": {
    "id": "XB4Rv9251GnD"
   },
   "outputs": [],
   "source": [
    "num_layers = [3, 4, 5]\n",
    "epochs = 400\n",
    "batch = 500\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = utilities.process_features(df, 'outcome_arrhythmia', QuantileTransformer(output_distribution='uniform'), one_hot=True)\n",
    "X_train, y_train= utilities.resample_data(X_train, y_train, 'under')\n",
    "\n",
    "save_history = pd.DataFrame()\n",
    "for n_layers in num_layers:\n",
    "    # evaluate model with a given number of nodes\n",
    "    history, result = evaluate_layers(n_layers, X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch)\n",
    "    save_history['loss_'+str(n_layers)]=history.history[\"loss\"]\n",
    "    save_history['acc_'+str(n_layers)]=history.history[\"acc\"]\n",
    "    save_history['f1'+str(n_layers)]=history.history[\"f1_m\"]\n",
    "    save_history['recall'+str(n_layers)]=history.history[\"recall_m\"]\n",
    "\n",
    "\n",
    "    # summarize final test set accuracy\n",
    "    print('nodes=%d  loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (n_layers, result[0], result[1], result[2], result[3], result[4]))\n",
    "    \n",
    "    # plot learning curves\n",
    "    utilities.plot_history(history)\n",
    "    plt.suptitle('Number of Layers: '+str(n_layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0e3458",
   "metadata": {
    "id": "2a0e3458"
   },
   "source": [
    "### Build Model after testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009fde5",
   "metadata": {
    "id": "0009fde5"
   },
   "outputs": [],
   "source": [
    "def mlp_model( X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation='tanh',opt=SGD, lr=0.000001):\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1000, activation=activation , input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(500, activation=activation))\n",
    "    model.add(Dense(500, activation=activation ))\n",
    "    model.add(Dense(200, activation=activation ))\n",
    "    model.add(Dense(1, activation=tf.nn.sigmoid))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=opt(learning_rate=lr),\n",
    "        metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "    # fit model on train set\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch,\n",
    "        epochs=epochs,\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val),\n",
    "    )\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return history, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad05a1b",
   "metadata": {
    "id": "6ad05a1b"
   },
   "outputs": [],
   "source": [
    "epochs =300\n",
    "batch = 400\n",
    "sample_methods =['ADASYN', 'over', 'under', 'partial_under']\n",
    "activations=['relu', 'tanh', tf.keras.activations.gelu]\n",
    "optimizers = [SGD, Adam, Adagrad]\n",
    "num_transformers = [StandardScaler(), MinMaxScaler(), QuantileTransformer(output_distribution='uniform')]\n",
    "# test one_hot==True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51f06c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e51f06c",
    "outputId": "c55f6aaf-a2ac-4304-c726-b8f3c2a700f5"
   },
   "outputs": [],
   "source": [
    "# Test numerical transformers\n",
    "save_history = pd.DataFrame()\n",
    "for param in num_transformers:\n",
    "    \n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = utilities.process_features(df, 'outcome_arrhythmia', param, one_hot=True)\n",
    "    X_train, y_train= utilities.resample_data(X_train, y_train, 'under')\n",
    "    \n",
    "    # evaluate model with a given number of nodes\n",
    "    history, result = mlp_model( X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation='tanh',opt=SGD, lr=0.000001)\n",
    "    save_history['loss_'+str(n_nodes)]=history.history[\"loss\"]\n",
    "    save_history['acc_'+str(n_nodes)]=history.history[\"acc\"]\n",
    "    save_history['f1'+str(n_nodes)]=history.history[\"f1_m\"]\n",
    "    save_history['recall'+str(n_nodes)]=history.history[\"recall_m\"]\n",
    "\n",
    "\n",
    "    # summarize final test set accuracy\n",
    "    print('loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (result[0], result[1], result[2], result[3], result[4]))\n",
    "    \n",
    "    # plot learning curves\n",
    "    utilities.plot_history(history)\n",
    "    plt.suptitle(str(param))\n",
    "\n",
    "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a7317",
   "metadata": {
    "id": "404a7317"
   },
   "outputs": [],
   "source": [
    "# Test sample methods\n",
    "save_history = pd.DataFrame()\n",
    "for param in sample_methods:\n",
    "    \n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = utilities.process_features(df, 'outcome_arrhythmia')\n",
    "    X_train, y_train= utilities.resample_data(X_train, y_train, param)\n",
    "    \n",
    "    # evaluate model with a given number of nodes\n",
    "    history, result = mlp_model(X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch,opt=SGD, lr=0.000001)\n",
    "    save_history['loss_'+str(n_nodes)]=history.history[\"loss\"]\n",
    "    save_history['acc_'+str(n_nodes)]=history.history[\"acc\"]\n",
    "    save_history['f1'+str(n_nodes)]=history.history[\"f1_m\"]\n",
    "    save_history['recall'+str(n_nodes)]=history.history[\"recall_m\"]\n",
    "\n",
    "\n",
    "    # summarize final test set accuracy\n",
    "    print('nodes=%d  loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (n_nodes, result[0], result[1], result[2], result[3], result[4]))\n",
    "    \n",
    "    # plot learning curves\n",
    "    utilities.plot_history(history)\n",
    "    plt.suptitle(str(param))\n",
    "\n",
    "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84752a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f84752a4",
    "outputId": "8bf77509-7036-4d5a-c909-0474e9422d75"
   },
   "outputs": [],
   "source": [
    "# Test activations\n",
    "activations = ['tanh']\n",
    "save_history = pd.DataFrame()\n",
    "for param in activations:\n",
    "    \n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = utilities.process_features(df, 'outcome_arrhythmia')\n",
    "    X_train, y_train= utilities.resample_data(X_train, y_train, 'under')\n",
    "    \n",
    "    # evaluate model with a given number of nodes\n",
    "    history, result = mlp_model(X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation=param,opt=SGD, lr=0.0001) #lr = 0.0002\n",
    "    save_history['loss_']=history.history[\"loss\"]\n",
    "    save_history['acc_']=history.history[\"acc\"]\n",
    "    save_history['f1']=history.history[\"f1_m\"]\n",
    "    save_history['recall']=history.history[\"recall_m\"]\n",
    "\n",
    "\n",
    "    # summarize final test set accuracy\n",
    "    print('nodes=%d  loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (n_nodes, result[0], result[1], result[2], result[3], result[4]))\n",
    "    \n",
    "    # plot learning curves\n",
    "    utilities.plot_history(history)\n",
    "    plt.suptitle(str(param))\n",
    "\n",
    "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a1880",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "580a1880",
    "outputId": "07f27940-6b33-434f-e547-24e0fa82ec50"
   },
   "outputs": [],
   "source": [
    "# Test optimizers\n",
    "\n",
    "optimizers =[Adam]\n",
    "save_history = pd.DataFrame()\n",
    "for param in optimizers:\n",
    "    \n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = utilities.process_features(df, 'outcome_arrhythmia')\n",
    "    X_train, y_train= utilities.resample_data(X_train, y_train, 'under')\n",
    "    \n",
    "    # evaluate model with a given number of nodes\n",
    "    history, result = mlp_model(X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation='tanh',opt=param, lr=0.000002)\n",
    "    save_history['loss_']=history.history[\"loss\"]\n",
    "    save_history['acc_']=history.history[\"acc\"]\n",
    "    save_history['f1']=history.history[\"f1_m\"]\n",
    "    save_history['recall']=history.history[\"recall_m\"]\n",
    "\n",
    "\n",
    "    # summarize final test set accuracy\n",
    "    print('loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (result[0], result[1], result[2], result[3], result[4]))\n",
    "    \n",
    "    # plot learning curves\n",
    "    utilities.plot_history(history)\n",
    "    plt.suptitle(str(param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i5FnEICHArGz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5FnEICHArGz",
    "outputId": "3c8e5c09-4ca3-4484-99b8-cfeb1b37e304"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m-XAdsqrw8HZ",
   "metadata": {
    "id": "m-XAdsqrw8HZ"
   },
   "source": [
    "#### Learning Rate Schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zNwMETydw7Ay",
   "metadata": {
    "id": "zNwMETydw7Ay"
   },
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dAaElnGDpvzg",
   "metadata": {
    "id": "dAaElnGDpvzg"
   },
   "outputs": [],
   "source": [
    "# Test opt opt params\n",
    "\n",
    "learning_rates = [1e-3, 1e-4, 1e-6, some_changing_thing()]\n",
    "beta1, beta2 = [1,2,3,4], [1,2,3,4]\n",
    "save_history = pd.DataFrame()\n",
    "for param in optimizers:\n",
    "    \n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = process_features(df, 'outcome_arrhythmia', QuantileTransformer(output_distribution='uniform'), one_hot=True)\n",
    "    X_train, y_train= resample_data(X_train, y_train, 'under')\n",
    "    \n",
    "    # evaluate model with a given number of nodes\n",
    "    history, result = basic_model(n_nodes, X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch, activation='relu',opt=param, lr=0.000001)\n",
    "    save_history['loss_'+str(n_nodes)]=history.history[\"loss\"]\n",
    "    save_history['acc_'+str(n_nodes)]=history.history[\"acc\"]\n",
    "    save_history['f1'+str(n_nodes)]=history.history[\"f1_m\"]\n",
    "    save_history['recall'+str(n_nodes)]=history.history[\"recall_m\"]\n",
    "\n",
    "\n",
    "    # summarize final test set accuracy\n",
    "    print('nodes=%d  loss=%.3f  accuracy=%.3f  F1-score=%.3f  Precision=%.3f  Recall=%.3f' % (n_nodes, result[0], result[1], result[2], result[3], result[4]))\n",
    "    \n",
    "    # plot learning curves\n",
    "    plot_history(history)\n",
    "    plt.suptitle(str(param))\n",
    "\n",
    "plot_compare(save_history.loc[:,save_history.columns.to_list()[3::4]], 'Recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7132839",
   "metadata": {
    "id": "b7132839"
   },
   "source": [
    "### Build MLP Model with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f78ee8",
   "metadata": {
    "id": "32f78ee8"
   },
   "outputs": [],
   "source": [
    "def build_categorical_inputs(features):\n",
    "\n",
    "    initial_inputs = {}\n",
    "    cat_input_layers={}\n",
    "    \n",
    "    train_test_cat_features = pd.concat([X_train[categorical_cols], X_test[categorical_cols]])\n",
    "    \n",
    "    for feature in features:\n",
    "        no_of_unique_cats  = train_test_cat_features[feature].nunique()\n",
    "        embedding_size = int(min(np.ceil((no_of_unique_cats)/2), 50))\n",
    "        categories  = no_of_unique_cats + 1\n",
    "\n",
    "        initial_inputs[feature] = Input(shape=(1,))\n",
    "        embedding_layer = Embedding(categories, \n",
    "                                    embedding_size,\n",
    "                                    embeddings_regularizer=regularizers.l2(0.01),\n",
    "                                    input_length=1)(initial_inputs[feature])\n",
    "        cat_input_layers[feature] = Reshape(target_shape=(embedding_size,))(embedding_layer)\n",
    "\n",
    "    return initial_inputs, cat_input_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a231b6",
   "metadata": {
    "id": "58a231b6"
   },
   "outputs": [],
   "source": [
    "def build_model( X_train, X_val, y_val, y_train, X_test, y_test, epochs, batch):\n",
    "    \n",
    "    models = []\n",
    "    for categorical_var in categorical_cols :\n",
    "        model = Sequential()\n",
    "        no_of_unique_cat  = X_train[categorical_var].nunique()\n",
    "        embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
    "        embedding_size = int(embedding_size)\n",
    "        vocab  = no_of_unique_cat+1\n",
    "        model.add( Embedding(vocab ,embedding_size, input_length = 1 ))\n",
    "        model.add(Reshape(target_shape=(embedding_size,)))\n",
    "        models.append( model )\n",
    "        \n",
    "    model_rest = Sequential()\n",
    "    model_rest.add(Dense(16, input_dim= X_train[numerical_cols+continuous_cols].shape[1]))\n",
    "    models.append(model_rest)\n",
    "\n",
    "    full_model = Sequential()\n",
    "    full_model.add(Concatenate(models))\n",
    "    full_model.add(Dense(1000))\n",
    "    full_model.add(Activation('relu'))\n",
    "    full_model.add(Dense(400))\n",
    "    full_model.add(Activation('relu'))\n",
    "    full_model.add(Dense(1))\n",
    "    full_model.add(Activation('sigmoid'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=0.000001),\n",
    "        metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "    # fit model on train set\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch,\n",
    "        epochs=epochs,\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val),\n",
    "    )\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return history, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df20d86",
   "metadata": {
    "id": "7df20d86"
   },
   "outputs": [],
   "source": [
    "def build_model( X_train, X_val, X_test ,y_train, y_val, y_test, epochs, batch):\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    for col in categorical_cols:\n",
    "        no_of_unique_cat  = X_train[col].nunique()\n",
    "        embedding_size = min(np.ceil((no_of_unique_cat)/2), 50)\n",
    "        embedding_size = int(embedding_size)\n",
    "        vocab  = no_of_unique_cat+1\n",
    "        model.add(Embedding(input_dim=no_of_unique_cat, output_dim=embedding_size, input_shape=(X_train.shape[1],)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation=tf.keras.activations.gelu ))\n",
    "    model.add(Dense(1, activation=tf.nn.sigmoid))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=0.000001),\n",
    "        metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "    # fit model on train set\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch,\n",
    "        epochs=epochs,\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val),\n",
    "    )\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return history, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7504bd9e",
   "metadata": {
    "id": "7504bd9e",
    "outputId": "461b0328-9c50-49ca-c506-82ac05ebb67c"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = process_features(df, 'outcome_arrhythmia', QuantileTransformer(output_distribution='uniform'), one_hot=False)\n",
    "X_train, y_train= resample_data(X_train, y_train, 'under')\n",
    "model=build_model(X_train, X_val, X_test ,y_train, y_val, y_test, 400, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac49e1",
   "metadata": {
    "id": "1fac49e1"
   },
   "outputs": [],
   "source": [
    "initial_inputs, input_layers = build_categorical_inputs(categorical_cols)\n",
    "\n",
    "no_of_num_features = len(X_train.columns) - len(categorical_cols)\n",
    "\n",
    "initial_inputs['numerical_features'] = Input(shape=(no_of_num_features,))\n",
    "input_layers['numerical_features'] = initial_inputs['numerical_features']\n",
    "\n",
    "inputs = Concatenate(axis=-1)([layer for layer in input_layers.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ccdade",
   "metadata": {
    "id": "40ccdade"
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "model_rest = Sequential()\n",
    "model_rest.add(Dense(100, input_dim= len(numerical_cols+continuous_cols) ))\n",
    "models.append(model_rest)\n",
    "\n",
    "for categorical_var in categorical_cols :\n",
    "     \n",
    "    model = Sequential()\n",
    "    no_of_unique_cat  = X_train[categorical_var].nunique()\n",
    "    \n",
    "    # jeremy howard rule\n",
    "    embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
    "    embedding_size = int(embedding_size)\n",
    "    vocab  = no_of_unique_cat+1\n",
    "    model.add( Embedding(vocab ,embedding_size, input_length = 1 ))\n",
    "    model.add(Reshape(target_shape=(embedding_size,)))\n",
    "    models.append( model )\n",
    "\n",
    "\n",
    "full_model = Sequential()\n",
    "full_model.add(Concatenate(models))\n",
    "full_model.add(Dense(1000))\n",
    "full_model.add(Activation('relu'))\n",
    "full_model.add(Dense(400))\n",
    "full_model.add(Activation('relu'))\n",
    "full_model.add(Dense(200))\n",
    "full_model.add(Activation('sigmoid'))\n",
    "full_model.add(Dense(1))\n",
    "full_model.add(Activation('sigmoid'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.000001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['acc',f1_m,precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987f57a0",
   "metadata": {
    "id": "987f57a0",
    "outputId": "d565f829-b10a-4bf0-eae3-9a584de3dd05"
   },
   "outputs": [],
   "source": [
    "batch=1000\n",
    "epochs=100\n",
    "# fit model on train set\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch,\n",
    "    epochs=epochs,\n",
    "#     shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val, y_val),\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0276b8",
   "metadata": {
    "id": "6a0276b8"
   },
   "source": [
    "### K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436b62e0",
   "metadata": {
    "id": "436b62e0"
   },
   "outputs": [],
   "source": [
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(no_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=loss_function,\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779c9624",
   "metadata": {
    "id": "779c9624"
   },
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd4df5",
   "metadata": {
    "id": "00dd4df5"
   },
   "outputs": [],
   "source": [
    "Model.save(\n",
    "    saved_models/'model_'+str(num)+'.h5',\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None,\n",
    "    save_traces=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "machine_shape": "hm",
   "name": "02-basic_model.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
