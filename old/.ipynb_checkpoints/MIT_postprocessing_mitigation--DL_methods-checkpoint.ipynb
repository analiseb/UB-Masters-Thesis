{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62aa9f5",
   "metadata": {},
   "source": [
    "## Post-processing Mitigation Methods: AIF360\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd8d3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import fairness_helpers as fh\n",
    "import utilities\n",
    "import global_variables as gv\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.optimizers  import Adam, Adagrad, SGD, RMSprop\n",
    "\n",
    "from aif360.sklearn.postprocessing import CalibratedEqualizedOdds, PostProcessingMeta\n",
    "from aif360.sklearn.metrics import disparate_impact_ratio, average_odds_error, generalized_fpr\n",
    "from aif360.sklearn.metrics import generalized_fnr, difference\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
    "# from common_utils import compute_metrics\n",
    "from aif360.datasets import StandardDataset, BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.postprocessing.calibrated_eq_odds_postprocessing import CalibratedEqOddsPostprocessing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96f3165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646fdbc",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8647ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('saved_models/mlp_binary_1.h5')\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(learning_rate=0.0005),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0fca1e",
   "metadata": {},
   "source": [
    "### get data & convert to AIF360 BinaryLabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93b373d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X1 = fh.get_aif360_data()\n",
    "\n",
    "dataset1b = BinaryLabelDataset(df=X1, \n",
    "                          label_names=['CVD'], \n",
    "                          protected_attribute_names=['sex-binary'])\n",
    "\n",
    "dataset2b = BinaryLabelDataset(df=X1, \n",
    "                          label_names=['CVD'], \n",
    "                          protected_attribute_names=['race-binary'])\n",
    "\n",
    "dataset3b = BinaryLabelDataset(df=X1, \n",
    "                          label_names=['CVD'], \n",
    "                          protected_attribute_names=['age-binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb377a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validation, and test partitions\n",
    "\n",
    "dataset_orig_train1, dataset_orig_vt1 = dataset1b.split([0.6], shuffle=True)\n",
    "dataset_orig_valid1, dataset_orig_test1 = dataset1b.split([0.5], shuffle=True)\n",
    "\n",
    "dataset_orig_train2, dataset_orig_vt2 = dataset2b.split([0.6], shuffle=True)\n",
    "dataset_orig_valid2, dataset_orig_test2 = dataset2b.split([0.5], shuffle=True)\n",
    "\n",
    "dataset_orig_train3, dataset_orig_vt3 = dataset1b.split([0.6], shuffle=True)\n",
    "dataset_orig_valid3, dataset_orig_test3 = dataset1b.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "794e99d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301488, 105)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c71af6f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = dataset_orig_train1.features[:,:-4]\n",
    "y_train = dataset_orig_train1.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5b2e3",
   "metadata": {},
   "source": [
    "#### get original predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7deafb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4795/9422 [==============>...............] - ETA: 39s - loss: 0.2780 - acc: 0.9086 - auc_2: 0.7253 - recall_2: 0.0053"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15020/180087699.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd6c33",
   "metadata": {},
   "source": [
    "### Method 1. Calibrated Equalized Odds Post-processing\n",
    "\n",
    "Optimizes over calibrated classifier score outputs to find probabilities with which to change output labels with an equalized odds objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef732ca",
   "metadata": {},
   "source": [
    "#### construct calibrated classifier for each protected attribute & constraint (FNR & weighted(fnr/fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be640614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost constraint of fnr will optimize generalized false negative rates, that of\n",
    "# fpr will optimize generalized false positive rates, and weighted will optimize\n",
    "# a weighted combination of both\n",
    "cost_constraint_fnr = \"fnr\" # \"fnr\", \"fpr\", \"weighted\"\n",
    "cost_constraint_weighted = \"weighted\"\n",
    "randseed = 156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28f7a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, u1 = fh.get_att_privilege_groups('sex-binary')\n",
    "p2, u2 = fh.get_att_privilege_groups('race-binary')\n",
    "p3, u3 = fh.get_att_privilege_groups('age-binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cedf0320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters to equalize odds and apply to create a new dataset\n",
    "\n",
    "# fnr constraint\n",
    "cpp_sex_fnr = CalibratedEqOddsPostprocessing(privileged_groups = p1,\n",
    "                                     unprivileged_groups = u1,\n",
    "                                     cost_constraint=cost_constraint_fnr,\n",
    "                                     seed=randseed)\n",
    "\n",
    "cpp_race_fnr = CalibratedEqOddsPostprocessing(privileged_groups = p2,\n",
    "                                     unprivileged_groups = u2,\n",
    "                                     cost_constraint=cost_constraint_fnr,\n",
    "                                     seed=randseed)\n",
    "\n",
    "cpp_age_fnr = CalibratedEqOddsPostprocessing(privileged_groups = p3,\n",
    "                                     unprivileged_groups = u3,\n",
    "                                     cost_constraint=cost_constraint_fnr,\n",
    "                                     seed=randseed)\n",
    "\n",
    "# weighted constraint\n",
    "cpp_sex_weighted = CalibratedEqOddsPostprocessing(privileged_groups = p1,\n",
    "                                     unprivileged_groups = u1,\n",
    "                                     cost_constraint=cost_constraint_weighted,\n",
    "                                     seed=randseed)\n",
    "\n",
    "cpp_race_weighted = CalibratedEqOddsPostprocessing(privileged_groups = p2,\n",
    "                                     unprivileged_groups = u2,\n",
    "                                     cost_constraint=cost_constraint_weighted,\n",
    "                                     seed=randseed)\n",
    "\n",
    "cpp_age_weighted = CalibratedEqOddsPostprocessing(privileged_groups = p3,\n",
    "                                     unprivileged_groups = u3,\n",
    "                                     cost_constraint=cost_constraint_weighted,\n",
    "                                     seed=randseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b96d6",
   "metadata": {},
   "source": [
    "#### fit each dataset on set of postprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90ae9b27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_orig_valid_pred1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15020/992210996.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# sex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcpp_sex_fnr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcpp_sex_fnr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_orig_valid1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_orig_valid_pred1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcpp_sex_weighted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcpp_sex_weighted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_orig_valid1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_orig_valid_pred1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_orig_valid_pred1' is not defined"
     ]
    }
   ],
   "source": [
    "# sex\n",
    "cpp_sex_fnr = cpp_sex_fnr.fit(dataset_orig_valid1, dataset_orig_valid_pred1)\n",
    "cpp_sex_weighted = cpp_sex_weighted.fit(dataset_orig_valid1, dataset_orig_valid_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26cadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026e93ee",
   "metadata": {},
   "source": [
    "### transform validation and test data using the post processing algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7871a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transf_valid_pred = cpp.predict(dataset_orig_valid_pred)\n",
    "dataset_transf_test_pred = cpp.predict(dataset_orig_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b97e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing: Check if the rates for validation data has gone down\n",
    "assert np.abs(cm_transf_valid.difference(cm_transf_valid.generalized_false_negative_rate)) < np.abs(cm_pred_valid.difference(cm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989bbd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds\n",
    "all_thresh = np.linspace(0.01, 0.99, 25)\n",
    "display(Markdown(\"#### Classification thresholds used for validation and parameter selection\"))\n",
    "\n",
    "bef_avg_odds_diff_test = []\n",
    "bef_avg_odds_diff_valid = []\n",
    "aft_avg_odds_diff_test = []\n",
    "aft_avg_odds_diff_valid = []\n",
    "bef_bal_acc_valid = []\n",
    "bef_bal_acc_test = []\n",
    "aft_bal_acc_valid = []\n",
    "aft_bal_acc_test = []\n",
    "for thresh in tqdm(all_thresh):\n",
    "    \n",
    "    dataset_orig_valid_pred_thresh = dataset_orig_valid_pred.copy(deepcopy=True)\n",
    "    dataset_orig_test_pred_thresh = dataset_orig_test_pred.copy(deepcopy=True)\n",
    "    dataset_transf_valid_pred_thresh = dataset_transf_valid_pred.copy(deepcopy=True)\n",
    "    dataset_transf_test_pred_thresh = dataset_transf_test_pred.copy(deepcopy=True)\n",
    "    \n",
    "    # Labels for the datasets from scores\n",
    "    y_temp = np.zeros_like(dataset_orig_valid_pred_thresh.labels)\n",
    "    y_temp[dataset_orig_valid_pred_thresh.scores >= thresh] = dataset_orig_valid_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_orig_valid_pred_thresh.scores >= thresh)] = dataset_orig_valid_pred_thresh.unfavorable_label\n",
    "    dataset_orig_valid_pred_thresh.labels = y_temp\n",
    "\n",
    "    y_temp = np.zeros_like(dataset_orig_test_pred_thresh.labels)\n",
    "    y_temp[dataset_orig_test_pred_thresh.scores >= thresh] = dataset_orig_test_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_orig_test_pred_thresh.scores >= thresh)] = dataset_orig_test_pred_thresh.unfavorable_label\n",
    "    dataset_orig_test_pred_thresh.labels = y_temp\n",
    "    \n",
    "    y_temp = np.zeros_like(dataset_transf_valid_pred_thresh.labels)\n",
    "    y_temp[dataset_transf_valid_pred_thresh.scores >= thresh] = dataset_transf_valid_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_transf_valid_pred_thresh.scores >= thresh)] = dataset_transf_valid_pred_thresh.unfavorable_label\n",
    "    dataset_transf_valid_pred_thresh.labels = y_temp\n",
    "    \n",
    "    y_temp = np.zeros_like(dataset_transf_test_pred_thresh.labels)\n",
    "    y_temp[dataset_transf_test_pred_thresh.scores >= thresh] = dataset_transf_test_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_transf_test_pred_thresh.scores >= thresh)] = dataset_transf_test_pred_thresh.unfavorable_label\n",
    "    dataset_transf_test_pred_thresh.labels = y_temp\n",
    "    \n",
    "    # Metrics for original validation data\n",
    "    classified_metric_orig_valid = ClassificationMetric(dataset_orig_valid,\n",
    "                                                 dataset_orig_valid_pred_thresh,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    bef_avg_odds_diff_valid.append(classified_metric_orig_valid.equal_opportunity_difference())\n",
    "\n",
    "    bef_bal_acc_valid.append(0.5*(classified_metric_orig_valid.true_positive_rate()+\n",
    "                              classified_metric_orig_valid.true_negative_rate()))\n",
    "\n",
    "    classified_metric_orig_test = ClassificationMetric(dataset_orig_test,\n",
    "                                                 dataset_orig_test_pred_thresh,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    bef_avg_odds_diff_test.append(classified_metric_orig_test.equal_opportunity_difference())\n",
    "    bef_bal_acc_test.append(0.5*(classified_metric_orig_test.true_positive_rate()+\n",
    "                              classified_metric_orig_test.true_negative_rate()))\n",
    "\n",
    "    # Metrics for transf validing data\n",
    "    classified_metric_transf_valid = ClassificationMetric(\n",
    "                                     dataset_orig_valid, \n",
    "                                     dataset_transf_valid_pred_thresh,\n",
    "                                     unprivileged_groups=unprivileged_groups,\n",
    "                                     privileged_groups=privileged_groups)\n",
    "    aft_avg_odds_diff_valid.append(classified_metric_transf_valid.equal_opportunity_difference())\n",
    "    aft_bal_acc_valid.append(0.5*(classified_metric_transf_valid.true_positive_rate()+\n",
    "                              classified_metric_transf_valid.true_negative_rate()))\n",
    "\n",
    "    # Metrics for transf validation data\n",
    "    classified_metric_transf_test = ClassificationMetric(dataset_orig_test,\n",
    "                                                 dataset_transf_test_pred_thresh,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    aft_avg_odds_diff_test.append(classified_metric_transf_test.equal_opportunity_difference())\n",
    "    aft_bal_acc_test.append(0.5*(classified_metric_transf_test.true_positive_rate()+\n",
    "                                  classified_metric_transf_test.true_negative_rate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "bef_bal_acc_valid = np.array(bef_bal_acc_valid)\n",
    "bef_avg_odds_diff_valid = np.array(bef_avg_odds_diff_valid)\n",
    "\n",
    "aft_bal_acc_valid = np.array(aft_bal_acc_valid)\n",
    "aft_avg_odds_diff_valid = np.array(aft_avg_odds_diff_valid)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(13,7))\n",
    "ax1.plot(all_thresh, bef_bal_acc_valid, color='b')\n",
    "ax1.plot(all_thresh, aft_bal_acc_valid, color='b', linestyle='dashed')\n",
    "ax1.set_title('Original and Postprocessed validation data', fontsize=16, fontweight='bold')\n",
    "ax1.set_xlabel('Classification Thresholds', fontsize=16, fontweight='bold')\n",
    "ax1.set_ylabel('Balanced Accuracy', color='b', fontsize=16, fontweight='bold')\n",
    "ax1.xaxis.set_tick_params(labelsize=14)\n",
    "ax1.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(all_thresh, np.abs(bef_avg_odds_diff_valid), color='r')\n",
    "ax2.plot(all_thresh, np.abs(aft_avg_odds_diff_valid), color='r', linestyle='dashed')\n",
    "ax2.set_ylabel('abs(Equal opportunity diff)', color='r', fontsize=16, fontweight='bold')\n",
    "ax2.yaxis.set_tick_params(labelsize=14)\n",
    "ax2.grid(True)\n",
    "fig.legend([\"Balanced Acc. - Orig.\", \"Balanced Acc. - Postproc.\",\n",
    "             \"Equal opp. diff. - Orig.\",\"Equal opp. diff. - Postproc.\",], \n",
    "           fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e264d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bef_bal_acc_test = np.array(bef_bal_acc_test)\n",
    "bef_avg_odds_diff_test = np.array(bef_avg_odds_diff_test)\n",
    "\n",
    "aft_bal_acc_test = np.array(aft_bal_acc_test)\n",
    "aft_avg_odds_diff_test = np.array(aft_avg_odds_diff_test)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(13,7))\n",
    "ax1.plot(all_thresh, bef_bal_acc_test, color='b')\n",
    "ax1.plot(all_thresh, aft_bal_acc_test, color='b', linestyle='dashed')\n",
    "ax1.set_title('Original and Postprocessed testing data', fontsize=16, fontweight='bold')\n",
    "ax1.set_xlabel('Classification Thresholds', fontsize=16, fontweight='bold')\n",
    "ax1.set_ylabel('Balanced Accuracy', color='b', fontsize=16, fontweight='bold')\n",
    "ax1.xaxis.set_tick_params(labelsize=14)\n",
    "ax1.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(all_thresh, np.abs(bef_avg_odds_diff_test), color='r')\n",
    "ax2.plot(all_thresh, np.abs(aft_avg_odds_diff_test), color='r', linestyle='dashed')\n",
    "ax2.set_ylabel('abs(Equal opportunity diff)', color='r', fontsize=16, fontweight='bold')\n",
    "ax2.yaxis.set_tick_params(labelsize=14)\n",
    "ax2.grid(True)\n",
    "fig.legend([\"Balanced Acc. - Orig.\", \"Balanced Acc. - Postproc.\",\n",
    "            \"Equal opp. diff. - Orig.\", \"Equal opp. diff. - Postproc.\"], \n",
    "           fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cda2b8",
   "metadata": {},
   "source": [
    "#### alternative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabfa2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_eq_odds = CalibratedEqualizedOdds('sex', cost_constraint='fnr', random_state=1234567)\n",
    "log_reg = LogisticRegression(solver='lbfgs')\n",
    "postproc = PostProcessingMeta(estimator=log_reg, postprocessor=cal_eq_odds, random_state=1234567)\n",
    "\n",
    "postproc.fit(X_train, y_train)\n",
    "accuracy_score(y_test, postproc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = postproc.predict_proba(X_test)[:, 1]\n",
    "y_lr = postproc.estimator_.predict_proba(X_test)[:, 1]\n",
    "br = postproc.postprocessor_.base_rates_\n",
    "i = X_test.index.get_level_values('sex-binary') == 1\n",
    "\n",
    "plt.plot([0, br[0]], [0, 1-br[0]], '-b', label='All calibrated classifiers (Females)')\n",
    "plt.plot([0, br[1]], [0, 1-br[1]], '-r', label='All calibrated classifiers (Males)')\n",
    "\n",
    "plt.scatter(generalized_fpr(y_test[~i], y_lr[~i]),\n",
    "            generalized_fnr(y_test[~i], y_lr[~i]),\n",
    "            300, c='b', marker='.', label='Original classifier (Females)')\n",
    "plt.scatter(generalized_fpr(y_test[i], y_lr[i]),\n",
    "            generalized_fnr(y_test[i], y_lr[i]),\n",
    "            300, c='r', marker='.', label='Original classifier (Males)')\n",
    "                                                                        \n",
    "plt.scatter(generalized_fpr(y_test[~i], y_pred[~i]),\n",
    "            generalized_fnr(y_test[~i], y_pred[~i]),\n",
    "            100, c='b', marker='d', label='Post-processed classifier (Females)')\n",
    "plt.scatter(generalized_fpr(y_test[i], y_pred[i]),\n",
    "            generalized_fnr(y_test[i], y_pred[i]),\n",
    "            100, c='r', marker='d', label='Post-processed classifier (Males)')\n",
    "\n",
    "plt.plot([0, 1], [generalized_fnr(y_test, y_pred)]*2, '--', c='0.5')\n",
    "\n",
    "plt.axis('square')\n",
    "plt.xlim([0.0, 0.4])\n",
    "plt.ylim([0.3, 0.7])\n",
    "plt.xlabel('generalized fpr');\n",
    "plt.ylabel('generalized fnr');\n",
    "plt.legend(bbox_to_anchor=(1.04,1), loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9651132",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference(generalized_fnr, y_test, y_pred, prot_attr='sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df4fe3e",
   "metadata": {},
   "source": [
    "### Method 2.  Equalized Odds Post-Processing\n",
    "\n",
    "Solves a linear program to find probabilities with which to change output labels to optimize equalized odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609e0d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01b09ab1",
   "metadata": {},
   "source": [
    "### Method 3. Reject Option Classification\n",
    "\n",
    "Gives favorable outcomes ot unprivileged groups and unfavorable outcomes to priviliged groups in a confidence band around the decision boundary with the highest uncertainty\n",
    "\n",
    "> The debiasing function used is implemented in the RejectOptionClassification class.\n",
    "- Divide the dataset into training, validation, and testing partitions.\n",
    "- Train classifier on original training data.\n",
    "- Estimate the optimal classification threshold, that maximizes balanced accuracy without fairness constraints.\n",
    "- Estimate the optimal classification threshold, and the critical region boundary (ROC margin) using a validation set for the desired constraint on fairness. The best parameters are those that maximize the classification threshold while satisfying the fairness constraints.\n",
    "- The constraints can be used on the following fairness measures:\n",
    "          - Statistical parity difference on the predictions of the classifier\n",
    "          - Average odds difference for the classifier\n",
    "          - Equal opportunity difference for the classifier\n",
    "- Determine the prediction scores for testing data. Using the estimated optimal classification threshold, compute accuracy and fairness metrics.\n",
    "- Using the determined optimal classification threshold and the ROC margin, adjust the predictions. Report accuracy and fairness metric on the new predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275c0914",
   "metadata": {},
   "source": [
    "#### estimate optimal parameters for the ROC method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc614000",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                  num_class_thresh=100, num_ROC_margin=50,\n",
    "                                  metric_name=metric_name,\n",
    "                                  metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "ROC = ROC.fit(dataset_orig_valid, dataset_orig_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8964651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
